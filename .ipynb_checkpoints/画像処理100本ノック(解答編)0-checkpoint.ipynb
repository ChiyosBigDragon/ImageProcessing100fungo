{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[画像処理100本ノック](https://github.com/yoyoyo-yo/Gasyori100knock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>目次<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Tutorial\" data-toc-modified-id=\"Tutorial-1\">Tutorial</a></span><ul class=\"toc-item\"><li><span><a href=\"#Python起動\" data-toc-modified-id=\"Python起動-1.1\">Python起動</a></span></li><li><span><a href=\"#インポート\" data-toc-modified-id=\"インポート-1.2\">インポート</a></span></li><li><span><a href=\"#画像読み込み、表示\" data-toc-modified-id=\"画像読み込み、表示-1.3\">画像読み込み、表示</a></span></li><li><span><a href=\"#画素をいじる。\" data-toc-modified-id=\"画素をいじる。-1.4\">画素をいじる。</a></span></li><li><span><a href=\"#画像のコピー\" data-toc-modified-id=\"画像のコピー-1.5\">画像のコピー</a></span></li><li><span><a href=\"#画像の保存\" data-toc-modified-id=\"画像の保存-1.6\">画像の保存</a></span></li><li><span><a href=\"#練習\" data-toc-modified-id=\"練習-1.7\">練習</a></span></li></ul></li><li><span><a href=\"#Q.-1---10\" data-toc-modified-id=\"Q.-1---10-2\">Q. 1 - 10</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.1.-チャネル入れ替え\" data-toc-modified-id=\"Q.1.-チャネル入れ替え-2.1\">Q.1. チャネル入れ替え</a></span></li><li><span><a href=\"#Q.2.-グレースケール化\" data-toc-modified-id=\"Q.2.-グレースケール化-2.2\">Q.2. グレースケール化</a></span></li><li><span><a href=\"#Q.3.-二値化\" data-toc-modified-id=\"Q.3.-二値化-2.3\">Q.3. 二値化</a></span></li><li><span><a href=\"#Q.4.-大津の二値化\" data-toc-modified-id=\"Q.4.-大津の二値化-2.4\">Q.4. 大津の二値化</a></span></li><li><span><a href=\"#Q.5.-HSV変換\" data-toc-modified-id=\"Q.5.-HSV変換-2.5\">Q.5. HSV変換</a></span></li><li><span><a href=\"#Q.6.-減色処理\" data-toc-modified-id=\"Q.6.-減色処理-2.6\">Q.6. 減色処理</a></span></li><li><span><a href=\"#Q.7.-平均プーリング\" data-toc-modified-id=\"Q.7.-平均プーリング-2.7\">Q.7. 平均プーリング</a></span></li><li><span><a href=\"#Q.8.-Maxプーリング\" data-toc-modified-id=\"Q.8.-Maxプーリング-2.8\">Q.8. Maxプーリング</a></span></li><li><span><a href=\"#Q.9.-ガウシアンフィルタ\" data-toc-modified-id=\"Q.9.-ガウシアンフィルタ-2.9\">Q.9. ガウシアンフィルタ</a></span></li><li><span><a href=\"#Q.10-メディアンフィルタ\" data-toc-modified-id=\"Q.10-メディアンフィルタ-2.10\">Q.10 メディアンフィルタ</a></span></li></ul></li><li><span><a href=\"#Q.11---20\" data-toc-modified-id=\"Q.11---20-3\">Q.11 - 20</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.11.-平滑化フィルタ\" data-toc-modified-id=\"Q.11.-平滑化フィルタ-3.1\">Q.11. 平滑化フィルタ</a></span></li><li><span><a href=\"#Q.12.-モーションフィルタ\" data-toc-modified-id=\"Q.12.-モーションフィルタ-3.2\">Q.12. モーションフィルタ</a></span></li><li><span><a href=\"#Q.13.-MAX-MINフィルタ\" data-toc-modified-id=\"Q.13.-MAX-MINフィルタ-3.3\">Q.13. MAX-MINフィルタ</a></span></li><li><span><a href=\"#Q.14.-微分フィルタ\" data-toc-modified-id=\"Q.14.-微分フィルタ-3.4\">Q.14. 微分フィルタ</a></span></li><li><span><a href=\"#Q.15.-Sobelフィルタ\" data-toc-modified-id=\"Q.15.-Sobelフィルタ-3.5\">Q.15. Sobelフィルタ</a></span></li><li><span><a href=\"#Q.16.-Prewittフィルタ\" data-toc-modified-id=\"Q.16.-Prewittフィルタ-3.6\">Q.16. Prewittフィルタ</a></span></li><li><span><a href=\"#Q.17.-Laplacianフィルタ\" data-toc-modified-id=\"Q.17.-Laplacianフィルタ-3.7\">Q.17. Laplacianフィルタ</a></span></li><li><span><a href=\"#Q.18.-Embossフィルタ\" data-toc-modified-id=\"Q.18.-Embossフィルタ-3.8\">Q.18. Embossフィルタ</a></span></li><li><span><a href=\"#Q.19.-LoGフィルタ\" data-toc-modified-id=\"Q.19.-LoGフィルタ-3.9\">Q.19. LoGフィルタ</a></span></li><li><span><a href=\"#Q.20.-ヒストグラム表示\" data-toc-modified-id=\"Q.20.-ヒストグラム表示-3.10\">Q.20. ヒストグラム表示</a></span></li></ul></li><li><span><a href=\"#Q.-21---30\" data-toc-modified-id=\"Q.-21---30-4\">Q. 21 - 30</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.21.-ヒストグラム正規化\" data-toc-modified-id=\"Q.21.-ヒストグラム正規化-4.1\">Q.21. ヒストグラム正規化</a></span></li><li><span><a href=\"#Q.22.-ヒストグラム操作\" data-toc-modified-id=\"Q.22.-ヒストグラム操作-4.2\">Q.22. ヒストグラム操作</a></span></li><li><span><a href=\"#Q.23.-ヒストグラム平坦化\" data-toc-modified-id=\"Q.23.-ヒストグラム平坦化-4.3\">Q.23. ヒストグラム平坦化</a></span></li><li><span><a href=\"#Q.24.-ガンマ補正\" data-toc-modified-id=\"Q.24.-ガンマ補正-4.4\">Q.24. ガンマ補正</a></span></li><li><span><a href=\"#Q.25.-最近傍補間\" data-toc-modified-id=\"Q.25.-最近傍補間-4.5\">Q.25. 最近傍補間</a></span></li><li><span><a href=\"#Q.26.-Bi-linear補間\" data-toc-modified-id=\"Q.26.-Bi-linear補間-4.6\">Q.26. Bi-linear補間</a></span></li><li><span><a href=\"#Q.27.-Bi-cubic補間\" data-toc-modified-id=\"Q.27.-Bi-cubic補間-4.7\">Q.27. Bi-cubic補間</a></span></li><li><span><a href=\"#Q.28.-アフィン変換(平行移動)\" data-toc-modified-id=\"Q.28.-アフィン変換(平行移動)-4.8\">Q.28. アフィン変換(平行移動)</a></span></li><li><span><a href=\"#Q.29.-アフィン変換(拡大縮小)\" data-toc-modified-id=\"Q.29.-アフィン変換(拡大縮小)-4.9\">Q.29. アフィン変換(拡大縮小)</a></span></li><li><span><a href=\"#Q.30.-アフィン変換(回転)\" data-toc-modified-id=\"Q.30.-アフィン変換(回転)-4.10\">Q.30. アフィン変換(回転)</a></span></li></ul></li><li><span><a href=\"#Q.-31---40\" data-toc-modified-id=\"Q.-31---40-5\">Q. 31 - 40</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.31.-アフィン変換(スキュー)\" data-toc-modified-id=\"Q.31.-アフィン変換(スキュー)-5.1\">Q.31. アフィン変換(スキュー)</a></span></li><li><span><a href=\"#Q.32.-フーリエ変換\" data-toc-modified-id=\"Q.32.-フーリエ変換-5.2\">Q.32. フーリエ変換</a></span></li><li><span><a href=\"#Q.33.-フーリエ変換　ローパスフィルタ\" data-toc-modified-id=\"Q.33.-フーリエ変換　ローパスフィルタ-5.3\">Q.33. フーリエ変換　ローパスフィルタ</a></span></li><li><span><a href=\"#Q.34.-フーリエ変換　ハイパスフィルタ\" data-toc-modified-id=\"Q.34.-フーリエ変換　ハイパスフィルタ-5.4\">Q.34. フーリエ変換　ハイパスフィルタ</a></span></li><li><span><a href=\"#Q.35.-フーリエ変換　バンドパスフィルタ\" data-toc-modified-id=\"Q.35.-フーリエ変換　バンドパスフィルタ-5.5\">Q.35. フーリエ変換　バンドパスフィルタ</a></span></li><li><span><a href=\"#Q.36.-JPEG圧縮-(Step.1)離散コサイン変換\" data-toc-modified-id=\"Q.36.-JPEG圧縮-(Step.1)離散コサイン変換-5.6\">Q.36. JPEG圧縮 (Step.1)離散コサイン変換</a></span></li><li><span><a href=\"#Q.37.-PSNR\" data-toc-modified-id=\"Q.37.-PSNR-5.7\">Q.37. PSNR</a></span></li><li><span><a href=\"#Q.38.-JPEG圧縮-(Step.2)DCT+量子化|\" data-toc-modified-id=\"Q.38.-JPEG圧縮-(Step.2)DCT+量子化|-5.8\">Q.38. JPEG圧縮 (Step.2)DCT+量子化|</a></span></li><li><span><a href=\"#Q.39.-JPEG圧縮-(Step.3)YCbCr表色系\" data-toc-modified-id=\"Q.39.-JPEG圧縮-(Step.3)YCbCr表色系-5.9\">Q.39. JPEG圧縮 (Step.3)YCbCr表色系</a></span></li><li><span><a href=\"#Q.40.-JPEG圧縮-(Step.4)YCbCr+DCT+量子化\" data-toc-modified-id=\"Q.40.-JPEG圧縮-(Step.4)YCbCr+DCT+量子化-5.10\">Q.40. JPEG圧縮 (Step.4)YCbCr+DCT+量子化</a></span></li></ul></li><li><span><a href=\"#Q.-41---50\" data-toc-modified-id=\"Q.-41---50-6\">Q. 41 - 50</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.41.-Cannyエッジ検出-(Step.1)-エッジ強度\" data-toc-modified-id=\"Q.41.-Cannyエッジ検出-(Step.1)-エッジ強度-6.1\">Q.41. Cannyエッジ検出 (Step.1) エッジ強度</a></span></li><li><span><a href=\"#Q.42.-Cannyエッジ検出-(Step.2)-細線化\" data-toc-modified-id=\"Q.42.-Cannyエッジ検出-(Step.2)-細線化-6.2\">Q.42. Cannyエッジ検出 (Step.2) 細線化</a></span></li><li><span><a href=\"#Q.43.-Cannyエッジ検出-(Step.3)-ヒステリシス閾処理\" data-toc-modified-id=\"Q.43.-Cannyエッジ検出-(Step.3)-ヒステリシス閾処理-6.3\">Q.43. Cannyエッジ検出 (Step.3) ヒステリシス閾処理</a></span></li><li><span><a href=\"#Q.44.-Hough変換・直線検出-(Step.1)-Hough変換\" data-toc-modified-id=\"Q.44.-Hough変換・直線検出-(Step.1)-Hough変換-6.4\">Q.44. Hough変換・直線検出 (Step.1) Hough変換</a></span></li><li><span><a href=\"#Q.45.-Hough変換・直線検出-(Step.2)-NMS\" data-toc-modified-id=\"Q.45.-Hough変換・直線検出-(Step.2)-NMS-6.5\">Q.45. Hough変換・直線検出 (Step.2) NMS</a></span></li><li><span><a href=\"#Q.46.-Hough変換・直線検出-(Step.3)-Hough逆変換\" data-toc-modified-id=\"Q.46.-Hough変換・直線検出-(Step.3)-Hough逆変換-6.6\">Q.46. Hough変換・直線検出 (Step.3) Hough逆変換</a></span></li><li><span><a href=\"#Q.47.-モルフォロジー処理(膨張)\" data-toc-modified-id=\"Q.47.-モルフォロジー処理(膨張)-6.7\">Q.47. モルフォロジー処理(膨張)</a></span></li><li><span><a href=\"#Q.48.-モルフォロジー処理(収縮)\" data-toc-modified-id=\"Q.48.-モルフォロジー処理(収縮)-6.8\">Q.48. モルフォロジー処理(収縮)</a></span></li><li><span><a href=\"#Q.49.-オープニング処理\" data-toc-modified-id=\"Q.49.-オープニング処理-6.9\">Q.49. オープニング処理</a></span></li><li><span><a href=\"#Q.50.-クロージング処理\" data-toc-modified-id=\"Q.50.-クロージング処理-6.10\">Q.50. クロージング処理</a></span></li></ul></li><li><span><a href=\"#Q.-51---60\" data-toc-modified-id=\"Q.-51---60-7\">Q. 51 - 60</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.51.-モルフォロジー勾配\" data-toc-modified-id=\"Q.51.-モルフォロジー勾配-7.1\">Q.51. モルフォロジー勾配</a></span></li><li><span><a href=\"#Q.52.-トップハット変換\" data-toc-modified-id=\"Q.52.-トップハット変換-7.2\">Q.52. トップハット変換</a></span></li><li><span><a href=\"#Q.53.-ブラックハット変換\" data-toc-modified-id=\"Q.53.-ブラックハット変換-7.3\">Q.53. ブラックハット変換</a></span></li><li><span><a href=\"#Q.54.-テンプレートマッチング-SSD\" data-toc-modified-id=\"Q.54.-テンプレートマッチング-SSD-7.4\">Q.54. テンプレートマッチング SSD</a></span></li><li><span><a href=\"#Q.55.-テンプレートマッチング-SAD\" data-toc-modified-id=\"Q.55.-テンプレートマッチング-SAD-7.5\">Q.55. テンプレートマッチング SAD</a></span></li><li><span><a href=\"#Q.56.-テンプレートマッチング-NCC\" data-toc-modified-id=\"Q.56.-テンプレートマッチング-NCC-7.6\">Q.56. テンプレートマッチング NCC</a></span></li><li><span><a href=\"#Q.57.-テンプレートマッチング-ZNCC\" data-toc-modified-id=\"Q.57.-テンプレートマッチング-ZNCC-7.7\">Q.57. テンプレートマッチング ZNCC</a></span></li><li><span><a href=\"#Q.58.-ラベリング-4近傍\" data-toc-modified-id=\"Q.58.-ラベリング-4近傍-7.8\">Q.58. ラベリング 4近傍</a></span></li><li><span><a href=\"#Q.59.-ラベリング-8近傍\" data-toc-modified-id=\"Q.59.-ラベリング-8近傍-7.9\">Q.59. ラベリング 8近傍</a></span></li><li><span><a href=\"#Q.60.-アルファブレンド\" data-toc-modified-id=\"Q.60.-アルファブレンド-7.10\">Q.60. アルファブレンド</a></span></li></ul></li><li><span><a href=\"#Q.-61---70\" data-toc-modified-id=\"Q.-61---70-8\">Q. 61 - 70</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.61.-4-連結数\" data-toc-modified-id=\"Q.61.-4-連結数-8.1\">Q.61. 4-連結数</a></span></li><li><span><a href=\"#Q.62.-8-連結数\" data-toc-modified-id=\"Q.62.-8-連結数-8.2\">Q.62. 8-連結数</a></span></li><li><span><a href=\"#Q.63.-細線化処理\" data-toc-modified-id=\"Q.63.-細線化処理-8.3\">Q.63. 細線化処理</a></span></li><li><span><a href=\"#Q.64.-ヒルディッチの細線化\" data-toc-modified-id=\"Q.64.-ヒルディッチの細線化-8.4\">Q.64. ヒルディッチの細線化</a></span></li><li><span><a href=\"#Q.65.-Zhang-Suenの細線化\" data-toc-modified-id=\"Q.65.-Zhang-Suenの細線化-8.5\">Q.65. Zhang-Suenの細線化</a></span></li><li><span><a href=\"#Q.66.-HOG-(Step.1)-勾配強度・勾配角度\" data-toc-modified-id=\"Q.66.-HOG-(Step.1)-勾配強度・勾配角度-8.6\">Q.66. HOG (Step.1) 勾配強度・勾配角度</a></span></li><li><span><a href=\"#Q.67.-HOG-(Step.2)-勾配ヒストグラム\" data-toc-modified-id=\"Q.67.-HOG-(Step.2)-勾配ヒストグラム-8.7\">Q.67. HOG (Step.2) 勾配ヒストグラム</a></span></li><li><span><a href=\"#Q.68.-HOG-(Step.3)-ヒストグラム正規化\" data-toc-modified-id=\"Q.68.-HOG-(Step.3)-ヒストグラム正規化-8.8\">Q.68. HOG (Step.3) ヒストグラム正規化</a></span></li><li><span><a href=\"#Q.69.-HOG-(Step.4)-特徴量の描画\" data-toc-modified-id=\"Q.69.-HOG-(Step.4)-特徴量の描画-8.9\">Q.69. HOG (Step.4) 特徴量の描画</a></span></li><li><span><a href=\"#Q.70.-カラートラッキング\" data-toc-modified-id=\"Q.70.-カラートラッキング-8.10\">Q.70. カラートラッキング</a></span></li></ul></li><li><span><a href=\"#Q.-71---80\" data-toc-modified-id=\"Q.-71---80-9\">Q. 71 - 80</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.71.-マスキング\" data-toc-modified-id=\"Q.71.-マスキング-9.1\">Q.71. マスキング</a></span></li><li><span><a href=\"#Q.72.-マスキング(カラートラッキング＋モルフォロジー)\" data-toc-modified-id=\"Q.72.-マスキング(カラートラッキング＋モルフォロジー)-9.2\">Q.72. マスキング(カラートラッキング＋モルフォロジー)</a></span></li><li><span><a href=\"#Q.73.-縮小と拡大\" data-toc-modified-id=\"Q.73.-縮小と拡大-9.3\">Q.73. 縮小と拡大</a></span></li><li><span><a href=\"#Q.74.-ピラミッド差分による高周波成分の抽出\" data-toc-modified-id=\"Q.74.-ピラミッド差分による高周波成分の抽出-9.4\">Q.74. ピラミッド差分による高周波成分の抽出</a></span></li><li><span><a href=\"#Q.75.-ガウシアンピラミッド\" data-toc-modified-id=\"Q.75.-ガウシアンピラミッド-9.5\">Q.75. ガウシアンピラミッド</a></span></li><li><span><a href=\"#Q.76.-顕著性マップ\" data-toc-modified-id=\"Q.76.-顕著性マップ-9.6\">Q.76. 顕著性マップ</a></span></li><li><span><a href=\"#Q.77.-ガボールフィルタ\" data-toc-modified-id=\"Q.77.-ガボールフィルタ-9.7\">Q.77. ガボールフィルタ</a></span></li><li><span><a href=\"#Q.78.-ガボールフィルタの回転\" data-toc-modified-id=\"Q.78.-ガボールフィルタの回転-9.8\">Q.78. ガボールフィルタの回転</a></span></li><li><span><a href=\"#Q.79.-ガボールフィルタによるエッジ抽出\" data-toc-modified-id=\"Q.79.-ガボールフィルタによるエッジ抽出-9.9\">Q.79. ガボールフィルタによるエッジ抽出</a></span></li><li><span><a href=\"#Q.80.-ガボールフィルタによる特徴抽出\" data-toc-modified-id=\"Q.80.-ガボールフィルタによる特徴抽出-9.10\">Q.80. ガボールフィルタによる特徴抽出</a></span></li></ul></li><li><span><a href=\"#Q.-81---90\" data-toc-modified-id=\"Q.-81---90-10\">Q. 81 - 90</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.81.-Hessianのコーナー検出\" data-toc-modified-id=\"Q.81.-Hessianのコーナー検出-10.1\">Q.81. Hessianのコーナー検出</a></span></li><li><span><a href=\"#Q.82.-Harrisのコーナー検出-(Step.1)-Sobel-+-Gauusian\" data-toc-modified-id=\"Q.82.-Harrisのコーナー検出-(Step.1)-Sobel-+-Gauusian-10.2\">Q.82. Harrisのコーナー検出 (Step.1) Sobel + Gauusian</a></span></li><li><span><a href=\"#Q.83.-Harrisのコーナー検出-(Step.2)-コーナー検出\" data-toc-modified-id=\"Q.83.-Harrisのコーナー検出-(Step.2)-コーナー検出-10.3\">Q.83. Harrisのコーナー検出 (Step.2) コーナー検出</a></span></li><li><span><a href=\"#Q.84.-簡単な画像認識-(Step.1)-減色化-+-ヒストグラム\" data-toc-modified-id=\"Q.84.-簡単な画像認識-(Step.1)-減色化-+-ヒストグラム-10.4\">Q.84. 簡単な画像認識 (Step.1) 減色化 + ヒストグラム</a></span></li><li><span><a href=\"#Q.85.-簡単な画像認識-(Step.2)-クラス判別\" data-toc-modified-id=\"Q.85.-簡単な画像認識-(Step.2)-クラス判別-10.5\">Q.85. 簡単な画像認識 (Step.2) クラス判別</a></span></li><li><span><a href=\"#Q.86.-簡単な画像認識-(Step.3)-評価(Accuracy)\" data-toc-modified-id=\"Q.86.-簡単な画像認識-(Step.3)-評価(Accuracy)-10.6\">Q.86. 簡単な画像認識 (Step.3) 評価(Accuracy)</a></span></li><li><span><a href=\"#Q.87.-簡単な画像認識-(Step.4)-k-NN\" data-toc-modified-id=\"Q.87.-簡単な画像認識-(Step.4)-k-NN-10.7\">Q.87. 簡単な画像認識 (Step.4) k-NN</a></span></li><li><span><a href=\"#Q.88.-K-means-(Step.1)-重心作成\" data-toc-modified-id=\"Q.88.-K-means-(Step.1)-重心作成-10.8\">Q.88. K-means (Step.1) 重心作成</a></span></li><li><span><a href=\"#Q.89.-K-means-(Step.2)-クラスタリング\" data-toc-modified-id=\"Q.89.-K-means-(Step.2)-クラスタリング-10.9\">Q.89. K-means (Step.2) クラスタリング</a></span></li><li><span><a href=\"#Q.90.-K-means-(Step.3)-初期ラベルの変更\" data-toc-modified-id=\"Q.90.-K-means-(Step.3)-初期ラベルの変更-10.10\">Q.90. K-means (Step.3) 初期ラベルの変更</a></span></li></ul></li><li><span><a href=\"#Q.-91---100\" data-toc-modified-id=\"Q.-91---100-11\">Q. 91 - 100</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q.91.-K-meansによる減色処理-(Step.1)-色の距離によるクラス分類\" data-toc-modified-id=\"Q.91.-K-meansによる減色処理-(Step.1)-色の距離によるクラス分類-11.1\">Q.91. K-meansによる減色処理 (Step.1) 色の距離によるクラス分類</a></span></li><li><span><a href=\"#Q.92.-K-meansによる減色処理-(Step.2)-減色処理\" data-toc-modified-id=\"Q.92.-K-meansによる減色処理-(Step.2)-減色処理-11.2\">Q.92. K-meansによる減色処理 (Step.2) 減色処理</a></span></li><li><span><a href=\"#Q.93.-機械学習の学習データの用意-(Step.1)-IoUの計算\" data-toc-modified-id=\"Q.93.-機械学習の学習データの用意-(Step.1)-IoUの計算-11.3\">Q.93. 機械学習の学習データの用意 (Step.1) IoUの計算</a></span></li><li><span><a href=\"#Q.94.-機械学習の学習データの用意-(Step.2)-ランダムクラッピング\" data-toc-modified-id=\"Q.94.-機械学習の学習データの用意-(Step.2)-ランダムクラッピング-11.4\">Q.94. 機械学習の学習データの用意 (Step.2) ランダムクラッピング</a></span></li><li><span><a href=\"#Q.95.-ニューラルネットワーク-(Step.1)-ディープラーニングにする\" data-toc-modified-id=\"Q.95.-ニューラルネットワーク-(Step.1)-ディープラーニングにする-11.5\">Q.95. ニューラルネットワーク (Step.1) ディープラーニングにする</a></span></li><li><span><a href=\"#Q.96.-ニューラルネットワーク-(Step.2)-学習\" data-toc-modified-id=\"Q.96.-ニューラルネットワーク-(Step.2)-学習-11.6\">Q.96. ニューラルネットワーク (Step.2) 学習</a></span></li><li><span><a href=\"#Q.97.-簡単な物体検出-(Step.1)-スライディングウィンドウ-+-HOG\" data-toc-modified-id=\"Q.97.-簡単な物体検出-(Step.1)-スライディングウィンドウ-+-HOG-11.7\">Q.97. 簡単な物体検出 (Step.1) スライディングウィンドウ + HOG</a></span></li><li><span><a href=\"#Q.98.-簡単な物体検出-(Step.2)-スライディングウィンドウ-+-NN\" data-toc-modified-id=\"Q.98.-簡単な物体検出-(Step.2)-スライディングウィンドウ-+-NN-11.8\">Q.98. 簡単な物体検出 (Step.2) スライディングウィンドウ + NN</a></span></li><li><span><a href=\"#Q.99.-簡単な物体検出-(Step.3)-Non-Maximum-Suppression\" data-toc-modified-id=\"Q.99.-簡単な物体検出-(Step.3)-Non-Maximum-Suppression-11.9\">Q.99. 簡単な物体検出 (Step.3) Non-Maximum Suppression</a></span></li><li><span><a href=\"#Q.100.-簡単な物体検出-(Step.4)-評価-Precision,-Recall,-F-score,-mAP\" data-toc-modified-id=\"Q.100.-簡単な物体検出-(Step.4)-評価-Precision,-Recall,-F-score,-mAP-11.10\">Q.100. 簡単な物体検出 (Step.4) 評価 Precision, Recall, F-score, mAP</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recall-...-正解の矩形がどれだけ検出できたか。正解をどれだけ網羅できたかを示す。[0,1]の範囲を取り、1が最高。\" data-toc-modified-id=\"Recall-...-正解の矩形がどれだけ検出できたか。正解をどれだけ網羅できたかを示す。[0,1]の範囲を取り、1が最高。-11.10.1\">Recall ... 正解の矩形がどれだけ検出できたか。正解をどれだけ網羅できたかを示す。[0,1]の範囲を取り、1が最高。</a></span></li><li><span><a href=\"#Precision-...-検出がどれだけ正確に行われたかを示す。[0,1]の範囲を取り、1が最高。\" data-toc-modified-id=\"Precision-...-検出がどれだけ正確に行われたかを示す。[0,1]の範囲を取り、1が最高。-11.10.2\">Precision ... 検出がどれだけ正確に行われたかを示す。[0,1]の範囲を取り、1が最高。</a></span></li><li><span><a href=\"#F-score-...-RecallとPrecisonの調和平均。　２つのバランスを示すもので、[0,1]の範囲を取り、1が最高。\" data-toc-modified-id=\"F-score-...-RecallとPrecisonの調和平均。　２つのバランスを示すもので、[0,1]の範囲を取り、1が最高。-11.10.3\">F-score ... RecallとPrecisonの調和平均。　２つのバランスを示すもので、[0,1]の範囲を取り、1が最高。</a></span></li><li><span><a href=\"#mAP-...-Mean-Average-Precision。物体を検出する物体検出では、mAPで測ることが多い。mAPの計算方法は少し複雑である。\" data-toc-modified-id=\"mAP-...-Mean-Average-Precision。物体を検出する物体検出では、mAPで測ることが多い。mAPの計算方法は少し複雑である。-11.10.4\">mAP ... Mean Average Precision。物体を検出する物体検出では、mAPで測ることが多い。mAPの計算方法は少し複雑である。</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "ここでは画像処理におけるnumpyの基本的な使い方をいくつか紹介していきます。\n",
    "\n",
    "**numpy**とはpyhtonで用意されたパッケージ(Cでいうライブラリのようなもの)の一種で、行列演算などを得意としています。\n",
    "\n",
    "また、画像処理では**OpenCV**というライブラリがあり、様々な処理をAPIかしています。\n",
    "\n",
    "この問題では、numpyをいじって、OpenCVの処理を自分の手で実現することを目標としています。\n",
    "\n",
    "pythonでのOpenCVはnumpyをベースとしているため、numpyがいじれる=OpenCVもいじれる　ということになっていきます。\n",
    "\n",
    "\n",
    "ここからはpyファイルでなく、インタプリタ形式でやってみて下さい。\n",
    "\n",
    "\n",
    "## Python起動\n",
    "\n",
    "コマンドプロンプト上で「python」と打って下さい。\n",
    "すると、こんな感じで >>> と出るはずです。\n",
    "\n",
    "```bash\n",
    "(gasyori100) :~/work_space/Gasyori100knock/Tutorial :$ python\n",
    "Python 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
    "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> \n",
    "```\n",
    "## インポート\n",
    "\n",
    "ここから、パッケージをインストールしていきます。\n",
    "OpenCVはcv2、numpyはnumpyをそれぞれインポートします。\n",
    "（numpyはよくnpという名前にエイリアスします。）\n",
    "\n",
    "```bash\n",
    ">>> import cv2\n",
    ">>> import numpy as np\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像読み込み、表示\n",
    "\n",
    "画像を読み込むのはimread()です。\n",
    "*imori.jpg*を読み込むには、こうします。\n",
    "\n",
    "```bash\n",
    ">>> img = cv2.imread(\"imori.jpg\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./Tutorial/imori.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで変数imgに画像情報がnumpy形式で保存されます。\n",
    "\n",
    "画像のサイズ情報をとるにはimg.shapeを使います。\n",
    "これは(高さ、横、チャネル)の順になっていて、つまり 縦128ピクセル、横128ピクセル、3チャネル(青、緑、赤)を意味します。\n",
    "\n",
    "```bash\n",
    ">>> img.shape\n",
    "(128, 128, 3)\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "型をとるには、img.dtypeを使用します。\n",
    "uint8とは符号なしintで8ビットを意味します。画像はRGB成分がそれぞれ通常0から255の256段階で表現されます。\n",
    "例えば、赤のピクセルは(R,G,B) = (255, 0, 0)、白は(R,G,B) = (255, 255, 255)です。\n",
    "画像にする時は必ずこの型にしないと画像がおかしくなってしまいます。（あとで説明します。）\n",
    "\n",
    "```bash\n",
    ">>> img.dtype\n",
    "dtype('uint8')\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の表示はcv2.imshow()を使います。\n",
    "cv2.imshow()の第一引数にはウィンドウの名前（特に気にしなくて良い）、第二引数には画像が必要です。\n",
    "\n",
    "cv2.waitKey(0)はキーボードから何かが入力されるまで画像を表示する、という働きがあります。（もっと気になる人は自分で調べて）\n",
    "\n",
    "```bash\n",
    ">>> cv2.imshow('', img); cv2.waitKey(0)\n",
    "102\n",
    ">>> \n",
    "```\n",
    "\n",
    "|表示 (sample1.png)|\n",
    "|:---:|\n",
    "|![](./Tutorial/sample1.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば、imgの型をfloat32にしてみます。\n",
    "これはastype()を使えばできます。\n",
    "\n",
    "```bash\n",
    ">>> _img = img.astype(np.float32)\n",
    "```\n",
    "\n",
    "これを表示すると、こうなります。\n",
    "つまり型がおかしくなるために表示がおかしくなります。（ただし保存はできます。）\n",
    "なので、画像をいじる時は、\n",
    "1. cv2.imreadで読み込む\n",
    "2. 型を**一度np.float32など小数点型に変換する**\n",
    "3. 画像をいじる\n",
    "4. **画素が0未満のものは0, 255を超えたものは255に直す。**（超重要）\n",
    "5. 型を**np.uint8に変換して表示・保存する**\n",
    "この手順にすることをおすすめします。\n",
    "\n",
    "4に関しては次章の「画素をいじる」で紹介します。\n",
    "\n",
    "```bash\n",
    ">>> cv2.imshow('', _img); cv2.waitKey(0)\n",
    "102\n",
    ">>>\n",
    "```\n",
    "|表示 (sample2.png)|\n",
    "|:---:|\n",
    "|![](./Tutorial/sample2.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画素をいじる。\n",
    "\n",
    "画像の操作法はnumpyとほとんど同じです。\n",
    "\n",
    "例えば、x=30、y=20の画素値をいじりたい時は、こうします。\n",
    "画素値はBGRの順に並んでいます。array()とはnumpy形式になっていることを意味します。つまり、OpenCVはnumpyのラッパーです。\n",
    "\n",
    "```bash\n",
    ">>> img[20, 30]\n",
    "array([232, 178, 171], dtype=uint8)\n",
    ">>> \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、x=30、y=20、のG成分をとる時はこうします。\n",
    "\n",
    "```bash\n",
    ">>> img[20, 30, 1]\n",
    "178\n",
    ">>> \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここから、numpyの本題に入っていきます。\n",
    "\n",
    "numpyには**スライス**という機能があります。\n",
    "これはある値v1からある値v2までの全ての要素にアクセスできることを意味します。\n",
    "\n",
    "例えば、y=20, x=[30, 32]までを見る時はこうします。\n",
    "30:33とすれば行列のまま取り出せます。a:bとすることで、a<= v < bの値にアクセスできます。\n",
    "ちなみに :30とすれば [0, 30]、30:とすれば[30, 最後]までを取り出せます。\n",
    "\n",
    "```bash\n",
    ">>> img[20, 30:33]\n",
    "array([[232, 178, 171],\n",
    "[209, 156, 153],\n",
    "[134,  85,  77]], dtype=uint8)\n",
    ">>> \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば画像の左上(x=[0, 50], y = [0, 50])を黒にするには、こんな感じでできます。\n",
    "copy()については次で説明します。\n",
    "\n",
    "```bash\n",
    ">>> img2 = img.copy()\n",
    ">>> img2[:50, :50] = 0\n",
    ">>> cv2.imshow(\"\", img2); cv2.waitKey(0)\n",
    "0\n",
    ">>>\n",
    "```\n",
    "\n",
    "|表示 (sample3.png)|\n",
    "|:---:|\n",
    "|![](./Tutorial/sample3.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に先程の　4. **画素が0未満のものは0, 255を超えたものは255に直す。**　に関して説明します。\n",
    "\n",
    "例えば、画像を一度 float32型にして、一部分のB成分を260という値に変えてみます。\n",
    "uint8型は[0, 255] の範囲しか取り得ないので、これをuint8型に直すとこんな風になります。\n",
    "イモリの顔の一部分が黄色くなってしまっています。\n",
    "\n",
    "**これは、260をuint8型に直すと260 - 256 が起きて、B=4となってしまうためです。**\n",
    "これが原因で画素値がおかしくなることが多々起きてしまいます。\n",
    "なので、4の操作が必要となります。\n",
    "\n",
    "```bash\n",
    ">>> img2 = img.copy().astype(np.float32)\n",
    ">>> img2[60:100, 60:100, 0] = 260\n",
    ">>> cv2.imshow(\"imori\", img2.astype(np.uint8)); cv2.waitKey(0)\n",
    "```\n",
    "\n",
    "|表示 (sample5.png)|\n",
    "|:---:|\n",
    "|![](./Tutorial/sample5.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像のコピー\n",
    "\n",
    "画像を別変数にコピーしたい時はcopy()を使いましょう。\n",
    "\n",
    "```bash\n",
    ">>> img2 = img.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純に img2 = img とすると、画像のアドレスが保存されるのでimg2をいじるとimgにも反映されてしまします。\n",
    "\n",
    "特別な利用がない場合は、**copy()で画像をコピーしましょう**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像の保存\n",
    "\n",
    "保存には cv2.imwrite()を使いましょう。\n",
    "\n",
    "例えば先程のimg2を *sample.jpg* という名前で保存する時はこうしましょう。\n",
    "Trueとなれば保存に成功で、これで同じフォルダ内にsample.jpgというファイルができています。\n",
    "\n",
    "```bash\n",
    ">>> cv2.imwrite(\"sample.jpg\", img2)\n",
    "True\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習\n",
    "\n",
    "画像の左半分上のRとBを入れ替えて表示してみましょう。\n",
    "\n",
    "回答例\n",
    " \n",
    "```bash\n",
    ">>> import cv2\n",
    ">>> img = cv2.imread(\"imori.jpg\")\n",
    ">>> img3 = img.copy()\n",
    ">>> H, W, C = img3.shape\n",
    ">>> img3[:H//2, :W//2] = img3[:H//2, :W//2, (2, 1, 0)]\n",
    ">>> cv2.imshow('', img3); cv2.waitKey(0)\n",
    "102\n",
    ">>> \n",
    "```\n",
    "\n",
    "|表示 (sample4.png)|\n",
    "|:---:|\n",
    "|![](./Tutorial/sample4.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上でチュートリアルは終了です。\n",
    "\n",
    "あとはばんばん問題を解いて下さい！！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 1 - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.1. チャネル入れ替え\n",
    "\n",
    "画像を読み込み、RGBをBGRの順に入れ替えよ。\n",
    "\n",
    "画像の赤成分を取り出すには、以下のコードで可能。\n",
    "cv2.imread()関数ではチャネルがBGRの順になることに注意！\n",
    "これで変数redにimori.jpgの赤成分のみが入る。\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "img = cv2.imread(\"imori.jpg\")\n",
    "red = img[:, :, 2].copy()\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_1.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori.jpg)|![](./Question_01_10/answer_1.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\")\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# RGB > BGR\n",
    "img[:, :, 0] = r\n",
    "img[:, :, 1] = g\n",
    "img[:, :, 2] = b\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", img)\n",
    "cv2.imshow(\"result\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.2. グレースケール化\n",
    "\n",
    "画像をグレースケールにせよ。\n",
    "グレースケールとは、画像の輝度表現方法の一種であり下式で計算される。\n",
    "\n",
    "Y = 0.2126 R + 0.7152 G + 0.0722 B\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_2.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori.jpg)|![](./Question_01_10/answer_2.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Gray scale\n",
    "out = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.3. 二値化\n",
    "\n",
    "画像を二値化せよ。\n",
    "二値化とは、画像を黒と白の二値で表現する方法である。\n",
    "ここでは、グレースケールにおいて閾値を128に設定し、下式で二値化する。\n",
    "\n",
    "```bash\n",
    "y = { 0 (if y < 128)\n",
    "     255 (else) \n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_3.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori.jpg)|![](./Question_01_10/answer_3.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Grayscale\n",
    "out = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Binarization\n",
    "th = 128\n",
    "out[out < th] = 0\n",
    "out[out >= th] = 255\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.4. 大津の二値化\n",
    "\n",
    "大津の二値化を実装せよ。\n",
    "大津の二値化とは判別分析法と呼ばれ、二値化における分離の閾値を自動決定する手法である。\n",
    "これは**クラス内分散**と**クラス間分散**の比から計算される。\n",
    "\n",
    "\n",
    "- 閾値t未満をクラス0, t以上をクラス1とする。\n",
    "- w0, w1 ... 閾値tにより分離された各クラスの画素数の割合 (w0 + w1 = 1を満たす)\n",
    "- S0^2, S1^2 ... 各クラスの画素値の分散\n",
    "- M0, M1 ... 各クラスの画素値の平均値\n",
    "\n",
    "とすると、\n",
    "\n",
    "```bash\n",
    "クラス内分散 Sw^2 = w0 * S0^2 + w1 * S1^2\n",
    "クラス間分散 Sb^2 = w0 * (M0 - Mt)^2 + w1 * (M1 - Mt)^2 = w0 * w1 * (M0 - M1) ^2\n",
    "画像全体の画素の分散 St^2 = Sw^2 + Sb^2 = (const)\n",
    "以上より、分離度は次式で定義される。\n",
    "分離度 X = Sb^2 / Sw^2 = Sb^2 / (St^2 - Sb^2)\n",
    "```\n",
    "\n",
    "となるので、\n",
    "\n",
    "```bash\n",
    "argmax_{t} X = argmax_{t} Sb^2\n",
    "```\n",
    "となる。すなわち、Sb^2 =  w0 * w1 * (M0 - M1) ^2 が最大となる、閾値tを二値化の閾値とすれば良い。\n",
    "\n",
    "|入力 (imori.jpg)|出力 (th = 127) (answer_4.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori.jpg)|![](./Question_01_10/answer_4.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "out = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Determine threshold of Otsu's binarization\n",
    "max_sigma = 0\n",
    "max_t = 0\n",
    "\n",
    "for _t in range(1, 255):\n",
    "    v0 = out[np.where(out < _t)]\n",
    "    m0 = np.mean(v0) if len(v0) > 0 else 0.\n",
    "    w0 = len(v0) / (H * W)\n",
    "    v1 = out[np.where(out >= _t)]\n",
    "    m1 = np.mean(v1) if len(v1) > 0 else 0.\n",
    "    w1 = len(v1) / (H * W)\n",
    "    sigma = w0 * w1 * ((m0 - m1) ** 2)\n",
    "    if sigma > max_sigma:\n",
    "        max_sigma = sigma\n",
    "        max_t = _t\n",
    "\n",
    "# Binarization\n",
    "print(\"threshold >>\", max_t)\n",
    "th = max_t\n",
    "out[out < th] = 0\n",
    "out[out >= th] = 255\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.5. HSV変換\n",
    "\n",
    "HSV変換を実装して、色相Hを反転せよ。\n",
    "\n",
    "HSV変換とは、**Hue(色相)**、**Saturation(彩度)**、**Value(明度)** で色を表現する手法である。\n",
    "\n",
    "- Hue ... 色合いを0~360度で表現し、赤や青など色の種類を示す。 ( 0 <= H < 360) 色相は次の色に対応する。\n",
    "\n",
    "```bash\n",
    "赤 黄色  緑  水色  青  紫   赤\n",
    "0  60  120  180 240 300 360\n",
    "```\n",
    "\n",
    "- Saturation ... 色の鮮やかさ。Saturationが低いと灰色さが顕著になり、くすんだ色となる。 ( 0<= S < 1)\n",
    "- Value ... 色の明るさ。Valueが高いほど白に近く、Valueが低いほど黒に近くなる。 ( 0 <= V < 1)\n",
    "\n",
    "RGB -> HSV変換は以下の式で定義される。\n",
    "\n",
    "R,G,Bが[0, 1]の範囲にあるとする。\n",
    "\n",
    "```bash\n",
    "Max = max(R,G,B)\n",
    "Min = min(R,G,B)\n",
    "\n",
    "H =  { 0                            (if Min=Max)\n",
    "       60 x (G-R) / (Max-Min) + 60  (if Min=B)\n",
    "       60 x (B-G) / (Max-Min) + 180 (if Min=R)\n",
    "       60 x (R-B) / (Max-Min) + 300 (if Min=G)\n",
    "       \n",
    "V = Max\n",
    "\n",
    "S = Max - Min\n",
    "```\n",
    "\n",
    "HSV -> RGB変換は以下の式で定義される。\n",
    "\n",
    "```bash\n",
    "C = S\n",
    "\n",
    "H' = H / 60\n",
    "\n",
    "X = C (1 - |H' mod 2 - 1|)\n",
    "\n",
    "(R,G,B) = (V - C) (1,1,1) + { (0, 0, 0)  (if H is undefined)\n",
    "                              (C, X, 0)  (if 0 <= H' < 1)\n",
    "                              (X, C, 0)  (if 1 <= H' < 2)\n",
    "                              (0, C, X)  (if 2 <= H' < 3)\n",
    "                              (0, X, C)  (if 3 <= H' < 4)\n",
    "                              (X, 0, C)  (if 4 <= H' < 5)\n",
    "                              (C, 0, X)  (if 5 <= H' < 6)\n",
    "```\n",
    "ここでは色相Hを反転(180を加算)し、RGBに直し画像を表示せよ。\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_5.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori.jpg)|![](./Question_01_10/answer_5.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32) / 255.\n",
    "\n",
    "# RGB > HSV\n",
    "out = np.zeros_like(img)\n",
    "\n",
    "max_v = np.max(img, axis=2).copy()\n",
    "min_v = np.min(img, axis=2).copy()\n",
    "min_arg = np.argmin(img, axis=2)\n",
    "\n",
    "H = np.zeros_like(max_v)\n",
    "\n",
    "H[np.where(max_v == min_v)] = 0\n",
    "## if min == B\n",
    "ind = np.where(min_arg == 0)\n",
    "H[ind] = 60 * (img[..., 1][ind] - img[..., 2][ind]) / (max_v[ind] - min_v[ind]) + 60\n",
    "## if min == R\n",
    "ind = np.where(min_arg == 2)\n",
    "H[ind] = 60 * (img[..., 0][ind] - img[..., 1][ind]) / (max_v[ind] - min_v[ind]) + 180\n",
    "## if min == G\n",
    "ind = np.where(min_arg == 1)\n",
    "H[ind] = 60 * (img[..., 2][ind] - img[..., 0][ind]) / (max_v[ind] - min_v[ind]) + 300\n",
    "    \n",
    "V = max_v.copy()\n",
    "S = max_v.copy() - min_v.copy()\n",
    "\n",
    "# Transpose Hue\n",
    "H = (H + 180) % 360\n",
    "\n",
    "# HSV > RGB\n",
    "\n",
    "C = S\n",
    "H_ = H / 60\n",
    "X = C * (1 - np.abs( H_ % 2 - 1))\n",
    "Z = np.zeros_like(H)\n",
    "\n",
    "vals = [[Z,X,C], [Z,C,X], [X,C,Z], [C,X,Z], [C,Z,X], [X,Z,C]]\n",
    "\n",
    "for i in range(6):\n",
    "    ind = np.where((i <= H_) & (H_ < (i+1)))\n",
    "    out[..., 0][ind] = (V-C)[ind] + vals[i][0][ind]\n",
    "    out[..., 1][ind] = (V-C)[ind] + vals[i][1][ind]\n",
    "    out[..., 2][ind] = (V-C)[ind] + vals[i][2][ind]\n",
    "\n",
    "out[np.where(max_v == min_v)] = 0\n",
    "out = (out * 255).astype(np.uint8) \n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.6. 減色処理\n",
    "\n",
    "ここでは画像の値を256^3から4^3、すなわちR,G,B in {32, 96, 160, 224}の各4値に減色せよ。\n",
    "これは量子化操作である。\n",
    "各値に関して、以下の様に定義する。\n",
    "\n",
    "```bash\n",
    "val = {  32  (0 <= val < 63)\n",
    "         96  (63 <= val < 127)\n",
    "        160  (127 <= val < 191)\n",
    "        224  (191 <= val < 256)\n",
    "```\n",
    "|入力 (imori.jpg)|出力 (answer_6.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori.jpg)|![](./Question_01_10/answer_6.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\")\n",
    "\n",
    "# Dicrease color\n",
    "out = img.copy()\n",
    "\n",
    "out = out // 64 * 64 + 32\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.7. 平均プーリング\n",
    "\n",
    "ここでは画像をグリッド分割(ある固定長の領域に分ける)し、かく領域内(セル)の平均値でその領域内の値を埋める。\n",
    "このようにグリッド分割し、その領域内の代表値を求める操作は**Pooling(プーリング)** と呼ばれる。\n",
    "これらプーリング操作は**CNN(Convolutional Neural Network)** において重要な役割を持つ。\n",
    "\n",
    "これは次式で定義される。\n",
    "\n",
    "```bash\n",
    "v = 1/|R| * Sum_{i in R} v_i\n",
    "```\n",
    "\n",
    "ここではimori.jpgは128x128なので、8x8にグリッド分割し、平均プーリングせよ。\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_7.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori.jpg)|![](./Question_01_10/answer_7.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\")\n",
    "\n",
    "# Average Pooling\n",
    "out = img.copy()\n",
    "\n",
    "H, W, C = img.shape\n",
    "G = 8\n",
    "Nh = int(H / G)\n",
    "Nw = int(W / G)\n",
    "\n",
    "for y in range(Nh):\n",
    "    for x in range(Nw):\n",
    "        for c in range(C):\n",
    "            out[G*y:G*(y+1), G*x:G*(x+1), c] = np.mean(out[G*y:G*(y+1), G*x:G*(x+1), c]).astype(np.int)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.8. Maxプーリング\n",
    "\n",
    "ここでは平均値でなく最大値でプーリングせよ。\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_8.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori.jpg)|![](./Question_01_10/answer_8.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\")\n",
    "\n",
    "# Max Pooling\n",
    "out = img.copy()\n",
    "\n",
    "H, W, C = img.shape\n",
    "G = 8\n",
    "Nh = int(H / G)\n",
    "Nw = int(W / G)\n",
    "\n",
    "for y in range(Nh):\n",
    "    for x in range(Nw):\n",
    "        for c in range(C):\n",
    "            out[G*y:G*(y+1), G*x:G*(x+1), c] = np.max(out[G*y:G*(y+1), G*x:G*(x+1), c])\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.9. ガウシアンフィルタ\n",
    "\n",
    "ガウシアンフィルタ(3x3、標準偏差1.3)を実装し、*imori_noise.jpg*のノイズを除去せよ。\n",
    "\n",
    "ガウシアンフィルタとは画像の**平滑化**（滑らかにする）を行うフィルタの一種であり、**ノイズ除去**にも使われる。\n",
    "\n",
    "ノイズ除去には他にも、メディアンフィルタ(Q.10)、平滑化フィルタ(Q.11)、LoGフィルタ(Q.19)などがある。\n",
    "\n",
    "ガウシアンフィルタは注目画素の周辺画素を、ガウス分布による重み付けで平滑化し、次式で定義される。\n",
    "このような重みは**カーネル**や**フィルタ**と呼ばれる。\n",
    "\n",
    "ただし、画像の端はこのままではフィルタリングできないため、画素が足りない部分は0で埋める。これを**0パディング**と呼ぶ。\n",
    "かつ、重みは正規化する。(sum g = 1)\n",
    "\n",
    "```bash\n",
    "重み g(x,y,s) = 1/ (s*sqrt(2 * pi)) * exp( - (x^2 + y^2) / (2*s^2))\n",
    "標準偏差s = 1.3による8近傍ガウシアンフィルタは\n",
    "            1 2 1\n",
    "K =  1/16 [ 2 4 2 ]\n",
    "            1 2 1\n",
    "```\n",
    "\n",
    "|入力 (imori_noise.jpg)|出力 (answer_9.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori_noise.jpg)|![](./Question_01_10/answer_9.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori_noise.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 3\n",
    "sigma = 1.3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2, C), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = img.copy().astype(np.float)\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = np.exp( -(x**2 + y**2) / (2* (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        for c in range(C):\n",
    "            out[pad+y, pad+x, c] = np.sum(K * out[y:y+K_size, x:x+K_size, c])\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.10 メディアンフィルタ\n",
    "\n",
    "メディアンフィルタ(3x3)を実装し、*imori_noise.jpg*のノイズを除去せよ。\n",
    "\n",
    "メディアンフィルタとは画像の平滑化を行うフィルタの一種である。\n",
    "\n",
    "これは注目画素の3x3の領域内の、メディアン値(中央値)を出力するフィルタである。\n",
    "これもゼロパディングせよ。\n",
    "\n",
    "|入力 (imori_noise.jpg)|出力 (answer_10.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_01_10/imori_noise.jpg)|![](./Question_01_10/answer_10.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori_noise.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "\n",
    "# Median Filter\n",
    "K_size = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2, C), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = img.copy().astype(np.float)\n",
    "\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        for c in range(C):\n",
    "            out[pad+y, pad+x, c] = np.median(out[y:y+K_size, x:x+K_size, c])\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.11 - 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.11. 平滑化フィルタ\n",
    "\n",
    "平滑化フィルタ(3x3)を実装せよ。\n",
    "\n",
    "平滑化フィルタはフィルタ内の画素の平均値を出力するフィルタである。\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_11.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_11.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "\n",
    "# Median Filter\n",
    "K_size = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2, C), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = img.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        for c in range(C):\n",
    "            out[pad+y, pad+x, c] = np.mean(tmp[y:y+K_size, x:x+K_size, c])\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.12. モーションフィルタ\n",
    "\n",
    "モーションフィルタ(3x3)を実装せよ。\n",
    "\n",
    "モーションフィルタとは対角方向の平均値を取るフィルタであり、次式で定義される。\n",
    "\n",
    "```bash\n",
    "  1/3  0   0\n",
    "[  0  1/3  0 ]\n",
    "   0   0  1/3\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_12.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_12.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "\n",
    "# Median Filter\n",
    "K_size = 3\n",
    "\n",
    "K = np.diag( [1] * K_size ).astype(np.float)\n",
    "K /= K_size\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2, C), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = img.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        for c in range(C):\n",
    "            out[pad+y, pad+x, c] = np.sum(K * tmp[y:y+K_size, x:x+K_size, c])\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.13. MAX-MINフィルタ\n",
    "\n",
    "MAX-MIJフィルタ(3x3)を実装せよ。\n",
    "\n",
    "MAX-MINフィルタとはフィルタ内の画素の最大値と最小値の差を出力するフィルタであり、**エッジ検出**のフィルタの一つである。\n",
    "エッジ検出とは画像内の線を検出るすることであり、このような画像内の情報を抜き出す操作を**特徴抽出**と呼ぶ。\n",
    "エッジ検出では多くの場合、グレースケール画像に対してフィルタリングを行う。\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_13.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_13.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# Max-Min Filter\n",
    "K_size = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        out[pad+y, pad+x] = np.max(tmp[y:y+K_size, x:x+K_size]) - np.min(tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.14. 微分フィルタ\n",
    "\n",
    "微分フィルタ(3x3)を実装せよ。\n",
    "\n",
    "微分フィルタは輝度の急激な変化が起こっている部分のエッジを取り出すフィルタであり、隣り合う画素同士の差を取る。\n",
    "\n",
    "```bash\n",
    "    (a)縦方向         (b)横方向\n",
    "      0 -1  0            0 0 0\n",
    "K = [ 0  1  0 ]   K = [ -1 1 0 ]\n",
    "      0  0  0            0 0 0\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力・縦方向 (answer_14_v.jpg)|出力・横方向 (answer_14_h.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_14_v.jpg)|![](./Question_11_20/answer_14_h.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# sobel Filter\n",
    "K_size = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "## Sobel vertical\n",
    "#K = [[0., -1., 0.],[0., 1., 0.],[0., 0., 0.]]\n",
    "## Sobel horizontal\n",
    "K = [[0., 0., 0.],[-1., 1., 0.], [0., 0., 0.]]\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        out[pad+y, pad+x] = np.mean(K * (tmp[y:y+K_size, x:x+K_size]))\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.15. Sobelフィルタ\n",
    "\n",
    "Sobelフィルタ(3x3)を実装せよ。\n",
    "\n",
    "ソーベルフィルタ(Sobelフィルタ)は特定方向（縦や横）のエッジのみを抽出するフィルタであり、次式でそれぞれ定義される。\n",
    "\n",
    "```bash\n",
    "    (a)縦方向       (b)横方向\n",
    "      1 0 -1            1  2  1\n",
    "K = [ 2 0 -2 ]   K = [  0  0  0 ]\n",
    "      1 0 -1           -1 -2 -1\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力・縦方向 (answer_15_v.jpg)|出力・横方向 (answer_15_h.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_15_v.jpg)|![](./Question_11_20/answer_15_h.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# sobel Filter\n",
    "K_size = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "## Sobel vertical\n",
    "K = [[1., 0., -1.],[2., 0., -2.],[1., 0., -1.]]\n",
    "## Sobel horizontal\n",
    "#K = [[1., 2., 1.],[0., 0., 0.], [-1., -2., -1.]]\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        out[pad+y, pad+x] = np.mean(K * (tmp[y:y+K_size, x:x+K_size]))\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.16. Prewittフィルタ\n",
    "\n",
    "Prewittフィルタ(3x3)を実装せよ。\n",
    "\n",
    "Prewittフィルタはエッジ抽出フィルタの一種であり、次式で定義される。\n",
    "\n",
    "```bash\n",
    "    (a)縦方向          (b)横方向\n",
    "      -1 -1 -1          -1 0 1\n",
    "K = [  0  0  0 ]  K = [ -1 0 1 ]\n",
    "       1  1  1          -1 0 1\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力・縦方向 (answer_16_v.jpg)|出力・横方向 (answer_16_h.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_16_v.jpg)|![](./Question_11_20/answer_16_h.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# sobel Filter\n",
    "K_size = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "## Sobel vertical\n",
    "#K = [[1., 0., -1.],[1., 0., -1.],[1., 0., -1.]]\n",
    "## Sobel horizontal\n",
    "K = [[-1., -1., -1.],[0., 0., 0.], [1., 1., 1.]]\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        out[pad+y, pad+x] = np.mean(K * (tmp[y:y+K_size, x:x+K_size]))\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.17. Laplacianフィルタ\n",
    "\n",
    "Laplacianフィルタを実装せよ。\n",
    "\n",
    "Laplacian（ラプラシアン）フィルタとは輝度の二次微分をとることでエッジ検出を行うフィルタである。\n",
    "\n",
    "デジタル画像は離散データであるので、x方向・y方向の一次微分は、それぞれ次式で表される。\n",
    "\n",
    "```bash\n",
    "Ix(x,y) = (I(x+1, y) - I(x,y)) / ((x+1)-x) = I(x+1, y) - I(x,y)\n",
    "Iy(x,y) = (I(x, y+1) - I(x,y)) / ((y+1)-y) = I(x, y+1) - I(x,y)\n",
    "```\n",
    "\n",
    "さらに二次微分は、次式で表される。\n",
    "\n",
    "```bash\n",
    "Ixx(x,y) = (Ix(x,y) - Ix(x-1,y)) / ((x+1)-x) = Ix(x,y) - Ix(x-1,y)\n",
    "         = (I(x+1, y) - I(x,y)) - (I(x, y) - I(x-1,y))\n",
    "         = I(x+1,y) - 2 * I(x,y) + I(x-1,y)\n",
    "Iyy(x,y) = ... = I(x,y+1) - 2 * I(x,y) + I(x,y-1)\n",
    "```\n",
    "\n",
    "これらより、ラプラシアン は次式で定義される。\n",
    "\n",
    "```bash\n",
    "D^2 I(x,y) = Ixx(x,y) + Iyy(x,y)\n",
    "           = I(x-1,y) + I(x,y-1) - 4 * I(x,y) + I(x+1,y) + I(x,y+1)\n",
    "```\n",
    "\n",
    "これをカーネル化すると、次のようになる。\n",
    "\n",
    "```bash\n",
    "      0  1  0\n",
    "K = [ 1 -4  1 ]\n",
    "      0  1  0\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力(answer_17.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_17.jpg)||\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# sobel Filter\n",
    "K_size = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "## Laplacian vertical\n",
    "K = [[0., 1., 0.],[1., -4., 1.], [0., 1., 0.]]\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        out[pad+y, pad+x] = np.mean(K * (tmp[y:y+K_size, x:x+K_size]))\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.18. Embossフィルタ\n",
    "\n",
    "Embossフィルタを実装せよ。\n",
    "\n",
    "Embossフィルタとは輪郭部分を浮き出しにするフィルタで、次式で定義される。\n",
    "\n",
    "```bash\n",
    "      -2 -1  0\n",
    "K = [ -1  1  1 ]\n",
    "       0  1  2\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力(answer_18.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_18.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# sobel Filter\n",
    "K_size = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "## Emboss vertical\n",
    "K = [[-2., -1., 0.],[-1., 1., 1.], [0., 1., 2.]]\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        out[pad+y, pad+x] = np.sum(K * (tmp[y:y+K_size, x:x+K_size]))\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.19. LoGフィルタ\n",
    "\n",
    "LoGフィルタ(s=3)を実装し、*imori_noise.jpg*のエッジを検出せよ。\n",
    "\n",
    "LoGフィルタとはLaplacian of Gaussianであり、ガウシアンフィルタで画像を平滑化した後にラプラシアンフィルタで輪郭を取り出すフィルタである。\n",
    "\n",
    "Laplcianフィルタは二次微分をとるのでノイズが強調されるのを防ぐために、予めGaussianフィルタでノイズを抑える。\n",
    "\n",
    "LoGフィルタは次式で定義される。\n",
    "\n",
    "```bash\n",
    "LoG(x,y) = (x^2 + y^2 - s^2) / (2 * pi * s^6) * exp(-(x^2+y^2) / (2*s^2))\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_19.jpg) |\n",
    "|:---:|:---:|\n",
    "|![](./Question_11_20/imori.jpg)|![](./Question_11_20/answer_19.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori_noise.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "b = img[:, :, 0].copy()\n",
    "g = img[:, :, 1].copy()\n",
    "r = img[:, :, 2].copy()\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * r + 0.7152 * g + 0.0722 * b\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 5\n",
    "s = 3\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "out = np.zeros((H + pad*2, W + pad*2), dtype=np.float)\n",
    "out[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float)\n",
    "tmp = out.copy()\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = (x**2 + y**2 - s**2) * np.exp( -(x**2 + y**2) / (2* (s**2)))\n",
    "K /= (2 * np.pi * (s**6))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        out[pad+y, pad+x] = np.sum(K * tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.20. ヒストグラム表示\n",
    "\n",
    "matplotlibを用いて*imori_dark.jpg*のヒストグラムを表示せよ。\n",
    "\n",
    "ヒストグラムとは画素の出現回数をグラフにしたものである。\n",
    "matplotlibではhist()という関数がすでにあるので、それを利用する。\n",
    "\n",
    "|入力 (imori_dark.jpg)|出力 (answer_20.png) |\n",
    "|:---:|:---:|\n",
    "|![](./Question_11_20/imori_dark.jpg)|![](./Question_11_20/answer_20.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori_dark.jpg\").astype(np.float)\n",
    "\n",
    "# Display histogram\n",
    "plt.hist(img.ravel(), bins=255, rwidth=0.8, range=(0, 255))\n",
    "plt.savefig(\"out.png\")\n",
    "plt.show()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 21 - 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.21. ヒストグラム正規化\n",
    "\n",
    "ヒストグラム正規化を実装せよ。\n",
    "\n",
    "ヒストグラムは偏りを持っていることが伺える。\n",
    "例えば、0に近い画素が多ければ画像は全体的に暗く、255に近い画素が多ければ画像は明るくなる。\n",
    "ヒストグラムが局所的に偏っていることを**ダイナミックレンジが狭い**などと表現する。\n",
    "そのため画像を人の目に見やすくするために、ヒストグラムを正規化したり平坦化したりなどの処理が必要である。\n",
    "\n",
    "このヒストグラム正規化は**濃度階調変換(glay-scale transformation)** と呼ばれ、[c,d]の画素値を持つ画像を[a,b]のレンジに変換する場合は次式で実現できる。\n",
    "今回は*imori_dark.jpg*を[0, 255]のレンジにそれぞれ変換する。\n",
    "\n",
    "```bash\n",
    "xout = {  a                         (xin < c)\n",
    "         (b-a)/(d-c) * (xin-c) + a  (c <= xin <= d)\n",
    "          b                         (d < xin)\n",
    "```\n",
    "\n",
    "|入力 (imori_dark.jpg)|出力 (answer_21_1.jpg) |ヒストグラム(answer_21_2.png)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_21_30/imori_dark.jpg)|![](./Question_21_30/answer_21_1.jpg)|![](./Question_21_30/answer_21_2.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori_dark.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Trans [0, 255]\n",
    "a, b = 0., 255.\n",
    "\n",
    "vmin = img.min()\n",
    "vmax = img.max()\n",
    "\n",
    "out = img.copy()\n",
    "out[out<a] = a\n",
    "out[out>b] = b\n",
    "out = (b-a) / (vmax - vmin) * (out - vmin) + a\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Display histogram\n",
    "plt.hist(out.ravel(), bins=255, rwidth=0.8, range=(0, 255))\n",
    "plt.savefig(\"out_his.png\")\n",
    "plt.show()\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.22. ヒストグラム操作\n",
    "\n",
    "ヒストグラムの平均値をm0=128、標準偏差をs0=52になるように操作せよ。\n",
    "\n",
    "これはヒストグラムのダイナミックレンジを変更するのではなく、ヒストグラムを平坦に変更する操作である。\n",
    "\n",
    "平均値m、標準偏差s、のヒストグラムを平均値m0, 標準偏差s0に変更するには、次式によって変換する。\n",
    "\n",
    "```bash\n",
    "xout = s0 / s * (xin - m) + m0\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_22_1.jpg) |ヒストグラム(answer_22_2.png)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_21_30/imori.jpg)|![](./Question_21_30/answer_22_1.jpg)|![](./Question_21_30/answer_22_2.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori_dark.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Trans [0, 255]\n",
    "m0 = 128\n",
    "s0 = 52\n",
    "\n",
    "m = np.mean(img)\n",
    "s = np.std(img)\n",
    "\n",
    "out = img.copy()\n",
    "out = s0 / s * (out - m) + m0\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Display histogram\n",
    "plt.hist(out.ravel(), bins=255, rwidth=0.8, range=(0, 255))\n",
    "plt.savefig(\"out_his.png\")\n",
    "plt.show()\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.23. ヒストグラム平坦化\n",
    "\n",
    "ヒストグラム平坦化を実装せよ。\n",
    "\n",
    "ヒストグラム平坦化とはヒストグラムを平坦に変更する操作であり、上記の平均値や標準偏差などを必要とせず、ヒストグラム値を均衡にする操作である。\n",
    "\n",
    "これは次式で定義される。\n",
    "ただし、S ... 画素値の総数、Zmax ... 画素値の最大値、h(z) ... 濃度zの度数\n",
    "\n",
    "```bash\n",
    "Z' = Zmax / S * Sum{i=0:z} h(z)\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_23_1.jpg) |ヒストグラム(answer_23_2.png)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_21_30/imori.jpg)|![](./Question_21_30/answer_23_1.jpg)|![](./Question_21_30/answer_23_2.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Histogram flattening\n",
    "S = H * W * C * 1.\n",
    "\n",
    "out = img.copy()\n",
    "\n",
    "sum_h = 0.\n",
    "z_max = 255.\n",
    "\n",
    "for i in range(1, 255):\n",
    "    ind = np.where(img == i)\n",
    "    sum_h += len(img[ind])\n",
    "    z_prime = z_max / S * sum_h\n",
    "    out[ind] = z_prime\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Display histogram\n",
    "plt.hist(out.ravel(), bins=255, rwidth=0.8, range=(0, 255))\n",
    "plt.savefig(\"out_his.png\")\n",
    "plt.show()\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.24. ガンマ補正\n",
    "\n",
    "*imori_gamma.jpg*に対してガンマ補正(c=1, g=2.2)を実行せよ。\n",
    "\n",
    "ガンマ補正とは、カメラなどの媒体の経由によって画素値が非線形的に変換された場合の補正である。\n",
    "ディスプレイなどで画像をそのまま表示すると画面が暗くなってしまうため、RGBの値を予め大きくすることで、ディスプレイの特性を排除した画像表示を行うことがガンマ補正の目的である。\n",
    "\n",
    "非線形変換は次式で起こるとされる。\n",
    "ただしxは[0,1]に正規化されている。\n",
    "c ... 定数、g ... ガンマ特性(通常は2.2)\n",
    "\n",
    "```bash\n",
    "x' = c * Iin ^ g\n",
    "```\n",
    "\n",
    "そこで、ガンマ補正は次式で行われる。\n",
    "\n",
    "```bash\n",
    "Iout = (1/c * Iin) ^ (1/g)\n",
    "```\n",
    "\n",
    "![](./Question_21_30/question_24_1.jpg) ![](./Question_21_30/question_24_2.jpg)\n",
    "\n",
    "|入力 (imori_gamma.jpg)|出力 (answer_24.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_21_30/imori_gamma.jpg)|![](./Question_21_30/answer_24.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori_gamma.jpg\").astype(np.float)\n",
    "\n",
    "# Gammma correction\n",
    "c = 1.\n",
    "g = 2.2\n",
    "\n",
    "out = img.copy()\n",
    "out /= 255.\n",
    "out = (1/c * out) ** (1/g)\n",
    "\n",
    "out *= 255\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.25. 最近傍補間\n",
    "\n",
    "最近傍補間により画像を1.5倍に拡大せよ。\n",
    "\n",
    "最近傍補間(Nearest Neighbor)は画像の拡大時に最近傍にある画素をそのまま使う手法である。\n",
    "シンプルで処理速度が速いが、画質の劣化は著しい。\n",
    "\n",
    "次式で補間される。\n",
    "I' ... 拡大後の画像、 I ... 拡大前の画像、a ... 拡大率、[ ] ... 四捨五入\n",
    "\n",
    "```bash\n",
    "I'(x,y) = I([x/a], [y/a])\n",
    "```\n",
    "|入力 (imori.jpg)|出力 (answer_25.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_21_30/imori.jpg)|![](./Question_21_30/answer_25.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "\n",
    "# Nearest Neighbor\n",
    "a = 1.5\n",
    "aH = int(a * H)\n",
    "aW = int(a * W)\n",
    "\n",
    "y = np.arange(aH).repeat(aW).reshape(aW, -1)\n",
    "x = np.tile(np.arange(aW), (aH, 1))\n",
    "y = np.round(y / a).astype(np.int)\n",
    "x = np.round(x / a).astype(np.int)\n",
    "\n",
    "out = img[y,x]\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.26. Bi-linear補間\n",
    "\n",
    "Bi-linear補間により画像を1.5倍に拡大せよ。\n",
    "\n",
    "Bi-linear補間とは周辺の４画素に距離に応じた重みをつけることで補完する手法である。\n",
    "計算量が多いだけ処理時間がかかるが、画質の劣化を抑えることができる。\n",
    "\n",
    "1. 拡大画像の座標(x', y')を拡大率aで割り、floor(x'/a, y'/a)を求める。\n",
    "2. 元画像の(x'/a, y'/a)の周囲4画素、I(x,y), I(x+1,y), I(x,y+1), I(x+1, y+1)を求める\n",
    "\n",
    "```bash\n",
    "I(x,y)    I(x+1,y) \n",
    "     * (x'/a,y'/a)\n",
    "I(x,y+1)  I(x+1,y+1)\n",
    "```\n",
    "\n",
    "3. それぞれの画素と(x'/a, y'/a)との距離dを求め、重み付けする。 w = d / Sum d\n",
    "4. 次式によって拡大画像の画素(x',y')を求める。 \n",
    "dx = x'/a - x , dy = y'/a - y\n",
    "```bash\n",
    "I'(x',y') = (1-dx)(1-dy)I(x,y) + dx(1-dy)I(x+1,y) + (1-dx)dyI(x,y+1) + dxdyI(x+1,y+1)\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_26.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_21_30/imori.jpg)|![](./Question_21_30/answer_26.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float)\n",
    "H, W, C = img.shape\n",
    "\n",
    "\n",
    "# Bi-lenear\n",
    "a = 1.5\n",
    "aH = int(a * H)\n",
    "aW = int(a * W)\n",
    "\n",
    "y = np.arange(aH).repeat(aW).reshape(aW, -1)\n",
    "x = np.tile(np.arange(aW), (aH, 1))\n",
    "y = (y / a)\n",
    "x = (x / a)\n",
    "\n",
    "ix = np.floor(x).astype(np.int)\n",
    "iy = np.floor(y).astype(np.int)\n",
    "\n",
    "ix = np.minimum(ix, W-2)\n",
    "iy = np.minimum(iy, H-2)\n",
    "\n",
    "dx = x - ix\n",
    "dy = y - iy\n",
    "\n",
    "dx = np.repeat(np.expand_dims(dx, axis=-1), 3, axis=-1)\n",
    "dy = np.repeat(np.expand_dims(dy, axis=-1), 3, axis=-1)\n",
    "\n",
    "\n",
    "out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "\n",
    "out[out>255] = 255\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.27. Bi-cubic補間\n",
    "\n",
    "Bi-cubic補間により画像を1.5倍に拡大せよ。\n",
    "\n",
    "Bi-cubic補間とはBi-linear補間の拡張であり、周辺の16画素から補間を行う。\n",
    "\n",
    "```bash\n",
    "I(x-1,y-1)  I(x,y-1)  I(x+1,y-1)  I(x+2,y-1)\n",
    "I(x-1,y)    I(x,y)    I(x+1,y)    I(x+2,y)\n",
    "I(x-1,y+1)  I(x,y+1)  I(x+1,y+1)  I(x+2,y+1)\n",
    "I(x-1,y+2)  I(x,y+2)  I(x+1,y+2)  I(x+2,y+2)\n",
    "```\n",
    "\n",
    "それぞれの画素との距離は次式の様に決定される。\n",
    "\n",
    "```bash\n",
    "dx1 = x'/a - (x-1) , dx2 = x'/a - x , dx3 = (x+1) - x'/a , dx2 = (x+2) - x'/a\n",
    "dy1 = y'/a - (y-1) , dy2 = y'/a - y , dy3 = (y+1) - y'/a , dy2 = (y+2) - y'/a\n",
    "```\n",
    "\n",
    "重みは距離によって次の関数により決定される。\n",
    "a は多くの場合-1となる。\n",
    "\n",
    "```bash\n",
    "h(t) = { (a+2)|t|^3 - (a+3)|t|^2 + 1    (when |t|<=1)\n",
    "         a|t|^3 - 5a|t|^2 + 8a|t| - 4a  (when 1<|t|<=2)\n",
    "         0                              (when 2<|t|) \n",
    "```\n",
    "\n",
    "これら画素と重みを用いて、次式で拡大画像の画素が計算される。\n",
    "それぞれの画素と重みを掛けた和を重みの和で割る。\n",
    "\n",
    "```bash\n",
    "I'(x', y') = (Sum{i=-1:2}{j=-1:2} I(x+i,y+j) * wxi * wyj) / Sum{i=-1:2}{j=-1:2} wxi * wyj\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_27.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_21_30/imori.jpg)|![](./Question_21_30/answer_27.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "\n",
    "# Bi-cubic\n",
    "a = 1.5\n",
    "aH = int(a * H)\n",
    "aW = int(a * W)\n",
    "\n",
    "y = np.arange(aH).repeat(aW).reshape(aW, -1)\n",
    "x = np.tile(np.arange(aW), (aH, 1))\n",
    "y = (y / a)\n",
    "x = (x / a)\n",
    "\n",
    "ix = np.floor(x).astype(np.int)\n",
    "iy = np.floor(y).astype(np.int)\n",
    "\n",
    "ix = np.minimum(ix, W-1)\n",
    "iy = np.minimum(iy, H-1)\n",
    "\n",
    "dx2 = x - ix\n",
    "dy2 = y - iy\n",
    "dx1 = dx2 + 1\n",
    "dy1 = dy2 + 1\n",
    "dx3 = 1 - dx2\n",
    "dy3 = 1 - dy2\n",
    "dx4 = 1 + dx3\n",
    "dy4 = 1 + dy3\n",
    "\n",
    "dxs = [dx1, dx2, dx3, dx4]\n",
    "dys = [dy1, dy2, dy3, dy4]\n",
    "\n",
    "def weight(t):\n",
    "    a = -1.\n",
    "    at = np.abs(t)\n",
    "    w = np.zeros_like(t)\n",
    "    ind = np.where(at <= 1)\n",
    "    w[ind] = ((a+2) * np.power(at, 3) - (a+3) * np.power(at, 2) + 1)[ind]\n",
    "    ind = np.where((at > 1) & (at <= 2))\n",
    "    w[ind] = (a*np.power(at, 3) - 5*a*np.power(at, 2) + 8*a*at - 4*a)[ind]\n",
    "    return w\n",
    "\n",
    "w_sum = np.zeros((aH, aW, C), dtype=np.float32)\n",
    "out = np.zeros((aH, aW, C), dtype=np.float32)\n",
    "\n",
    "for j in range(-1, 3):\n",
    "    for i in range(-1, 3):\n",
    "        ind_x = np.minimum(np.maximum(ix + i, 0), W-1)\n",
    "        ind_y = np.minimum(np.maximum(iy + j, 0), H-1)\n",
    "\n",
    "        wx = weight(dxs[i+1])\n",
    "        wy = weight(dys[j+1])\n",
    "        wx = np.repeat(np.expand_dims(wx, axis=-1), 3, axis=-1)\n",
    "        wy = np.repeat(np.expand_dims(wy, axis=-1), 3, axis=-1)\n",
    "\n",
    "        w_sum += wx * wy\n",
    "        out += wx * wy * img[ind_y, ind_x]\n",
    "\n",
    "out /= w_sum\n",
    "out[out>255] = 255\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.28. アフィン変換(平行移動)\n",
    "\n",
    "アフィン変換を利用して画像をx方向に+30、y方向に-30だけ平行移動させよ。\n",
    "\n",
    "アフィン変換とは3x3の行列を用いて画像の変換を行う操作である。\n",
    "\n",
    "変換は(1)平行移動(Q.28) (2)拡大縮小(Q.29) (3)回転(Q.30) (4)スキュー(Q.31) がある。\n",
    "\n",
    "元画像を(x,y)、変換後の画像を(x',y')とする。\n",
    "画像の拡大縮小は、次式で表される。\n",
    "\n",
    "```bash\n",
    "[ x' ] = [a b][x]\n",
    "  y'      c d  y\n",
    "```\n",
    "\n",
    "一方、平行移動は次式となる。\n",
    "\n",
    "```bash\n",
    "[ x' ] = [x] + [tx]\n",
    "  y'      y  +  ty\n",
    "```\n",
    "\n",
    "以上を一つの式にまとめると、次式になり、これがアフィン変換である。\n",
    "\n",
    "```bash\n",
    "  x'       a b tx    x\n",
    "[ y' ] = [ c d ty ][ y ]\n",
    "  1        0 0  1    1\n",
    "```\n",
    "\n",
    "平行移動では次式を用いる。\n",
    "\n",
    "```bash\n",
    "  x'       1 0 tx    x\n",
    "[ y' ] = [ 0 1 ty ][ y ]\n",
    "  1        0 0  1    1\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_28.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_21_30/imori.jpg)|![](./Question_21_30/answer_28.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "\n",
    "# Affine\n",
    "a = 1.\n",
    "b = 0.\n",
    "c = 0.\n",
    "d = 1.\n",
    "tx = 30\n",
    "ty = -30\n",
    "\n",
    "y = np.arange(H).repeat(W).reshape(W, -1)\n",
    "x = np.tile(np.arange(W), (H, 1))\n",
    "\n",
    "out = np.zeros((H+1, W+1, C), dtype=np.float32)\n",
    "\n",
    "x_new = a * x + b * y + tx\n",
    "y_new = c * x + d * y + ty\n",
    "\n",
    "x_new = np.minimum(np.maximum(x_new, 0), W).astype(np.int)\n",
    "y_new = np.minimum(np.maximum(y_new, 0), H).astype(np.int)\n",
    "\n",
    "out[y_new, x_new] = img[y, x]\n",
    "out = out[:H, :W]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.29. アフィン変換(拡大縮小)\n",
    "\n",
    "アフィン変換を用いて、(1)x方向に1.3倍、y方向に0.8倍にリサイズせよ。\n",
    "\n",
    "また、(2)  (1)の条件に加えて、x方向に+30、y方向に-30だけ平行移動を同時に実現せよ。\n",
    "\n",
    "|入力 (imori.jpg)|出力 (1) (answer_29_1.jpg)|出力 (2) (answer_29_2.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_21_30/imori.jpg)|![](./Question_21_30/answer_29_1.jpg)|![](./Question_21_30/answer_29_2.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "_img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = _img.shape\n",
    "\n",
    "\n",
    "# Affine\n",
    "a = 1.3\n",
    "b = 0.\n",
    "c = 0.\n",
    "d = 0.8\n",
    "tx = 30\n",
    "ty = -30\n",
    "\n",
    "img = np.zeros((H+2, W+2, C), dtype=np.float32)\n",
    "img[1:H+1, 1:W+1] = _img\n",
    "\n",
    "H_new = np.round(H * d).astype(np.int)\n",
    "W_new = np.round(W * a).astype(np.int)\n",
    "out = np.zeros((H_new+1, W_new+1, C), dtype=np.float32)\n",
    "\n",
    "x_new = np.tile(np.arange(W_new), (H_new, 1))\n",
    "y_new = np.arange(H_new).repeat(W_new).reshape(H_new, -1)\n",
    "\n",
    "adbc = a * d - b * c\n",
    "x = np.round((d * x_new  - b * y_new) / adbc).astype(np.int) - tx + 1\n",
    "y = np.round((-c * x_new + a * y_new) / adbc).astype(np.int) - ty + 1\n",
    "\n",
    "x = np.minimum(np.maximum(x, 0), W+1).astype(np.int)\n",
    "y = np.minimum(np.maximum(y, 0), H+1).astype(np.int)\n",
    "\n",
    "out[y_new, x_new] = img[y, x]\n",
    "\n",
    "out = out[:H_new, :W_new]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.30. アフィン変換(回転)\n",
    "\n",
    "(1)アフィン変換を用いて、反時計方向に30度回転させよ。\n",
    "\n",
    "(2) アフィン変換を用いて、反時計方向に30度回転した画像全体を見れる画像を作成せよ。\n",
    "（ただし、単純なアフィン変換を行うと画像が切れてしまうので、工夫を要する。）\n",
    "\n",
    "アフィン変換において、反時計方向にA度回転させる時は、次式となる。\n",
    "\n",
    "```bash\n",
    "  x'       cosA -sinA tx    x\n",
    "[ y' ] = [ sinA  cosA ty ][ y ]\n",
    "  1         0     0    1    1\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (1) (answer_30_1.jpg)|出力 (2) (answer_30_2.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_21_30/imori.jpg)|![](./Question_21_30/answer_30_1.jpg)|![](./Question_21_30/answer_30_2.jpg)|\n",
    "\n",
    "<details><summary>答え(1)(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "_img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = _img.shape\n",
    "\n",
    "\n",
    "# Affine\n",
    "\n",
    "A = 30.\n",
    "theta = - np.pi * A / 180.\n",
    "\n",
    "a = np.cos(theta)\n",
    "b = -np.sin(theta)\n",
    "c = np.sin(theta)\n",
    "d = np.cos(theta)\n",
    "tx = 0\n",
    "ty = 0\n",
    "\n",
    "img = np.zeros((H+2, W+2, C), dtype=np.float32)\n",
    "img[1:H+1, 1:W+1] = _img\n",
    "\n",
    "H_new = np.round(H).astype(np.int)\n",
    "W_new = np.round(W).astype(np.int)\n",
    "out = np.zeros((H_new, W_new, C), dtype=np.float32)\n",
    "\n",
    "x_new = np.tile(np.arange(W_new), (H_new, 1))\n",
    "y_new = np.arange(H_new).repeat(W_new).reshape(H_new, -1)\n",
    "\n",
    "adbc = a * d - b * c\n",
    "x = np.round((d * x_new  - b * y_new) / adbc).astype(np.int) - tx + 1\n",
    "y = np.round((-c * x_new + a * y_new) / adbc).astype(np.int) - ty + 1\n",
    "\n",
    "x = np.minimum(np.maximum(x, 0), W+1).astype(np.int)\n",
    "y = np.minimum(np.maximum(y, 0), H+1).astype(np.int)\n",
    "\n",
    "out[y_new, x_new] = img[y, x]\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>\n",
    "\n",
    "<details><summary>答え(2)(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "_img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = _img.shape\n",
    "\n",
    "\n",
    "# Affine\n",
    "A = 30.\n",
    "theta = - np.pi * A / 180.\n",
    "\n",
    "a = np.cos(theta)\n",
    "b = -np.sin(theta)\n",
    "c = np.sin(theta)\n",
    "d = np.cos(theta)\n",
    "tx = 0\n",
    "ty = 0\n",
    "\n",
    "img = np.zeros((H+2, W+2, C), dtype=np.float32)\n",
    "img[1:H+1, 1:W+1] = _img\n",
    "\n",
    "H_new = np.round(H).astype(np.int)\n",
    "W_new = np.round(W).astype(np.int)\n",
    "out = np.zeros((H_new, W_new, C), dtype=np.float32)\n",
    "\n",
    "x_new = np.tile(np.arange(W_new), (H_new, 1))\n",
    "y_new = np.arange(H_new).repeat(W_new).reshape(H_new, -1)\n",
    "\n",
    "adbc = a * d - b * c\n",
    "x = np.round((d * x_new  - b * y_new) / adbc).astype(np.int) - tx + 1\n",
    "y = np.round((-c * x_new + a * y_new) / adbc).astype(np.int) - ty + 1\n",
    "\n",
    "dcx = (x.max() + x.min()) // 2 - W // 2\n",
    "dcy = (y.max() + y.min()) // 2 - H // 2\n",
    "\n",
    "x -= dcx\n",
    "y -= dcy\n",
    "\n",
    "x = np.minimum(np.maximum(x, 0), W+1).astype(np.int)\n",
    "y = np.minimum(np.maximum(y, 0), H+1).astype(np.int)\n",
    "\n",
    "out[y_new, x_new] = img[y, x]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 31 - 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.31. アフィン変換(スキュー)\n",
    "\n",
    "(1)アフィン変換を用いて、出力(1)のようなX-sharing(dx = 30)画像を作成せよ。\n",
    "\n",
    "(2)アフィン変換を用いて、出力2のようなY-sharing(dy = 30)画像を作成せよ。\n",
    "\n",
    "(3)アフィン変換を用いて、出力3のような幾何変換した(dx = 30, dy = 30)画像を作成せよ。\n",
    "\n",
    "このような画像はスキュー画像と呼ばれ、画像を斜め方向に伸ばした画像である。\n",
    "\n",
    "出力(1)の場合、x方向にdxだけ引き伸ばした画像はX-sharingと呼ばれる。\n",
    "\n",
    "出力(2)の場合、y方向にdyだけ引き伸ばした画像はY-sharingと呼ばれる。\n",
    "\n",
    "それぞれ次式のアフィン変換で実現できる。\n",
    "ただし、元画像のサイズがh x wとする。\n",
    "\n",
    "```bash\n",
    "(1) X-sharing                  (2) Y-sharing\n",
    "   a = dx / h                     a = dy / w\n",
    "\n",
    "  x'       1 a tx    x           x'       1 0 tx    x\n",
    "[ y' ] = [ 0 1 ty ][ y ]       [ y' ] = [ a 1 ty ][ y ]\n",
    "  1        0 0  1    1           1        0 0  1    1\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (1) (answer_31_1.jpg)|出力 (2) (answer_31_2.jpg)|出力 (3) (answer_31_3.jpg)|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/answer_31_1.jpg)|![](./Question_31_40/answer_31_2.jpg)|![](./Question_31_40/answer_31_3.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "_img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = _img.shape\n",
    "\n",
    "\n",
    "# Affine\n",
    "dx = 30.\n",
    "dy = 30.\n",
    "a = 1.\n",
    "b = dx / H\n",
    "c = dy / W\n",
    "d = 1.\n",
    "tx = 0.\n",
    "ty = 0.\n",
    "\n",
    "img = np.zeros((H+2, W+2, C), dtype=np.float32)\n",
    "img[1:H+1, 1:W+1] = _img\n",
    "\n",
    "H_new = np.ceil(dy + H).astype(np.int)\n",
    "W_new = np.ceil(dx + W).astype(np.int)\n",
    "out = np.zeros((H_new, W_new, C), dtype=np.float32)\n",
    "\n",
    "x_new = np.tile(np.arange(W_new), (H_new, 1))\n",
    "y_new = np.arange(H_new).repeat(W_new).reshape(H_new, -1)\n",
    "\n",
    "adbc = a * d - b * c\n",
    "x = np.round((d * x_new  - b * y_new) / adbc).astype(np.int) - tx + 1\n",
    "y = np.round((-c * x_new + a * y_new) / adbc).astype(np.int) - ty + 1\n",
    "\n",
    "x = np.minimum(np.maximum(x, 0), W+1).astype(np.int)\n",
    "y = np.minimum(np.maximum(y, 0), H+1).astype(np.int)\n",
    "\n",
    "out[y_new, x_new] = img[y, x]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.32. フーリエ変換\n",
    "\n",
    "二次元離散フーリエ変換(DFT)を実装し、*imori.jpg*をグレースケール化したものの周波数のパワースペクトルを表示せよ。\n",
    "また、逆二次元離散フーリエ変換(IDFT)で画像を復元せよ。\n",
    "\n",
    "二次元離散フーリエ変換(DFT: Discrete Fourier Transformation)とはフーリエ変換の画像に対する処理方法である。\n",
    "\n",
    "通常のフーリエ変換はアナログ信号や音声などの連続値かつ一次元を対象に周波数成分を求める計算処理である。\n",
    "\n",
    "一方、ディジタル画像は[0,255]の離散値をとり、かつ画像はHxWの二次元表示であるので、二次元離散フーリエ変換が行われる。\n",
    "\n",
    "二次元離散フーリエ変換(DFT)は次式で計算される。\n",
    "\n",
    "```bash\n",
    "K = 0:W, l = 0:H, 入力画像をI として\n",
    "G(k,l) = Sum_{y=0:H-1, x=0:W-1} I(x,y) exp( -2pi * j * (kx/W + ly/H)) / sqrt(H * W)\n",
    "```\n",
    "\n",
    "ここでは画像をグレースケール化してから二次元離散フーリエ変換を行え。\n",
    "\n",
    "パワースペクトルとは Gは複素数で表されるので、Gの絶対値を求めることである。\n",
    "今回のみ画像表示の時はパワースペクトルは[0,255]にスケーリングせよ。\n",
    "\n",
    "逆二次元離散フーリエ変換(IDFT: Inverse DFT)とは周波数成分Gから元の画像を復元する手法であり、次式で定義される。\n",
    "\n",
    "```bash\n",
    "x = 0:W, y = 0:H  として\n",
    "I(x,y) = Sum_{l=0:H-1, k=0:W-1} G(k,l) exp( 2pi * j * (kx/W + ly/H)) / sqrt(H * W)\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|グレースケール (imori_gray.jpg)|出力 (answer_32.jpg)|パワースペクトル (answer_32_ps.jpg)\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/imori_gray.jpg)|![](./Question_31_40/answer_32.jpg)|![](./Question_31_40/answer_32_ps.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "\"\"\"\n",
    "fimg = np.fft.fft2(gray)\n",
    "    \n",
    "# 第1象限と第3象限, 第2象限と第4象限を入れ替え\n",
    "fimg =  np.fft.fftshift(fimg)\n",
    "print(fimg.shape)\n",
    "# パワースペクトルの計算\n",
    "mag = 20*np.log(np.abs(fimg))\n",
    "    \n",
    "# 入力画像とスペクトル画像をグラフ描画\n",
    "plt.subplot(121)\n",
    "plt.imshow(gray, cmap = 'gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(mag, cmap = 'gray')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# DFT\n",
    "K = W\n",
    "L = H\n",
    "M = W\n",
    "N = H\n",
    "\n",
    "G = np.zeros((L, K), dtype=np.complex)\n",
    "\n",
    "x = np.tile(np.arange(W), (H, 1))\n",
    "y = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "for l in range(L):\n",
    "    for k in range(K):\n",
    "        G[l, k] = np.sum(gray * np.exp(-2j * np.pi * (x * k / M + y * l / N))) / np.sqrt(M * N)\n",
    "        #for n in range(N):\n",
    "        #    for m in range(M):\n",
    "        #        v += gray[n, m] * np.exp(-2j * np.pi * (m * k / M + n * l / N))\n",
    "        #G[l, k] = v / np.sqrt(M * N)\n",
    "\n",
    "ps = (np.abs(G) / np.abs(G).max() * 255).astype(np.uint8)\n",
    "cv2.imwrite(\"out_ps.jpg\", ps)\n",
    "\n",
    "# IDFT\n",
    "out = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "for n in range(N):\n",
    "    for m in range(M):\n",
    "        out[n,m] = np.abs(np.sum(G * np.exp(2j * np.pi * (x * m / M + y * n / N)))) / np.sqrt(M * N)\n",
    "\n",
    "out[out>255] = 255\n",
    "out = out.astype(np.uint8)\n",
    "    \n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.33. フーリエ変換　ローパスフィルタ\n",
    "\n",
    "*imori.jpg*をグレースケール化したものをDFTし、ローパスフィルタを通してIDFTで画像を復元せよ。\n",
    "\n",
    "DFTによって得られた周波数成分は左上、右上、左下、右下に近いほど低周波数の成分を含んでいることになり、中心に近いほど高周波成分を示す。\n",
    "\n",
    "画像における高周波成分とは色が変わっている部分（ノイズや輪郭など）を示し、低周波成分とは色があまり変わっていない部分（夕日のグラデーションなど）を表す。\n",
    "ここでは、高周波成分をカットし、低周波成分のみを通す**ローパスフィルタ**を実装せよ。\n",
    "\n",
    "ここでは低周波数の中心から高周波までの距離をrとすると0.5rまでの成分を通すとする。\n",
    "\n",
    "|入力 (imori.jpg)|グレースケール (imori_gray.jpg)|出力 (answer_33.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/imori_gray.jpg)|![](./Question_31_40/answer_33.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# DFT\n",
    "K = W\n",
    "L = H\n",
    "M = W\n",
    "N = H\n",
    "\n",
    "G = np.zeros((L, K), dtype=np.complex)\n",
    "\n",
    "x = np.tile(np.arange(W), (H, 1))\n",
    "y = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "for l in range(L):\n",
    "    for k in range(K):\n",
    "        G[l, k] = np.sum(gray * np.exp(-2j * np.pi * (x * k / M + y * l / N))) / np.sqrt(M * N)\n",
    "\n",
    "# low-pass filter\n",
    "_G = np.zeros_like(G)\n",
    "_G[:H//2, :W//2] = G[H//2:, W//2:]\n",
    "_G[:H//2, W//2:] = G[H//2:, :W//2]\n",
    "_G[H//2:, :W//2] = G[:H//2, W//2:]\n",
    "_G[H//2:, W//2:] = G[:H//2, :W//2]\n",
    "p = 0.5\n",
    "_x = x - W // 2\n",
    "_y = y - H // 2\n",
    "r = np.sqrt(_x ** 2 + _y ** 2)\n",
    "mask = np.ones((H, W), dtype=np.float32)\n",
    "mask[r>(W//2*p)] = 0\n",
    "\n",
    "_G *= mask\n",
    "\n",
    "G[:H//2, :W//2] = _G[H//2:, W//2:]\n",
    "G[:H//2, W//2:] = _G[H//2:, :W//2]\n",
    "G[H//2:, :W//2] = _G[:H//2, W//2:]\n",
    "G[H//2:, W//2:] = _G[:H//2, :W//2]\n",
    "\n",
    "# IDFT\n",
    "out = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "for n in range(N):\n",
    "    for m in range(M):\n",
    "        out[n,m] = np.abs(np.sum(G * np.exp(2j * np.pi * (x * m / M + y * n / N)))) / np.sqrt(M * N)\n",
    "\n",
    "out[out>255] = 255\n",
    "out = out.astype(np.uint8)\n",
    "    \n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.34. フーリエ変換　ハイパスフィルタ\n",
    "\n",
    "*imori.jpg*をグレースケール化したものをDFTし、ハイパスフィルタを通してIDFTで画像を復元せよ。\n",
    "\n",
    "ここでは、低周波成分をカットし、高周波成分のみを通す**ハイパスフィルタ**を実装せよ。\n",
    "\n",
    "ここでは低周波数の中心から高周波までの距離をrとすると0.2rからの成分を通すとする。\n",
    "\n",
    "|入力 (imori.jpg)|グレースケール (imori_gray.jpg)|出力 (answer_34.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/imori_gray.jpg)|![](./Question_31_40/answer_34.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# DFT\n",
    "K = W\n",
    "L = H\n",
    "M = W\n",
    "N = H\n",
    "\n",
    "G = np.zeros((L, K), dtype=np.complex)\n",
    "\n",
    "x = np.tile(np.arange(W), (H, 1))\n",
    "y = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "for l in range(L):\n",
    "    for k in range(K):\n",
    "        G[l, k] = np.sum(gray * np.exp(-2j * np.pi * (x * k / M + y * l / N))) / np.sqrt(M * N)\n",
    "\n",
    "# low-pass filter\n",
    "_G = np.zeros_like(G)\n",
    "_G[:H//2, :W//2] = G[H//2:, W//2:]\n",
    "_G[:H//2, W//2:] = G[H//2:, :W//2]\n",
    "_G[H//2:, :W//2] = G[:H//2, W//2:]\n",
    "_G[H//2:, W//2:] = G[:H//2, :W//2]\n",
    "p = 0.2\n",
    "_x = x - W // 2\n",
    "_y = y - H // 2\n",
    "r = np.sqrt(_x ** 2 + _y ** 2)\n",
    "mask = np.ones((H, W), dtype=np.float32)\n",
    "mask[r<(W//2*p)] = 0\n",
    "\n",
    "_G *= mask\n",
    "\n",
    "G[:H//2, :W//2] = _G[H//2:, W//2:]\n",
    "G[:H//2, W//2:] = _G[H//2:, :W//2]\n",
    "G[H//2:, :W//2] = _G[:H//2, W//2:]\n",
    "G[H//2:, W//2:] = _G[:H//2, :W//2]\n",
    "\n",
    "# IDFT\n",
    "out = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "for n in range(N):\n",
    "    for m in range(M):\n",
    "        out[n,m] = np.abs(np.sum(G * np.exp(2j * np.pi * (x * m / M + y * n / N)))) / np.sqrt(M * N)\n",
    "\n",
    "out[out>255] = 255\n",
    "out = out.astype(np.uint8)\n",
    "    \n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.35. フーリエ変換　バンドパスフィルタ\n",
    "\n",
    "*imori.jpg*をグレースケール化したものをDFTし、ハイパスフィルタを通してIDFTで画像を復元せよ。\n",
    "\n",
    "ここでは、低周波成分と高周波成分の中間の周波数成分のみを通す**ハイパスフィルタ**を実装せよ。\n",
    "\n",
    "ここでは低周波数の中心から高周波までの距離をrとすると0.1rから0.5rまでの成分を通すとする。\n",
    "\n",
    "|入力 (imori.jpg)|グレースケール (imori_gray.jpg)|出力 (answer_35.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/imori_gray.jpg)|![](./Question_31_40/answer_35.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# DFT\n",
    "K = W\n",
    "L = H\n",
    "M = W\n",
    "N = H\n",
    "\n",
    "G = np.zeros((L, K), dtype=np.complex)\n",
    "\n",
    "x = np.tile(np.arange(W), (H, 1))\n",
    "y = np.arange(H).repeat(W).reshape(H, -1)\n",
    "\n",
    "for l in range(L):\n",
    "    for k in range(K):\n",
    "        G[l, k] = np.sum(gray * np.exp(-2j * np.pi * (x * k / M + y * l / N))) / np.sqrt(M * N)\n",
    "\n",
    "# low-pass filter\n",
    "_G = np.zeros_like(G)\n",
    "_G[:H//2, :W//2] = G[H//2:, W//2:]\n",
    "_G[:H//2, W//2:] = G[H//2:, :W//2]\n",
    "_G[H//2:, :W//2] = G[:H//2, W//2:]\n",
    "_G[H//2:, W//2:] = G[:H//2, :W//2]\n",
    "p1 = 0.1\n",
    "p2 = 0.5\n",
    "_x = x - W // 2\n",
    "_y = y - H // 2\n",
    "r = np.sqrt(_x ** 2 + _y ** 2)\n",
    "mask = np.zeros((H, W), dtype=np.float32)\n",
    "mask[np.where((r > (W//2*p1)) & (r < (W//2*p2)))] = 1\n",
    "\n",
    "_G *= mask\n",
    "\n",
    "G[:H//2, :W//2] = _G[H//2:, W//2:]\n",
    "G[:H//2, W//2:] = _G[H//2:, :W//2]\n",
    "G[H//2:, :W//2] = _G[:H//2, W//2:]\n",
    "G[H//2:, W//2:] = _G[:H//2, :W//2]\n",
    "\n",
    "# IDFT\n",
    "out = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "for n in range(N):\n",
    "    for m in range(M):\n",
    "        out[n,m] = np.abs(np.sum(G * np.exp(2j * np.pi * (x * m / M + y * n / N)))) / np.sqrt(M * N)\n",
    "\n",
    "out[out>255] = 255\n",
    "out = out.astype(np.uint8)\n",
    "    \n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.36. JPEG圧縮 (Step.1)離散コサイン変換\n",
    "\n",
    "*imori.jpg*をグレースケール化し離散コサイン変換を行い、逆離散コサイン変換を行え。\n",
    "\n",
    "離散コサイン変換(DCT: Discrete Cosine Transformation)とは、次式で定義される周波数変換の一つである。\n",
    "\n",
    "```bash\n",
    "T = 8\n",
    "F(u,v) = 1 / T * C(u)C(v) * Sum_{y=0:T-1} Sum_{x=0:T-1} f(x,y) cos((2x+1)u*pi/2T) cos((2y+1)v*pi/2T)\n",
    "```\n",
    "\n",
    "逆離散コサイン変換(IDCT: Inverse Discrete Cosine Transformation)とは離散コサイン変換の逆（復号）であり、次式で定義される。\n",
    "\n",
    "```bash\n",
    "f(x,y) = 1 / T * C(x)C(y) * Sum_{u=0:T-1} Sum_{v=0:T-1} F(u,v) cos((2x+1)u*pi/2T) cos((2y+1)v*pi/2T)\n",
    "```\n",
    "\n",
    "ここでは画像を8x8ずつの領域に分割して、各領域で以上のDCT, IDCTを繰り返すことで、jpeg符号に応用される。\n",
    "今回も同様に8x8の領域に分割して、DCT, IDCTを行え。\n",
    "\n",
    "|入力 (imori.jpg)|グレースケール (imori_gray.jpg)|出力 (1) (answer_36.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/imori_gray.jpg)|![](./Question_31_40/answer_36.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# DCT\n",
    "T = 8\n",
    "K = 8\n",
    "X = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "#indx = np.tile(np.arange(T), (T, 1))\n",
    "#indy = np.arange(T).repeat(T).reshape(T, -1)\n",
    "#dct = np.ones_like(indx, dtype=np.float32)\n",
    "#dct[:, 0] /= np.sqrt(2)\n",
    "#dct[0] /= np.sqrt(2)\n",
    "\n",
    "def w(x, y, u, v):\n",
    "    cu = 1.\n",
    "    cv = 1.\n",
    "    if u == 0:\n",
    "        cu /= np.sqrt(2)\n",
    "    if v == 0:\n",
    "        cv /= np.sqrt(2)\n",
    "    theta = np.pi / (2 * T)\n",
    "    return (( 2 * cu * cv / T) * np.cos((2*x+1)*u*theta) * np.cos((2*y+1)*v*theta))\n",
    "    \n",
    "for yi in range(0, H, T):\n",
    "    for xi in range(0, W, T):\n",
    "        for v in range(T):\n",
    "            for u in range(T):\n",
    "                for y in range(T):\n",
    "                    for x in range(T):\n",
    "                        X[v+yi, u+xi] += gray[y+yi, x+xi] * w(x,y,u,v)\n",
    "                \"\"\"\n",
    "                _x = indx + xi * T\n",
    "                _y = indy + yi * T\n",
    "                _u = u + xi * T\n",
    "                _v = v + yi * T\n",
    "                X[_v, _u] = np.sum(C * gray[_y, _x] * np.cos((2*indx+1)*u*np.pi/(2*T)) * np.cos((2*indy+1)*v*np.pi/(2*T)))\n",
    "                \"\"\"\n",
    "        \n",
    "# IDCT\n",
    "out = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "for yi in range(0, H, T):\n",
    "    for xi in range(0, W, T):\n",
    "        for y in range(T):\n",
    "            for x in range(T):\n",
    "                for v in range(K):\n",
    "                    for u in range(K):\n",
    "                        out[y+yi, x+xi] += X[v+yi, u+xi] * w(x,y,u,v)\n",
    "                \"\"\"\n",
    "                _u = indx + xi * T\n",
    "                _v = indy + yi * T\n",
    "                _x = x + yi * T\n",
    "                _y = y + xi * T\n",
    "                out[_y, _x] = np.sum(C * X[_v, _u] * np.cos((2*x+1)*indx*np.pi/(2*T)) * np.cos((2*y+1)*indy*np.pi/(2*T))) * 4. / (T ** 2)\n",
    "                \"\"\"\n",
    "out[out>255] = 255\n",
    "out = np.round(out).astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.37. PSNR\n",
    "\n",
    "IDCTで用いるDCT係数を8でなく、4にすると画像の劣化が生じる。\n",
    "入力画像とIDCT画像のPSNRを求めよ。また、IDCTによるビットレートを求めよ。\n",
    "\n",
    "PSNR(Peak Signal to Noise Ratio)とは信号対雑音比と呼ばれ、画像がどれだけ劣化したかを示す。\n",
    "\n",
    "PSNRが大きいほど、画像が劣化していないことを示し、次式で定義される。\n",
    "MAXは取りうる値の最大値で[0,255]の表示なら MAX=255　となる。\n",
    "また、MSEはMean Squared Error(平均二乗誤差)と呼ばれ、二つの画像の差分の二乗の平均値を示す。\n",
    "\n",
    "\n",
    "```bash\n",
    "PSNR = 10 * log10(MAX^2 / MSE)\n",
    "MSE = Sum_{y=0:H-1} Sum_{x=0:W-1} (I1(x,y) - I2(x,y))^2 / (HW)\n",
    "```\n",
    "\n",
    "ビットレートとは8x8でDCTを行い、IDCTでKxKの係数までを用いた時に次式で定義される。\n",
    "\n",
    "```bash\n",
    "bitrate = 8 * K^2 / 8^2\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|グレースケール|出力 (answer_37.jpg) (PSNR = 27.62, Bitrate=2.0)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/imori_gray.jpg)|![](./Question_31_40/answer_37.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# DCT\n",
    "T = 8\n",
    "K = 4\n",
    "X = np.zeros((H, W), dtype=np.float64)\n",
    "#indx = np.tile(np.arange(T), (T, 1))\n",
    "#indy = np.arange(T).repeat(T).reshape(T, -1)\n",
    "#dct = np.ones_like(indx, dtype=np.float32)\n",
    "#dct[:, 0] /= np.sqrt(2)\n",
    "#dct[0] /= np.sqrt(2)\n",
    "\n",
    "def w(x, y, u, v):\n",
    "    cu = 1.\n",
    "    cv = 1.\n",
    "    if u == 0:\n",
    "        cu /= np.sqrt(2)\n",
    "    if v == 0:\n",
    "        cv /= np.sqrt(2)\n",
    "    theta = np.pi / (2 * T)\n",
    "    return (( 2 * cu * cv / T) * np.cos((2*x+1)*u*theta) * np.cos((2*y+1)*v*theta))\n",
    "    \n",
    "for yi in range(0, H, T):\n",
    "    for xi in range(0, W, T):\n",
    "        for v in range(T):\n",
    "            for u in range(T):\n",
    "                for y in range(T):\n",
    "                    for x in range(T):\n",
    "                        X[v+yi, u+xi] += gray[y+yi, x+xi] * w(x,y,u,v)\n",
    "                \"\"\"\n",
    "                _x = indx + xi * T\n",
    "                _y = indy + yi * T\n",
    "                _u = u + xi * T\n",
    "                _v = v + yi * T\n",
    "                X[_v, _u] = np.sum(C * gray[_y, _x] * np.cos((2*indx+1)*u*np.pi/(2*T)) * np.cos((2*indy+1)*v*np.pi/(2*T)))\n",
    "                \"\"\"\n",
    "\n",
    "# IDCT\n",
    "out = np.zeros((H, W), dtype=np.float64)\n",
    "\n",
    "for yi in range(0, H, T):\n",
    "    for xi in range(0, W, T):\n",
    "        for y in range(T):\n",
    "            for x in range(T):\n",
    "                for v in range(K):\n",
    "                    for u in range(K):\n",
    "                        out[y+yi, x+xi] += X[v+yi, u+xi] * w(x,y,u,v)\n",
    "                \"\"\"\n",
    "                _u = indx + xi * T\n",
    "                _v = indy + yi * T\n",
    "                _x = x + yi * T\n",
    "                _y = y + xi * T\n",
    "                out[_y, _x] = np.sum(C * X[_v, _u] * np.cos((2*x+1)*indx*np.pi/(2*T)) * np.cos((2*y+1)*indy*np.pi/(2*T))) * 4. / (T ** 2)\n",
    "                \"\"\"\n",
    "\n",
    "out[out>255] = 255\n",
    "out = np.floor(out).astype(np.uint8)\n",
    "\n",
    "# MSE\n",
    "v_max = 255.\n",
    "mse = np.sum(np.power(np.abs(gray.astype(np.float32) - out.astype(np.float32)), 2)) / (H * W)\n",
    "psnr = 10 * np.log10(v_max ** 2 / mse)\n",
    "\n",
    "print(\"PSNR >>\", psnr)\n",
    "\n",
    "bitrate = 1. * T * K ** 2 / (T ** 2)\n",
    "print(\"bitrate >>\", bitrate)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.38. JPEG圧縮 (Step.2)DCT+量子化|\n",
    "\n",
    "DCT係数を量子化し、IDCTで復元せよ。また、その時の画像の容量を比べよ。\n",
    "\n",
    "DCT係数を量子化することはjpeg画像にする符号化で用いられる手法である。\n",
    "\n",
    "量子化とは、値を予め決定された区分毎に値を大まかに丸め込む作業であり、floorやceil, roundなどが似た計算である。\n",
    "\n",
    "JPEG画像ではDCT係数を下記で表される量子化テーブルに則って量子化する。\n",
    "この量子化テーブルはjpeg団体の仕様書から取った。\n",
    "量子化では8x8の係数をQで割り、四捨五入する。その後Qを掛けることで行われる。\n",
    "IDCTでは係数は全て用いるものとする。\n",
    "\n",
    "```bash\n",
    "Q = np.array(((16, 11, 10, 16, 24, 40, 51, 61),\n",
    "              (12, 12, 14, 19, 26, 58, 60, 55),\n",
    "              (14, 13, 16, 24, 40, 57, 69, 56),\n",
    "              (14, 17, 22, 29, 51, 87, 80, 62),\n",
    "              (18, 22, 37, 56, 68, 109, 103, 77),\n",
    "              (24, 35, 55, 64, 81, 104, 113, 92),\n",
    "              (49, 64, 78, 87, 103, 121, 120, 101),\n",
    "              (72, 92, 95, 98, 112, 100, 103, 99)), dtype=np.float32)\n",
    "```\n",
    "\n",
    "量子化を行うと画像の容量が減っていることから、データ量が削減されたことが伺える。\n",
    "\n",
    "|入力 (imori.jpg)|グレースケール(9kb)|出力 (answer_38.jpg) (7kb)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/imori_gray.jpg)|![](./Question_31_40/answer_38.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray scale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# DCT\n",
    "T = 8\n",
    "K = 8\n",
    "X = np.zeros((H, W), dtype=np.float64)\n",
    "#indx = np.tile(np.arange(T), (T, 1))\n",
    "#indy = np.arange(T).repeat(T).reshape(T, -1)\n",
    "#dct = np.ones_like(indx, dtype=np.float32)\n",
    "#dct[:, 0] /= np.sqrt(2)\n",
    "#dct[0] /= np.sqrt(2)\n",
    "\n",
    "Q = np.array(((16, 11, 10, 16, 24, 40, 51, 61),\n",
    "              (12, 12, 14, 19, 26, 58, 60, 55),\n",
    "              (14, 13, 16, 24, 40, 57, 69, 56),\n",
    "              (14, 17, 22, 29, 51, 87, 80, 62),\n",
    "              (18, 22, 37, 56, 68, 109, 103, 77),\n",
    "              (24, 35, 55, 64, 81, 104, 113, 92),\n",
    "              (49, 64, 78, 87, 103, 121, 120, 101),\n",
    "              (72, 92, 95, 98, 112, 100, 103, 99)), dtype=np.float32)\n",
    "\n",
    "def w(x, y, u, v):\n",
    "    cu = 1.\n",
    "    cv = 1.\n",
    "    if u == 0:\n",
    "        cu /= np.sqrt(2)\n",
    "    if v == 0:\n",
    "        cv /= np.sqrt(2)\n",
    "    theta = np.pi / (2 * T)\n",
    "    return (( 2 * cu * cv / T) * np.cos((2*x+1)*u*theta) * np.cos((2*y+1)*v*theta))\n",
    "    \n",
    "for yi in range(0, H, T):\n",
    "    for xi in range(0, W, T):\n",
    "        for v in range(T):\n",
    "            for u in range(T):\n",
    "                for y in range(T):\n",
    "                    for x in range(T):\n",
    "                        X[v+yi, u+xi] += gray[y+yi, x+xi] * w(x,y,u,v)\n",
    "        X[yi:yi+T, xi:xi+T] = np.round(X[yi:yi+T, xi:xi+T] / Q) * Q\n",
    "                \n",
    "                #_x = indx + xi * T\n",
    "                #_y = indy + yi * T\n",
    "                #_u = u + xi * T\n",
    "                #_v = v + yi * T\n",
    "                #X[_v, _u] = np.sum(C * gray[_y, _x] * np.cos((2*indx+1)*u*np.pi/(2*T)) * np.cos((2*indy+1)*v*np.pi/(2*T)))\n",
    "\n",
    "# IDCT\n",
    "out = np.zeros((H, W), dtype=np.float64)\n",
    "\n",
    "for yi in range(0, H, T):\n",
    "    for xi in range(0, W, T):\n",
    "        for y in range(T):\n",
    "            for x in range(T):\n",
    "                for v in range(K):\n",
    "                    for u in range(K):\n",
    "                        out[y+yi, x+xi] += X[v+yi, u+xi] * w(x,y,u,v)\n",
    "                \"\"\"\n",
    "                _u = indx + xi * T\n",
    "                _v = indy + yi * T\n",
    "                _x = x + yi * T\n",
    "                _y = y + xi * T\n",
    "                out[_y, _x] = np.sum(C * X[_v, _u] * np.cos((2*x+1)*indx*np.pi/(2*T)) * np.cos((2*y+1)*indy*np.pi/(2*T))) * 4. / (T ** 2)\n",
    "                \"\"\"\n",
    "out[out>255] = 255\n",
    "out = np.floor(out).astype(np.uint8)\n",
    "\n",
    "# MSE\n",
    "v_max = 255.\n",
    "mse = np.sum(np.power(np.abs(gray.astype(np.float32) - out.astype(np.float32)), 2)) / (H * W)\n",
    "psnr = 10 * np.log10(v_max ** 2 / mse)\n",
    "\n",
    "print(\"PSNR >>\", psnr)\n",
    "\n",
    "bitrate = 1. * T * K ** 2 / (T ** 2)\n",
    "print(\"bitrate >>\", bitrate)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.39. JPEG圧縮 (Step.3)YCbCr表色系\n",
    "\n",
    "YCbCr表色形において、Yを0.7倍してコントラストを暗くせよ。\n",
    "\n",
    "YCbCr表色系とは、画像を明るさを表すY、輝度と青レベルの差Cb、輝度と赤レベルの差Crに分解する表現方法である。\n",
    "\n",
    "これはJPEG変換で用いられる。\n",
    "\n",
    "RGBからYCbCrへの変換は次式。\n",
    "\n",
    "```bash\n",
    "Y = 0.299 * R + 0.5870 * G + 0.114 * B\n",
    "Cb = -0.1687 * R - 0.3313 * G + 0.5 * B + 128\n",
    "Cr = 0.5 * R - 0.4187 * G - 0.0813 * B + 128\n",
    "```\n",
    "\n",
    "YCbCrからRGBへの変換は次式。\n",
    "\n",
    "```bash\n",
    "R = Y + (Cr - 128) * 1.402\n",
    "G = Y - (Cb - 128) * 0.3441 - (Cr - 128) * 0.7139\n",
    "B = Y + (Cb - 128) * 1.7718\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg)|出力 (answer_39.jpg) |\n",
    "|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/answer_39.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# RGB > YCbCr\n",
    "Y = 0.2990 * img[..., 2] + 0.5870 * img[..., 1] + 0.1140 * img[..., 0]\n",
    "Cb = -0.1687 * img[..., 2] - 0.3313 * img[..., 1] + 0.5 * img[..., 0] + 128.\n",
    "Cr = 0.5 * img[..., 2] - 0.4187 * img[..., 1] - 0.0813 * img[..., 0] + 128.\n",
    "\n",
    "Y *= 0.7\n",
    "\n",
    "# YCbCr > RGB\n",
    "out = np.zeros_like(img, dtype=np.float32)\n",
    "out[..., 2] = Y + (Cr - 128.) * 1.4020\n",
    "out[..., 1] = Y - (Cb - 128.) * 0.3441 - (Cr - 128.) * 0.7139\n",
    "out[..., 0] = Y + (Cb - 128.) * 1.7718\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.40. JPEG圧縮 (Step.4)YCbCr+DCT+量子化\n",
    "\n",
    "YCbCr表色系にし、DCT後、Yを量子化テーブルQ1、CbとCrをQ2で量子化し、IDCTで画像を復元せよ。\n",
    "また、画像の容量を比較せよ。\n",
    "\n",
    "これはJPEGで実際に使われるデータ量削減の手法であり、Q1,Q2はJPEGの仕様書に則って次式で定義される。\n",
    "\n",
    "```bash\n",
    "Q1 = np.array(((16, 11, 10, 16, 24, 40, 51, 61),\n",
    "               (12, 12, 14, 19, 26, 58, 60, 55),\n",
    "               (14, 13, 16, 24, 40, 57, 69, 56),\n",
    "               (14, 17, 22, 29, 51, 87, 80, 62),\n",
    "               (18, 22, 37, 56, 68, 109, 103, 77),\n",
    "               (24, 35, 55, 64, 81, 104, 113, 92),\n",
    "               (49, 64, 78, 87, 103, 121, 120, 101),\n",
    "               (72, 92, 95, 98, 112, 100, 103, 99)), dtype=np.float32)\n",
    "\n",
    "Q2 = np.array(((17, 18, 24, 47, 99, 99, 99, 99),\n",
    "               (18, 21, 26, 66, 99, 99, 99, 99),\n",
    "               (24, 26, 56, 99, 99, 99, 99, 99),\n",
    "               (47, 66, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99)), dtype=np.float32)\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg) (13kb)|出力 (answer_40.jpg) (8kb)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_31_40/imori.jpg)|![](./Question_31_40/answer_40.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# RGB > YCbCr\n",
    "Y = 0.2990 * img[..., 2] + 0.5870 * img[..., 1] + 0.1140 * img[..., 0]\n",
    "Cb = -0.1687 * img[..., 2] - 0.3313 * img[..., 1] + 0.5 * img[..., 0] + 128.\n",
    "Cr = 0.5 * img[..., 2] - 0.4187 * img[..., 1] - 0.0813 * img[..., 0] + 128.\n",
    "\n",
    "YCC = np.zeros_like(img, dtype=np.float32)\n",
    "YCC[..., 0] = Y\n",
    "YCC[..., 1] = Cb\n",
    "YCC[..., 2] = Cr\n",
    "\n",
    "\n",
    "# DCT\n",
    "T = 8\n",
    "K = 8\n",
    "X = np.zeros((H, W, C), dtype=np.float64)\n",
    "\n",
    "Q1 = np.array(((16, 11, 10, 16, 24, 40, 51, 61),\n",
    "               (12, 12, 14, 19, 26, 58, 60, 55),\n",
    "               (14, 13, 16, 24, 40, 57, 69, 56),\n",
    "               (14, 17, 22, 29, 51, 87, 80, 62),\n",
    "               (18, 22, 37, 56, 68, 109, 103, 77),\n",
    "               (24, 35, 55, 64, 81, 104, 113, 92),\n",
    "               (49, 64, 78, 87, 103, 121, 120, 101),\n",
    "               (72, 92, 95, 98, 112, 100, 103, 99)), dtype=np.float32)\n",
    "\n",
    "Q2 = np.array(((17, 18, 24, 47, 99, 99, 99, 99),\n",
    "               (18, 21, 26, 66, 99, 99, 99, 99),\n",
    "               (24, 26, 56, 99, 99, 99, 99, 99),\n",
    "               (47, 66, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99),\n",
    "               (99, 99, 99, 99, 99, 99, 99, 99)), dtype=np.float32)\n",
    "\n",
    "def w(x, y, u, v):\n",
    "    cu = 1.\n",
    "    cv = 1.\n",
    "    if u == 0:\n",
    "        cu /= np.sqrt(2)\n",
    "    if v == 0:\n",
    "        cv /= np.sqrt(2)\n",
    "    theta = np.pi / (2 * T)\n",
    "    return (( 2 * cu * cv / T) * np.cos((2*x+1)*u*theta) * np.cos((2*y+1)*v*theta))\n",
    "    \n",
    "for yi in range(0, H, T):\n",
    "    for xi in range(0, W, T):\n",
    "        for v in range(T):\n",
    "            for u in range(T):\n",
    "                for y in range(T):\n",
    "                    for x in range(T):\n",
    "                        for c in range(C):\n",
    "                            X[v+yi, u+xi, c] += YCC[y+yi, x+xi, c] * w(x,y,u,v)\n",
    "                            \n",
    "        X[yi:yi+T, xi:xi+T, 0] = np.round(X[yi:yi+T, xi:xi+T, 0] / Q1) * Q1\n",
    "        X[yi:yi+T, xi:xi+T, 1] = np.round(X[yi:yi+T, xi:xi+T, 1] / Q2) * Q2\n",
    "        X[yi:yi+T, xi:xi+T, 2] = np.round(X[yi:yi+T, xi:xi+T, 2] / Q2) * Q2\n",
    "                \n",
    "\n",
    "# IDCT\n",
    "IYCC = np.zeros((H, W, 3), dtype=np.float64)\n",
    "\n",
    "for yi in range(0, H, T):\n",
    "    for xi in range(0, W, T):\n",
    "        for y in range(T):\n",
    "            for x in range(T):\n",
    "                for v in range(K):\n",
    "                    for u in range(K):\n",
    "                        IYCC[y+yi, x+xi] += X[v+yi, u+xi] * w(x,y,u,v)\n",
    "\n",
    "\n",
    "# YCbCr > RGB\n",
    "out = np.zeros_like(img, dtype=np.float32)\n",
    "out[..., 2] = IYCC[..., 0] + (IYCC[..., 2] - 128.) * 1.4020\n",
    "out[..., 1] = IYCC[..., 0] - (IYCC[..., 1] - 128.) * 0.3441 - (IYCC[..., 2] - 128.) * 0.7139\n",
    "out[..., 0] = IYCC[..., 0] + (IYCC[..., 1] - 128.) * 1.7718\n",
    "\n",
    "out[out>255] = 255\n",
    "out = out.astype(np.uint8)\n",
    "                        \n",
    "# MSE\n",
    "v_max = 255.\n",
    "mse = np.sum(np.power(np.abs(img.astype(np.float32) - out.astype(np.float32)), 2)) / (H * W * C)\n",
    "psnr = 10 * np.log10(v_max ** 2 / mse)\n",
    "\n",
    "print(\"PSNR >>\", psnr)\n",
    "\n",
    "bitrate = 1. * T * K ** 2 / (T ** 2)\n",
    "print(\"bitrate >>\", bitrate)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 41 - 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.41. Cannyエッジ検出 (Step.1) エッジ強度\n",
    "\n",
    "Q.41 - 43 ではエッジ検出手法の一つであるCanny法の理論となる。\n",
    "\n",
    "Canny法は、\n",
    "1. ガウシアンフィルタを掛ける\n",
    "2. x, y方向のSobelフィルタを掛け、それらからエッジ強度とエッジ勾配を求める\n",
    "3. エッジ勾配の値から、Non-maximum suppression によりエッジの細線化を行う\n",
    "4. ヒステリシスによる閾値処理を行う\n",
    "\n",
    "以上により、画像からエッジ部分を抜き出す手法である。\n",
    "\n",
    "ここでは、1と2の処理を実装する。\n",
    "\n",
    "処理手順は、\n",
    "1. 画像をグレースケール化する\n",
    "2. ガウシアンフィルタ(5x5, s=1.4)をかける\n",
    "3. x方向、y方向のsobelフィルタを掛け、画像の勾配画像fx, fyを求め、勾配強度と勾配角度を次式で求める。\n",
    "\n",
    "```bash\n",
    "勾配強度 edge = sqrt(fx^2 + fy^2)\n",
    "勾配角度 tan = arctan(fy / fx)\n",
    "```\n",
    "\n",
    "4. 勾配角度を次式に沿って、量子化する。\n",
    "\n",
    "```bash\n",
    "angle = {   0  (if -0.4142 < tan <= 0.4142)\n",
    "           45  (if  0.4142 < tan < 2.4142)\n",
    "           90  (if  |tan| >= 2.4142)\n",
    "          135  (if -2.4142 < tan <= -0.4142)\n",
    "```\n",
    "\n",
    "ただし、フィルタリングをパディングする際は、numpy.pad()を用いて、エッジの値でパディングせよ。\n",
    "\n",
    "|入力 (imori.jpg) |出力(勾配強度) (answer_41_1.jpg)|出力(勾配角度) (answer_41_2.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_41_50/imori.jpg)|![](./Question_41_50/answer_41_1.jpg)|![](./Question_41_50/answer_41_2.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "gau = np.zeros((H + pad*2, W + pad*2), dtype=np.float32)\n",
    "#gau[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float32)\n",
    "gau = np.pad(gray, (pad, pad), 'edge')\n",
    "tmp = gau.copy()\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float32)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = np.exp( -(x**2 + y**2) / (2* (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        gau[pad+y, pad+x] = np.sum(K * tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "## Sobel vertical\n",
    "KSV = np.array(((-1., -2., -1.), (0., 0., 0.), (1., 2., 1.)), dtype=np.float32)\n",
    "## Sobel horizontal\n",
    "KSH = np.array(((-1., 0., 1.), (-2., 0., 2.), (-1., 0., 1.)), dtype=np.float32)\n",
    "\n",
    "gau = gau[pad-1:H+pad+1, pad-1:W+pad+1]\n",
    "fy = np.zeros_like(gau, dtype=np.float32)\n",
    "fx = np.zeros_like(gau, dtype=np.float32)\n",
    "K_size = 3\n",
    "pad = K_size // 2\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        fy[pad+y, pad+x] = np.sum(KSV * gau[y:y+K_size, x:x+K_size])\n",
    "        fx[pad+y, pad+x] = np.sum(KSH * gau[y:y+K_size, x:x+K_size])\n",
    "        \n",
    "fx = fx[pad:pad+H, pad:pad+W]\n",
    "fy = fy[pad:pad+H, pad:pad+W]\n",
    "\n",
    "# Non-maximum suppression\n",
    "edge = np.sqrt(np.power(fx, 2) + np.power(fy, 2))\n",
    "fx[fx == 0] = 1e-5\n",
    "tan = np.arctan(fy / fx)\n",
    "## Angle quantization\n",
    "angle = np.zeros_like(tan, dtype=np.uint8)\n",
    "angle[np.where((tan > -0.4142) & (tan <= 0.4142))] = 0\n",
    "angle[np.where((tan > 0.4142) & (tan < 2.4142))] = 45\n",
    "angle[np.where((tan >= 2.4142) | (tan <= -2.4142))] = 95\n",
    "angle[np.where((tan > -2.4142) & (tan <= -0.4142))] = 135\n",
    "\n",
    "out = angle.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.42. Cannyエッジ検出 (Step.2) 細線化\n",
    "\n",
    "ここでは3を実装する。\n",
    "\n",
    "Q.41で求めた勾配角度から、Non-maximum suppressionを行い、エッジ線を細くする（細線化）。\n",
    "\n",
    "Non-maximum suppression(NMS)とは非最大値以外を除去する作業の総称である。（他のタスクでもこの名前はよく出る）\n",
    "\n",
    "ここでは、注目している箇所の勾配角度の法線方向の隣接ピクセルの３つの勾配強度を比較して、最大値ならそのまま値をいじらずに、最大値でなければ強度を0にする、\n",
    "\n",
    "つまり、勾配強度edge(x,y)に注目している際に、勾配角度angle(x,y)によって次式のようにedge(x,y)を変更する。\n",
    "\n",
    "```bash\n",
    "if angle(x,y)  = 0\n",
    " if edge(x,y), edge(x-1,y), edge(x+1,y)で edge(x,y)が最大じゃない\n",
    "  then edge(x,y) = 0\n",
    "if angle(x,y)  = 45\n",
    " if edge(x,y), edge(x-1,y+1), edge(x+1,y-1)で edge(x,y)が最大じゃない\n",
    "  then edge(x,y) = 0\n",
    "if angle(x,y)  = 90\n",
    " if edge(x,y), edge(x,y-1), edge(x,y+1)で edge(x,y)が最大じゃない\n",
    "  then edge(x,y) = 0\n",
    "if angle(x,y)  = 135\n",
    " if edge(x,y), edge(x-1,y-1), edge(x+1,y+1)で edge(x,y)が最大じゃない\n",
    "  then edge(x,y) = 0\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg) |出力 (answer_42.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_41_50/imori.jpg)|![](./Question_41_50/answer_42.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "gau = np.zeros((H + pad*2, W + pad*2), dtype=np.float32)\n",
    "#gau[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float32)\n",
    "gau = np.pad(gray, (pad, pad), 'edge')\n",
    "tmp = gau.copy()\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float32)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = np.exp( -(x**2 + y**2) / (2* (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        gau[pad+y, pad+x] = np.sum(K * tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "## Sobel vertical\n",
    "KSV = np.array(((-1., -2., -1.), (0., 0., 0.), (1., 2., 1.)), dtype=np.float32)\n",
    "## Sobel horizontal\n",
    "KSH = np.array(((-1., 0., 1.), (-2., 0., 2.), (-1., 0., 1.)), dtype=np.float32)\n",
    "\n",
    "gau = gau[pad-1:H+pad+1, pad-1:W+pad+1]\n",
    "fy = np.zeros_like(gau, dtype=np.float32)\n",
    "fx = np.zeros_like(gau, dtype=np.float32)\n",
    "K_size = 3\n",
    "pad = K_size // 2\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        fy[pad+y, pad+x] = np.sum(KSV * gau[y:y+K_size, x:x+K_size])\n",
    "        fx[pad+y, pad+x] = np.sum(KSH * gau[y:y+K_size, x:x+K_size])\n",
    "        \n",
    "fx = fx[pad:pad+H, pad:pad+W]\n",
    "fy = fy[pad:pad+H, pad:pad+W]\n",
    "\n",
    "# Non-maximum suppression\n",
    "edge = np.sqrt(np.power(fx, 2) + np.power(fy, 2))\n",
    "fx[fx == 0] = 1e-5\n",
    "tan = np.arctan(fy / fx)\n",
    "## Angle quantization\n",
    "angle = np.zeros_like(tan, dtype=np.uint8)\n",
    "angle[np.where((tan > -0.4142) & (tan <= 0.4142))] = 0\n",
    "angle[np.where((tan > 0.4142) & (tan < 2.4142))] = 45\n",
    "angle[np.where((tan >= 2.4142) | (tan <= -2.4142))] = 95\n",
    "angle[np.where((tan > -2.4142) & (tan <= -0.4142))] = 135\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if angle[y, x] == 0:\n",
    "            dx1, dy1, dx2, dy2 = -1, 0, 1, 0\n",
    "        elif angle[y, x] == 45:\n",
    "            dx1, dy1, dx2, dy2 = -1, 1, 1, -1\n",
    "        elif angle[y, x] == 90:\n",
    "            dx1, dy1, dx2, dy2 = 0, -1, 0, 1\n",
    "        elif angle[y, x] == 135:\n",
    "            dx1, dy1, dx2, dy2 = -1, -1, 1, 1\n",
    "        if x == 0:\n",
    "            dx1 = max(dx1, 0)\n",
    "            dx2 = max(dx2, 0)\n",
    "        if x == W-1:\n",
    "            dx1 = min(dx1, 0)\n",
    "            dx2 = min(dx2, 0)\n",
    "        if y == 0:\n",
    "            dy1 = max(dy1, 0)\n",
    "            dy2 = max(dy2, 0)\n",
    "        if y == H-1:\n",
    "            dy1 = min(dy1, 0)\n",
    "            dy2 = min(dy2, 0)\n",
    "        if max(max(edge[y, x], edge[y+dy1, x+dx1]), edge[y+dy2, x+dx2]) != edge[y, x]:\n",
    "            edge[y, x] = 0\n",
    "            \n",
    "out = edge.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.43. Cannyエッジ検出 (Step.3) ヒステリシス閾処理\n",
    "\n",
    "ここでは4を実装する。これがCanny法の最後である。\n",
    "\n",
    "ここでは、閾値により勾配強度の二値化を行うがCanny法では二つの閾値(HT: high thoresholdとLT: low threshold)を用いる。\n",
    "\n",
    "はじめに、\n",
    "1. 勾配強度edge(x,y)がHTより大きい場合はedge(x,y)=255\n",
    "2. LTより小さい場合はedge(x,y)=0\n",
    "3.  LT < edge(x,y) < HTの時、周り８ピクセルの勾配強度でHTより大きい値が存在すれば、edge(x,y)=255\n",
    "\n",
    "ここでは、HT=100, LT=30とする。ちなみに閾値の値は結果を見ながら判断するしかない。\n",
    "\n",
    "以上のアルゴリズムによって、Canny法が行われる。\n",
    "\n",
    "|入力 (imori.jpg) |出力 (answer_43.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_41_50/imori.jpg)|![](./Question_41_50/answer_43.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "gau = np.zeros((H + pad*2, W + pad*2), dtype=np.float32)\n",
    "#gau[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float32)\n",
    "gau = np.pad(gray, (pad, pad), 'edge')\n",
    "tmp = gau.copy()\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float32)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = np.exp( -(x**2 + y**2) / (2* (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        gau[pad+y, pad+x] = np.sum(K * tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "## Sobel vertical\n",
    "KSV = np.array(((-1., -2., -1.), (0., 0., 0.), (1., 2., 1.)), dtype=np.float32)\n",
    "## Sobel horizontal\n",
    "KSH = np.array(((-1., 0., 1.), (-2., 0., 2.), (-1., 0., 1.)), dtype=np.float32)\n",
    "\n",
    "gau = gau[pad-1:H+pad+1, pad-1:W+pad+1]\n",
    "fy = np.zeros_like(gau, dtype=np.float32)\n",
    "fx = np.zeros_like(gau, dtype=np.float32)\n",
    "K_size = 3\n",
    "pad = K_size // 2\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        fy[pad+y, pad+x] = np.sum(KSV * gau[y:y+K_size, x:x+K_size])\n",
    "        fx[pad+y, pad+x] = np.sum(KSH * gau[y:y+K_size, x:x+K_size])\n",
    "        \n",
    "fx = fx[pad:pad+H, pad:pad+W]\n",
    "fy = fy[pad:pad+H, pad:pad+W]\n",
    "\n",
    "# Non-maximum suppression\n",
    "edge = np.sqrt(np.power(fx, 2) + np.power(fy, 2))\n",
    "fx[fx == 0] = 1e-5\n",
    "tan = np.arctan(fy / fx)\n",
    "## Angle quantization\n",
    "angle = np.zeros_like(tan, dtype=np.uint8)\n",
    "angle[np.where((tan > -0.4142) & (tan <= 0.4142))] = 0\n",
    "angle[np.where((tan > 0.4142) & (tan < 2.4142))] = 45\n",
    "angle[np.where((tan >= 2.4142) | (tan <= -2.4142))] = 95\n",
    "angle[np.where((tan > -2.4142) & (tan <= -0.4142))] = 135\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if angle[y, x] == 0:\n",
    "            dx1, dy1, dx2, dy2 = -1, 0, 1, 0\n",
    "        elif angle[y, x] == 45:\n",
    "            dx1, dy1, dx2, dy2 = -1, 1, 1, -1\n",
    "        elif angle[y, x] == 90:\n",
    "            dx1, dy1, dx2, dy2 = 0, -1, 0, 1\n",
    "        elif angle[y, x] == 135:\n",
    "            dx1, dy1, dx2, dy2 = -1, -1, 1, 1\n",
    "        if x == 0:\n",
    "            dx1 = max(dx1, 0)\n",
    "            dx2 = max(dx2, 0)\n",
    "        if x == W-1:\n",
    "            dx1 = min(dx1, 0)\n",
    "            dx2 = min(dx2, 0)\n",
    "        if y == 0:\n",
    "            dy1 = max(dy1, 0)\n",
    "            dy2 = max(dy2, 0)\n",
    "        if y == H-1:\n",
    "            dy1 = min(dy1, 0)\n",
    "            dy2 = min(dy2, 0)\n",
    "        if max(max(edge[y, x], edge[y+dy1, x+dx1]), edge[y+dy2, x+dx2]) != edge[y, x]:\n",
    "            edge[y, x] = 0\n",
    "\n",
    "\n",
    "# Histeresis threshold\n",
    "HT = 100\n",
    "LT = 30\n",
    "edge[edge >= HT] = 255\n",
    "edge[edge <= LT] = 0\n",
    "\n",
    "_edge = np.zeros((H+2, W+2), dtype=np.float32)\n",
    "_edge[1:H+1, 1:W+1] = edge\n",
    "\n",
    "## 8 - Nearest neighbor\n",
    "nn = np.array(((1., 1., 1.), (1., 0., 1.), (1., 1., 1.)), dtype=np.float32)\n",
    "\n",
    "for y in range(1, H+2):\n",
    "    for x in range(1, W+2):\n",
    "        if _edge[y, x] < LT or _edge[y, x] > HT:\n",
    "            continue\n",
    "        if np.max(_edge[y-1:y+2, x-1:x+2] * nn) >= HT:\n",
    "            _edge[y, x] = 255\n",
    "        else:\n",
    "            _edge[y, x] = 0\n",
    "\n",
    "edge = _edge[1:H+1, 1:W+1]\n",
    "            \n",
    "out = edge.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.44. Hough変換・直線検出 (Step.1) Hough変換\n",
    "\n",
    "Q.44 - 46 ではHough変換を用いた直線検出を行う。\n",
    "\n",
    "Hough変換とは、座標を直交座標から極座標に変換することにより数式に沿って直線や円など一定の形状を検出する手法である。\n",
    "ある直線状の点では極座標に変換すると一定のr, tにおいて交わる。\n",
    "その点が検出すべき直線を表すパラメータであり、このパラメータを逆変換すると直線の方程式を求めることができる。\n",
    "\n",
    "方法としては、\n",
    "1. エッジ画像からエッジのピクセルにおいてHough変換を行う。\n",
    "2. Hough変換後の値のヒストグラムをとり、極大点を選ぶ。\n",
    "3. 極大点のr, tの値をHough逆変換して検出した直線のパラメータを得る。\n",
    "\n",
    "となる。\n",
    "\n",
    "ここでは、1のHough変換を行いヒストグラムを作成する。\n",
    "\n",
    "アルゴリズムは、\n",
    "\n",
    "1. 画像の対角線の長さrmaxを求める\n",
    "2. エッジ箇所(x,y)において、t = 0-179で一度ずつtを変えながら、次式によりHough変換を行う\n",
    "\n",
    "```bash\n",
    "r = x * cos(t) + y * sin(t)\n",
    "```\n",
    "3. 180 x rmaxのサイズの表を用意し、1で得たtable(t, r) に1を足す\n",
    "\n",
    "これはすなわち投票(ボーディング)であり、一定の箇所に投票が集中する。\n",
    "\n",
    "今回は*torino.jpg*を用いて、ボーディングした表を図示せよ。\n",
    "Cannyのパラメータは, gaussian filter(5x5, s=1.4), HT = 100, LT = 30で使用せよ。\n",
    "\n",
    "|入力 (thorino.jpg) |出力 (answer_44.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_41_50/thorino.jpg)|![](./Question_41_50/answer_44.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"thorino.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "gau = np.zeros((H + pad*2, W + pad*2), dtype=np.float32)\n",
    "#gau[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float32)\n",
    "gau = np.pad(gray, (pad, pad), 'edge')\n",
    "tmp = gau.copy()\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float32)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = np.exp( -(x**2 + y**2) / (2* (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        gau[pad+y, pad+x] = np.sum(K * tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "## Sobel vertical\n",
    "KSV = np.array(((-1., -2., -1.), (0., 0., 0.), (1., 2., 1.)), dtype=np.float32)\n",
    "## Sobel horizontal\n",
    "KSH = np.array(((-1., 0., 1.), (-2., 0., 2.), (-1., 0., 1.)), dtype=np.float32)\n",
    "\n",
    "gau = gau[pad-1:H+pad+1, pad-1:W+pad+1]\n",
    "fy = np.zeros_like(gau, dtype=np.float32)\n",
    "fx = np.zeros_like(gau, dtype=np.float32)\n",
    "K_size = 3\n",
    "pad = K_size // 2\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        fy[pad+y, pad+x] = np.sum(KSV * gau[y:y+K_size, x:x+K_size])\n",
    "        fx[pad+y, pad+x] = np.sum(KSH * gau[y:y+K_size, x:x+K_size])\n",
    "        \n",
    "fx = fx[pad:pad+H, pad:pad+W]\n",
    "fy = fy[pad:pad+H, pad:pad+W]\n",
    "\n",
    "# Non-maximum suppression\n",
    "edge = np.sqrt(np.power(fx, 2) + np.power(fy, 2))\n",
    "fx[fx == 0] = 1e-5\n",
    "tan = np.arctan(fy / fx)\n",
    "## Angle quantization\n",
    "angle = np.zeros_like(tan, dtype=np.uint8)\n",
    "angle[np.where((tan > -0.4142) & (tan <= 0.4142))] = 0\n",
    "angle[np.where((tan > 0.4142) & (tan < 2.4142))] = 45\n",
    "angle[np.where((tan >= 2.4142) | (tan <= -2.4142))] = 95\n",
    "angle[np.where((tan > -2.4142) & (tan <= -0.4142))] = 135\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if angle[y, x] == 0:\n",
    "            dx1, dy1, dx2, dy2 = -1, 0, 1, 0\n",
    "        elif angle[y, x] == 45:\n",
    "            dx1, dy1, dx2, dy2 = -1, 1, 1, -1\n",
    "        elif angle[y, x] == 90:\n",
    "            dx1, dy1, dx2, dy2 = 0, -1, 0, 1\n",
    "        elif angle[y, x] == 135:\n",
    "            dx1, dy1, dx2, dy2 = -1, -1, 1, 1\n",
    "        if x == 0:\n",
    "            dx1 = max(dx1, 0)\n",
    "            dx2 = max(dx2, 0)\n",
    "        if x == W-1:\n",
    "            dx1 = min(dx1, 0)\n",
    "            dx2 = min(dx2, 0)\n",
    "        if y == 0:\n",
    "            dy1 = max(dy1, 0)\n",
    "            dy2 = max(dy2, 0)\n",
    "        if y == H-1:\n",
    "            dy1 = min(dy1, 0)\n",
    "            dy2 = min(dy2, 0)\n",
    "        if max(max(edge[y, x], edge[y+dy1, x+dx1]), edge[y+dy2, x+dx2]) != edge[y, x]:\n",
    "            edge[y, x] = 0\n",
    "\n",
    "\n",
    "# Histeresis threshold\n",
    "HT = 100\n",
    "LT = 30\n",
    "edge[edge >= HT] = 255\n",
    "edge[edge <= LT] = 0\n",
    "\n",
    "_edge = np.zeros((H+2, W+2), dtype=np.float32)\n",
    "_edge[1:H+1, 1:W+1] = edge\n",
    "\n",
    "## 8 - Nearest neighbor\n",
    "nn = np.array(((1., 1., 1.), (1., 0., 1.), (1., 1., 1.)), dtype=np.float32)\n",
    "\n",
    "for y in range(1, H+2):\n",
    "    for x in range(1, W+2):\n",
    "        if _edge[y, x] < LT or _edge[y, x] > HT:\n",
    "            continue\n",
    "        if np.max(_edge[y-1:y+2, x-1:x+2] * nn) >= HT:\n",
    "            _edge[y, x] = 255\n",
    "        else:\n",
    "            _edge[y, x] = 0\n",
    "\n",
    "edge = _edge[1:H+1, 1:W+1].astype(np.uint8)\n",
    "            \n",
    "## Canny finish\n",
    "\n",
    "# Hough\n",
    "\n",
    "## Voting\n",
    "drho = 1\n",
    "dtheta = 1\n",
    "rho_max = np.ceil(np.sqrt(H**2 + W**2)).astype(np.int)\n",
    "hough = np.zeros((rho_max, 180), dtype=np.int)\n",
    "\n",
    "ind = np.where(edge == 255)\n",
    "\n",
    "## hough transformation\n",
    "for y, x in zip(ind[0], ind[1]):\n",
    "    for theta in range(0, 180, dtheta):\n",
    "        t = np.pi / 180 * theta\n",
    "        rho = int(x * np.cos(t) + y * np.sin(t))\n",
    "        hough[rho, theta] += 1\n",
    "          \n",
    "out = hough.astype(np.uint8)\n",
    "            \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.45. Hough変換・直線検出 (Step.2) NMS\n",
    "\n",
    "ここでは2を実装する。\n",
    "\n",
    "Q.44で得られた表では、ある一定の箇所付近に多く投票される。\n",
    "ここでは、その付近の極大値を抜き出す操作を行え。\n",
    "\n",
    "今回はボーディングが多い箇所を上位10個抜き出し、図示せよ。\n",
    "\n",
    "NMSのアルゴリズムは、\n",
    "1. 表において、周囲8マス(8近傍)より注目ピクセルの得票数が多ければそのまま。\n",
    "2. 注目ピクセルの値が少なければ0にする。\n",
    "\n",
    "|入力 (thorino.jpg) |出力 (answer_45.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_41_50/thorino.jpg)|![](./Question_41_50/answer_45.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"thorino.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "gau = np.zeros((H + pad*2, W + pad*2), dtype=np.float32)\n",
    "#gau[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float32)\n",
    "gau = np.pad(gray, (pad, pad), 'edge')\n",
    "tmp = gau.copy()\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float32)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = np.exp( -(x**2 + y**2) / (2* (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        gau[pad+y, pad+x] = np.sum(K * tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "## Sobel vertical\n",
    "KSV = np.array(((-1., -2., -1.), (0., 0., 0.), (1., 2., 1.)), dtype=np.float32)\n",
    "## Sobel horizontal\n",
    "KSH = np.array(((-1., 0., 1.), (-2., 0., 2.), (-1., 0., 1.)), dtype=np.float32)\n",
    "\n",
    "gau = gau[pad-1:H+pad+1, pad-1:W+pad+1]\n",
    "fy = np.zeros_like(gau, dtype=np.float32)\n",
    "fx = np.zeros_like(gau, dtype=np.float32)\n",
    "K_size = 3\n",
    "pad = K_size // 2\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        fy[pad+y, pad+x] = np.sum(KSV * gau[y:y+K_size, x:x+K_size])\n",
    "        fx[pad+y, pad+x] = np.sum(KSH * gau[y:y+K_size, x:x+K_size])\n",
    "        \n",
    "fx = fx[pad:pad+H, pad:pad+W]\n",
    "fy = fy[pad:pad+H, pad:pad+W]\n",
    "\n",
    "# Non-maximum suppression\n",
    "edge = np.sqrt(np.power(fx, 2) + np.power(fy, 2))\n",
    "fx[fx == 0] = 1e-5\n",
    "tan = np.arctan(fy / fx)\n",
    "## Angle quantization\n",
    "angle = np.zeros_like(tan, dtype=np.uint8)\n",
    "angle[np.where((tan > -0.4142) & (tan <= 0.4142))] = 0\n",
    "angle[np.where((tan > 0.4142) & (tan < 2.4142))] = 45\n",
    "angle[np.where((tan >= 2.4142) | (tan <= -2.4142))] = 95\n",
    "angle[np.where((tan > -2.4142) & (tan <= -0.4142))] = 135\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if angle[y, x] == 0:\n",
    "            dx1, dy1, dx2, dy2 = -1, 0, 1, 0\n",
    "        elif angle[y, x] == 45:\n",
    "            dx1, dy1, dx2, dy2 = -1, 1, 1, -1\n",
    "        elif angle[y, x] == 90:\n",
    "            dx1, dy1, dx2, dy2 = 0, -1, 0, 1\n",
    "        elif angle[y, x] == 135:\n",
    "            dx1, dy1, dx2, dy2 = -1, -1, 1, 1\n",
    "        if x == 0:\n",
    "            dx1 = max(dx1, 0)\n",
    "            dx2 = max(dx2, 0)\n",
    "        if x == W-1:\n",
    "            dx1 = min(dx1, 0)\n",
    "            dx2 = min(dx2, 0)\n",
    "        if y == 0:\n",
    "            dy1 = max(dy1, 0)\n",
    "            dy2 = max(dy2, 0)\n",
    "        if y == H-1:\n",
    "            dy1 = min(dy1, 0)\n",
    "            dy2 = min(dy2, 0)\n",
    "        if max(max(edge[y, x], edge[y+dy1, x+dx1]), edge[y+dy2, x+dx2]) != edge[y, x]:\n",
    "            edge[y, x] = 0\n",
    "\n",
    "\n",
    "# Histeresis threshold\n",
    "HT = 100\n",
    "LT = 30\n",
    "edge[edge >= HT] = 255\n",
    "edge[edge <= LT] = 0\n",
    "\n",
    "_edge = np.zeros((H+2, W+2), dtype=np.float32)\n",
    "_edge[1:H+1, 1:W+1] = edge\n",
    "\n",
    "## 8 - Nearest neighbor\n",
    "nn = np.array(((1., 1., 1.), (1., 0., 1.), (1., 1., 1.)), dtype=np.float32)\n",
    "\n",
    "for y in range(1, H+2):\n",
    "    for x in range(1, W+2):\n",
    "        if _edge[y, x] < LT or _edge[y, x] > HT:\n",
    "            continue\n",
    "        if np.max(_edge[y-1:y+2, x-1:x+2] * nn) >= HT:\n",
    "            _edge[y, x] = 255\n",
    "        else:\n",
    "            _edge[y, x] = 0\n",
    "\n",
    "edge = _edge[1:H+1, 1:W+1].astype(np.uint8)\n",
    "\n",
    "## Canny finish\n",
    "\n",
    "# Hough\n",
    "\n",
    "## Voting\n",
    "drho = 1\n",
    "dtheta = 1\n",
    "rho_max = np.ceil(np.sqrt(H**2 + W**2)).astype(np.int)\n",
    "hough = np.zeros((rho_max, 180), dtype=np.int)\n",
    "\n",
    "ind = np.where(edge == 255)\n",
    "\n",
    "## hough transformation\n",
    "for y, x in zip(ind[0], ind[1]):\n",
    "    for theta in range(0, 180, dtheta):\n",
    "        t = np.pi / 180 * theta\n",
    "        rho = int(x * np.cos(t) + y * np.sin(t))\n",
    "        hough[rho, theta] += 1\n",
    "\n",
    "plt.imshow(hough, cmap='gray')\n",
    "\n",
    "## non maximum suppression\n",
    "for y in range(rho_max):\n",
    "    for x in range(180):\n",
    "        x1 = max(x-1, 0)\n",
    "        x2 = min(x+2, 180)\n",
    "        y1 = max(y-1, 0)\n",
    "        y2 = min(y+2, rho_max)\n",
    "        if np.max(hough[y1:y2, x1:x2]) == hough[y,x] and hough[y, x] != 0:\n",
    "            pass\n",
    "            #hough[y,x] = 255\n",
    "        else:\n",
    "            hough[y,x] = 0\n",
    "ind_x = np.argsort(hough.ravel())[::-1][:10]\n",
    "ind_y = ind_x.copy()\n",
    "thetas = ind_x % 180\n",
    "rhos = ind_y // 180\n",
    "_hough = np.zeros_like(hough, dtype=np.int)\n",
    "_hough[rhos, thetas] = 255\n",
    "        \n",
    "out = _hough.astype(np.uint8)\n",
    "            \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.46. Hough変換・直線検出 (Step.3) Hough逆変換\n",
    "\n",
    "ここではQ.45.で得られた極大値をHough逆変換をして直線を描画する。これで、Hough変換による直線検出が完了する。\n",
    "\n",
    "アルゴリズムは、\n",
    "1. 極大点(r, t)を次式で逆変換する。\n",
    "\n",
    "```bash\n",
    "y = - cos(t) / sin(t) * x + r / sin(t)\n",
    "x = - sin(t) / cos(t) * y + r / cos(t)\n",
    "```\n",
    "\n",
    "2. 1の逆変換を極大点ごとにy = 0 - H-1, x = 0 - W-1 で行い、入力画像に検出した直線を描画せよ。\n",
    "ただし、描画するのは赤線(R,G,B) = (255, 0, 0)とする。\n",
    "\n",
    "|入力 (thorino.jpg) |出力 (answer_46.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_41_50/thorino.jpg)|![](./Question_41_50/answer_46.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"thorino.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "gau = np.zeros((H + pad*2, W + pad*2), dtype=np.float32)\n",
    "#gau[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float32)\n",
    "gau = np.pad(gray, (pad, pad), 'edge')\n",
    "tmp = gau.copy()\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float32)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = np.exp( -(x**2 + y**2) / (2* (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        gau[pad+y, pad+x] = np.sum(K * tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "## Sobel vertical\n",
    "KSV = np.array(((-1., -2., -1.), (0., 0., 0.), (1., 2., 1.)), dtype=np.float32)\n",
    "## Sobel horizontal\n",
    "KSH = np.array(((-1., 0., 1.), (-2., 0., 2.), (-1., 0., 1.)), dtype=np.float32)\n",
    "\n",
    "gau = gau[pad-1:H+pad+1, pad-1:W+pad+1]\n",
    "fy = np.zeros_like(gau, dtype=np.float32)\n",
    "fx = np.zeros_like(gau, dtype=np.float32)\n",
    "K_size = 3\n",
    "pad = K_size // 2\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        fy[pad+y, pad+x] = np.sum(KSV * gau[y:y+K_size, x:x+K_size])\n",
    "        fx[pad+y, pad+x] = np.sum(KSH * gau[y:y+K_size, x:x+K_size])\n",
    "        \n",
    "fx = fx[pad:pad+H, pad:pad+W]\n",
    "fy = fy[pad:pad+H, pad:pad+W]\n",
    "\n",
    "# Non-maximum suppression\n",
    "edge = np.sqrt(np.power(fx, 2) + np.power(fy, 2))\n",
    "fx[fx == 0] = 1e-5\n",
    "tan = np.arctan(fy / fx)\n",
    "## Angle quantization\n",
    "angle = np.zeros_like(tan, dtype=np.uint8)\n",
    "angle[np.where((tan > -0.4142) & (tan <= 0.4142))] = 0\n",
    "angle[np.where((tan > 0.4142) & (tan < 2.4142))] = 45\n",
    "angle[np.where((tan >= 2.4142) | (tan <= -2.4142))] = 95\n",
    "angle[np.where((tan > -2.4142) & (tan <= -0.4142))] = 135\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if angle[y, x] == 0:\n",
    "            dx1, dy1, dx2, dy2 = -1, 0, 1, 0\n",
    "        elif angle[y, x] == 45:\n",
    "            dx1, dy1, dx2, dy2 = -1, 1, 1, -1\n",
    "        elif angle[y, x] == 90:\n",
    "            dx1, dy1, dx2, dy2 = 0, -1, 0, 1\n",
    "        elif angle[y, x] == 135:\n",
    "            dx1, dy1, dx2, dy2 = -1, -1, 1, 1\n",
    "        if x == 0:\n",
    "            dx1 = max(dx1, 0)\n",
    "            dx2 = max(dx2, 0)\n",
    "        if x == W-1:\n",
    "            dx1 = min(dx1, 0)\n",
    "            dx2 = min(dx2, 0)\n",
    "        if y == 0:\n",
    "            dy1 = max(dy1, 0)\n",
    "            dy2 = max(dy2, 0)\n",
    "        if y == H-1:\n",
    "            dy1 = min(dy1, 0)\n",
    "            dy2 = min(dy2, 0)\n",
    "        if max(max(edge[y, x], edge[y+dy1, x+dx1]), edge[y+dy2, x+dx2]) != edge[y, x]:\n",
    "            edge[y, x] = 0\n",
    "\n",
    "\n",
    "# Histeresis threshold\n",
    "HT = 100\n",
    "LT = 30\n",
    "edge[edge >= HT] = 255\n",
    "edge[edge <= LT] = 0\n",
    "\n",
    "_edge = np.zeros((H+2, W+2), dtype=np.float32)\n",
    "_edge[1:H+1, 1:W+1] = edge\n",
    "\n",
    "## 8 - Nearest neighbor\n",
    "nn = np.array(((1., 1., 1.), (1., 0., 1.), (1., 1., 1.)), dtype=np.float32)\n",
    "\n",
    "for y in range(1, H+2):\n",
    "    for x in range(1, W+2):\n",
    "        if _edge[y, x] < LT or _edge[y, x] > HT:\n",
    "            continue\n",
    "        if np.max(_edge[y-1:y+2, x-1:x+2] * nn) >= HT:\n",
    "            _edge[y, x] = 255\n",
    "        else:\n",
    "            _edge[y, x] = 0\n",
    "\n",
    "edge = _edge[1:H+1, 1:W+1].astype(np.uint8)\n",
    "\n",
    "## Canny finish\n",
    "\n",
    "# Hough\n",
    "\n",
    "## Voting\n",
    "drho = 1\n",
    "dtheta = 1\n",
    "rho_max = np.ceil(np.sqrt(H**2 + W**2)).astype(np.int)\n",
    "hough = np.zeros((rho_max, 180), dtype=np.int)\n",
    "\n",
    "ind = np.where(edge == 255)\n",
    "\n",
    "## hough transformation\n",
    "for y, x in zip(ind[0], ind[1]):\n",
    "    for theta in range(0, 180, dtheta):\n",
    "        t = np.pi / 180 * theta\n",
    "        rho = int(x * np.cos(t) + y * np.sin(t))\n",
    "        hough[rho, theta] += 1\n",
    "\n",
    "plt.imshow(hough, cmap='gray')\n",
    "\n",
    "## non maximum suppression\n",
    "for y in range(rho_max):\n",
    "    for x in range(180):\n",
    "        x1 = max(x-1, 0)\n",
    "        x2 = min(x+2, 180)\n",
    "        y1 = max(y-1, 0)\n",
    "        y2 = min(y+2, rho_max)\n",
    "        if np.max(hough[y1:y2, x1:x2]) == hough[y,x] and hough[y, x] != 0:\n",
    "            pass\n",
    "            #hough[y,x] = 255\n",
    "        else:\n",
    "            hough[y,x] = 0\n",
    "ind_x = np.argsort(hough.ravel())[::-1][:10]\n",
    "ind_y = ind_x.copy()\n",
    "thetas = ind_x % 180\n",
    "rhos = ind_y // 180\n",
    "#_hough = np.zeros_like(hough, dtype=np.int)\n",
    "#_hough[rhos, thetas] = 255\n",
    "\n",
    "## Inverse hough transformation\n",
    "\n",
    "out = img.copy()\n",
    "\n",
    "for theta, rho in zip(thetas, rhos):\n",
    "    t = np.pi / 180. * theta\n",
    "    for x in range(W):\n",
    "        if np.sin(t) != 0:\n",
    "            y = - (np.cos(t) / np.sin(t)) * x + rho / np.sin(t)\n",
    "            y = int(y)\n",
    "            if y >= H or y < 0:\n",
    "                continue\n",
    "            out[y, x] = [0, 0, 255]\n",
    "    for y in range(H):\n",
    "        if np.cos(t) != 0:\n",
    "            x = - (np.sin(t) / np.cos(t)) * y + rho / np.cos(t)\n",
    "            x = int(x)\n",
    "            if x >= W or x < 0:\n",
    "                continue\n",
    "            out[y, x] = [0, 0, 255]\n",
    "          \n",
    "out = out.astype(np.uint8)\n",
    "            \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.47. モルフォロジー処理(膨張)\n",
    "\n",
    "*imori.jpg*を大津の二値化したものに、モルフォロジー処理による膨張を2回行え。\n",
    "\n",
    "モルフォロジー処理にとは二値化画像の白(255)マス部分を4近傍(上下左右1マス)に膨張、または1マスだけ収縮させる処理をいう。\n",
    "\n",
    "この膨張と収縮を何度も繰り返すことで1マスだけに存在する白マスを消したり(Q.49. オープニング処理)、本来つながってほしい白マスを結合させたりできる(Q.50. クロージング処理)。\n",
    "\n",
    "モルフォロジー処理の膨張(Dolation)アルゴリズムは、\n",
    "注目画素I(x, y)=0で、I(x, y-1), I(x-1, y), I(x+1, y), I(x, y+1)のどれか一つが255なら、I(x, y) = 255 とする。\n",
    "\n",
    "\n",
    "つまり、上の処理を2回行えば2マス分膨張できることになる。\n",
    "\n",
    "例えば、[[0,1,0], [1,0,1], [0,1,0]] のフィルタを掛けた和が255を超えれば膨張である、と考える。\n",
    "\n",
    "|入力 (imori.jpg) |大津の二値化(answer_4.jpg)|出力 (answer_47.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_41_50/imori.jpg)|![](./Question_41_50/answer_4.jpg)|![](./Question_41_50/answer_47.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Otsu binary\n",
    "## Grayscale\n",
    "out = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "## Determine threshold of Otsu's binarization\n",
    "max_sigma = 0\n",
    "max_t = 0\n",
    "\n",
    "for _t in range(1, 255):\n",
    "    v0 = out[np.where(out < _t)]\n",
    "    m0 = np.mean(v0) if len(v0) > 0 else 0.\n",
    "    w0 = len(v0) / (H * W)\n",
    "    v1 = out[np.where(out >= _t)]\n",
    "    m1 = np.mean(v1) if len(v1) > 0 else 0.\n",
    "    w1 = len(v1) / (H * W)\n",
    "    sigma = w0 * w1 * ((m0 - m1) ** 2)\n",
    "    if sigma > max_sigma:\n",
    "        max_sigma = sigma\n",
    "        max_t = _t\n",
    "\n",
    "## Binarization\n",
    "#print(\"threshold >>\", max_t)\n",
    "th = max_t\n",
    "out[out < th] = 0\n",
    "out[out >= th] = 255\n",
    "\n",
    "\n",
    "# Morphology - dilate\n",
    "Dil_time = 2\n",
    "MF = np.array(((0, 1, 0),\n",
    "               (1, 0, 1),\n",
    "               (0, 1, 0)), dtype=np.int)\n",
    "\n",
    "\n",
    "for i in range(Dil_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) >= 255:\n",
    "                out[y-1, x-1] = 255\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.48. モルフォロジー処理(収縮)\n",
    "\n",
    "*imori.jpg*を大津の二値化したものに、モルフォロジー処理による収縮を2回行え。\n",
    "\n",
    "モルフォロジー処理の膨張(Erosion)アルゴリズムは、\n",
    "注目画素I(x, y)=255で、I(x, y-1), I(x-1, y), I(x+1, y), I(x, y+1)のどれか一つが255なら、I(x, y) = 0 とする。\n",
    "\n",
    "例えば、[[0,1,0], [1,0,1], [0,1,0]] のフィルタを掛けた和が255*4未満なら収縮である、と考える。\n",
    "\n",
    "|入力 (imori.jpg) |大津の二値化(answer_4.jpg)|出力 (answer_48.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_41_50/imori.jpg)|![](./Question_41_50/answer_4.jpg)|![](./Question_41_50/answer_48.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Otsu binary\n",
    "## Grayscale\n",
    "out = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "## Determine threshold of Otsu's binarization\n",
    "max_sigma = 0\n",
    "max_t = 0\n",
    "\n",
    "for _t in range(1, 255):\n",
    "    v0 = out[np.where(out < _t)]\n",
    "    m0 = np.mean(v0) if len(v0) > 0 else 0.\n",
    "    w0 = len(v0) / (H * W)\n",
    "    v1 = out[np.where(out >= _t)]\n",
    "    m1 = np.mean(v1) if len(v1) > 0 else 0.\n",
    "    w1 = len(v1) / (H * W)\n",
    "    sigma = w0 * w1 * ((m0 - m1) ** 2)\n",
    "    if sigma > max_sigma:\n",
    "        max_sigma = sigma\n",
    "        max_t = _t\n",
    "\n",
    "## Binarization\n",
    "#print(\"threshold >>\", max_t)\n",
    "th = max_t\n",
    "out[out < th] = 0\n",
    "out[out >= th] = 255\n",
    "\n",
    "\n",
    "# Morphology filter\n",
    "MF = np.array(((0, 1, 0),\n",
    "               (1, 0, 1),\n",
    "               (0, 1, 0)), dtype=np.int)\n",
    "\n",
    "# Morphology - erode\n",
    "Erode_time = 2\n",
    "\n",
    "for i in range(Erode_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) < 255*4:\n",
    "                out[y-1, x-1] = 0\n",
    "\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.49. オープニング処理\n",
    "\n",
    "**大津の二値化後**に、オープニング処理(N=1)を行え。\n",
    "\n",
    "クロージング処理とは、モルフォロジー処理の収縮をN回行った後に膨張をN回行う処理である。\n",
    "\n",
    "クロージング処理により、一つだけ余分に存在する画素などを削除できる。\n",
    "\n",
    "|入力 (imori.jpg) |大津の二値化(answer_4.jpg)|出力 (answer_49.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_41_50/imori.jpg)|![](./Question_41_50/answer_4.jpg)|![](./Question_41_50/answer_49.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Otsu binary\n",
    "## Grayscale\n",
    "out = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "## Determine threshold of Otsu's binarization\n",
    "max_sigma = 0\n",
    "max_t = 0\n",
    "\n",
    "for _t in range(1, 255):\n",
    "    v0 = out[np.where(out < _t)]\n",
    "    m0 = np.mean(v0) if len(v0) > 0 else 0.\n",
    "    w0 = len(v0) / (H * W)\n",
    "    v1 = out[np.where(out >= _t)]\n",
    "    m1 = np.mean(v1) if len(v1) > 0 else 0.\n",
    "    w1 = len(v1) / (H * W)\n",
    "    sigma = w0 * w1 * ((m0 - m1) ** 2)\n",
    "    if sigma > max_sigma:\n",
    "        max_sigma = sigma\n",
    "        max_t = _t\n",
    "\n",
    "## Binarization\n",
    "#print(\"threshold >>\", max_t)\n",
    "th = max_t\n",
    "out[out < th] = 0\n",
    "out[out >= th] = 255\n",
    "\n",
    "# Morphology filter\n",
    "MF = np.array(((0, 1, 0),\n",
    "               (1, 0, 1),\n",
    "               (0, 1, 0)), dtype=np.int)\n",
    "\n",
    "# Morphology - erode\n",
    "Erode_time = 1\n",
    "\n",
    "for i in range(Erode_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) < 255*4:\n",
    "                out[y-1, x-1] = 0\n",
    "\n",
    "# Morphology - dilate\n",
    "Dil_time = 1\n",
    "\n",
    "for i in range(Dil_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) >= 255:\n",
    "                out[y-1, x-1] = 255\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.50. クロージング処理\n",
    "\n",
    "**Canny検出した後**に、クロージング処理(N=1)を行え。\n",
    "\n",
    "クロージング処理とは、モルフォロジー処理の膨張をN回行った後に収縮をN回行う処理である。\n",
    "\n",
    "クロージング処理により、途中で途切れた画素を結合することができる。\n",
    "\n",
    "|入力 (imori.jpg) |Canny(answer_43.jpg)|出力 (answer_50.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_41_50/imori.jpg)|![](./Question_41_50/answer_43.jpg)|![](./Question_41_50/answer_50.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Gray\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Gaussian Filter\n",
    "K_size = 5\n",
    "sigma = 1.4\n",
    "\n",
    "## Zero padding\n",
    "pad = K_size // 2\n",
    "gau = np.zeros((H + pad*2, W + pad*2), dtype=np.float32)\n",
    "#gau[pad:pad+H, pad:pad+W] = gray.copy().astype(np.float32)\n",
    "gau = np.pad(gray, (pad, pad), 'edge')\n",
    "tmp = gau.copy()\n",
    "\n",
    "## Kernel\n",
    "K = np.zeros((K_size, K_size), dtype=np.float32)\n",
    "for x in range(-pad, -pad+K_size):\n",
    "    for y in range(-pad, -pad+K_size):\n",
    "        K[y+pad, x+pad] = np.exp( -(x**2 + y**2) / (2* (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        gau[pad+y, pad+x] = np.sum(K * tmp[y:y+K_size, x:x+K_size])\n",
    "\n",
    "## Sobel vertical\n",
    "KSV = np.array(((-1., -2., -1.), (0., 0., 0.), (1., 2., 1.)), dtype=np.float32)\n",
    "## Sobel horizontal\n",
    "KSH = np.array(((-1., 0., 1.), (-2., 0., 2.), (-1., 0., 1.)), dtype=np.float32)\n",
    "\n",
    "gau = gau[pad-1:H+pad+1, pad-1:W+pad+1]\n",
    "fy = np.zeros_like(gau, dtype=np.float32)\n",
    "fx = np.zeros_like(gau, dtype=np.float32)\n",
    "K_size = 3\n",
    "pad = K_size // 2\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        fy[pad+y, pad+x] = np.sum(KSV * gau[y:y+K_size, x:x+K_size])\n",
    "        fx[pad+y, pad+x] = np.sum(KSH * gau[y:y+K_size, x:x+K_size])\n",
    "        \n",
    "fx = fx[pad:pad+H, pad:pad+W]\n",
    "fy = fy[pad:pad+H, pad:pad+W]\n",
    "\n",
    "# Non-maximum suppression\n",
    "edge = np.sqrt(np.power(fx, 2) + np.power(fy, 2))\n",
    "fx[fx == 0] = 1e-5\n",
    "tan = np.arctan(fy / fx)\n",
    "## Angle quantization\n",
    "angle = np.zeros_like(tan, dtype=np.uint8)\n",
    "angle[np.where((tan > -0.4142) & (tan <= 0.4142))] = 0\n",
    "angle[np.where((tan > 0.4142) & (tan < 2.4142))] = 45\n",
    "angle[np.where((tan >= 2.4142) | (tan <= -2.4142))] = 95\n",
    "angle[np.where((tan > -2.4142) & (tan <= -0.4142))] = 135\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if angle[y, x] == 0:\n",
    "            dx1, dy1, dx2, dy2 = -1, 0, 1, 0\n",
    "        elif angle[y, x] == 45:\n",
    "            dx1, dy1, dx2, dy2 = -1, 1, 1, -1\n",
    "        elif angle[y, x] == 90:\n",
    "            dx1, dy1, dx2, dy2 = 0, -1, 0, 1\n",
    "        elif angle[y, x] == 135:\n",
    "            dx1, dy1, dx2, dy2 = -1, -1, 1, 1\n",
    "        if x == 0:\n",
    "            dx1 = max(dx1, 0)\n",
    "            dx2 = max(dx2, 0)\n",
    "        if x == W-1:\n",
    "            dx1 = min(dx1, 0)\n",
    "            dx2 = min(dx2, 0)\n",
    "        if y == 0:\n",
    "            dy1 = max(dy1, 0)\n",
    "            dy2 = max(dy2, 0)\n",
    "        if y == H-1:\n",
    "            dy1 = min(dy1, 0)\n",
    "            dy2 = min(dy2, 0)\n",
    "        if max(max(edge[y, x], edge[y+dy1, x+dx1]), edge[y+dy2, x+dx2]) != edge[y, x]:\n",
    "            edge[y, x] = 0\n",
    "\n",
    "\n",
    "# Histeresis threshold\n",
    "HT = 100\n",
    "LT = 30\n",
    "edge[edge >= HT] = 255\n",
    "edge[edge <= LT] = 0\n",
    "\n",
    "_edge = np.zeros((H+2, W+2), dtype=np.float32)\n",
    "_edge[1:H+1, 1:W+1] = edge\n",
    "\n",
    "## 8 - Nearest neighbor\n",
    "nn = np.array(((1., 1., 1.), (1., 0., 1.), (1., 1., 1.)), dtype=np.float32)\n",
    "\n",
    "for y in range(1, H+2):\n",
    "    for x in range(1, W+2):\n",
    "        if _edge[y, x] < LT or _edge[y, x] > HT:\n",
    "            continue\n",
    "        if np.max(_edge[y-1:y+2, x-1:x+2] * nn) >= HT:\n",
    "            _edge[y, x] = 255\n",
    "        else:\n",
    "            _edge[y, x] = 0\n",
    "\n",
    "edge = _edge[1:H+1, 1:W+1]\n",
    "            \n",
    "out = edge.astype(np.uint8)\n",
    "\n",
    "\n",
    "# Morphology filter\n",
    "MF = np.array(((0, 1, 0),\n",
    "               (1, 0, 1),\n",
    "               (0, 1, 0)), dtype=np.int)\n",
    "\n",
    "# Morphology - dilate\n",
    "Dil_time = 1\n",
    "\n",
    "for i in range(Dil_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) >= 255:\n",
    "                out[y-1, x-1] = 255\n",
    "\n",
    "# Morphology - erode\n",
    "Erode_time = 1\n",
    "\n",
    "for i in range(Erode_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) < 255*4:\n",
    "                out[y-1, x-1] = 0\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 51 - 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.51. モルフォロジー勾配\n",
    "\n",
    "大津の二値化を行った後、モルフォロジー勾配を求めよ。\n",
    "\n",
    "モルフォロジー勾配とはモルフォロジー膨張の画像と収縮の画像の差分をとることで、物体の境界線を抽出する手法である。\n",
    "\n",
    "ここではモルフォロジー処理のN=1とする。\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_51.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_51_60/imori.jpg)|![](./Question_51_60/answer_51.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Otsu binary\n",
    "## Grayscale\n",
    "out = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "## Determine threshold of Otsu's binarization\n",
    "max_sigma = 0\n",
    "max_t = 0\n",
    "\n",
    "for _t in range(1, 255):\n",
    "    v0 = out[np.where(out < _t)[0]]\n",
    "    m0 = np.mean(v0) if len(v0) > 0 else 0.\n",
    "    w0 = len(v0) / (H * W)\n",
    "    v1 = out[np.where(out >= _t)[0]]\n",
    "    m1 = np.mean(v1) if len(v1) > 0 else 0.\n",
    "    w1 = len(v1) / (H * W)\n",
    "    sigma = w0 * w1 * ((m0 - m1) ** 2)\n",
    "    if sigma > max_sigma:\n",
    "        max_sigma = sigma\n",
    "        max_t = _t\n",
    "\n",
    "## Binarization\n",
    "#print(\"threshold >>\", max_t)\n",
    "th = max_t\n",
    "out[out < th] = 0\n",
    "out[out >= th] = 255\n",
    "\n",
    "# Morphology filter\n",
    "MF = np.array(((0, 1, 0),\n",
    "               (1, 0, 1),\n",
    "               (0, 1, 0)), dtype=np.int)\n",
    "\n",
    "# Morphology - erode\n",
    "Erode_time = 1\n",
    "erode = out.copy()\n",
    "\n",
    "for i in range(Erode_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) < 255*4:\n",
    "                erode[y-1, x-1] = 0\n",
    "                \n",
    "# Morphology - dilate\n",
    "Dil_time = 1\n",
    "dilate = out.copy()\n",
    "\n",
    "for i in range(Dil_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) >= 255:\n",
    "                dilate[y-1, x-1] = 255\n",
    "                \n",
    "out = np.abs(erode - dilate) * 255\n",
    "                \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.52. トップハット変換\n",
    "\n",
    "大津の二値化を行った後、トップハット変換を行え。\n",
    "\n",
    "トップハット変換とは元画像からオープニング処理を行った画像を差し引いた画像であり、細い線状のものやノイズなどを抽出できると言われる。\n",
    "\n",
    "ここでは、大津の二値化画像からオープニング処理画像(N=3)を差し引いて求めよ。\n",
    "\n",
    "＊ここの問題だと効果が分かりにくいので、他の画像があればそのうち訂正します。\n",
    "\n",
    "|入力 (imori.jpg) |大津の二値化(answer_4.jpg)|出力(answer_52.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_51_60/imori.jpg)|![](./Question_51_60/answer_4.jpg)|![](./Question_51_60/answer_52.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Otsu binary\n",
    "## Grayscale\n",
    "out = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "## Determine threshold of Otsu's binarization\n",
    "max_sigma = 0\n",
    "max_t = 0\n",
    "\n",
    "for _t in range(1, 255):\n",
    "    v0 = out[np.where(out < _t)]\n",
    "    m0 = np.mean(v0) if len(v0) > 0 else 0.\n",
    "    w0 = len(v0) / (H * W)\n",
    "    v1 = out[np.where(out >= _t)]\n",
    "    m1 = np.mean(v1) if len(v1) > 0 else 0.\n",
    "    w1 = len(v1) / (H * W)\n",
    "    sigma = w0 * w1 * ((m0 - m1) ** 2)\n",
    "    if sigma > max_sigma:\n",
    "        max_sigma = sigma\n",
    "        max_t = _t\n",
    "\n",
    "## Binarization\n",
    "#print(\"threshold >>\", max_t)\n",
    "th = max_t\n",
    "out[out < th] = 0\n",
    "out[out >= th] = 255\n",
    "\n",
    "# Morphology filter\n",
    "MF = np.array(((0, 1, 0),\n",
    "               (1, 0, 1),\n",
    "               (0, 1, 0)), dtype=np.int)\n",
    "\n",
    "# Morphology - erode\n",
    "Erode_time = 3\n",
    "mor = out.copy()\n",
    "\n",
    "for i in range(Erode_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) < 255*4:\n",
    "                mor[y-1, x-1] = 0\n",
    "\n",
    "# Morphology - dilate\n",
    "Dil_time = 3\n",
    "\n",
    "for i in range(Dil_time):\n",
    "    tmp = np.pad(mor, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) >= 255:\n",
    "                mor[y-1, x-1] = 255\n",
    "\n",
    "out = out - mor\n",
    "                \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.53. ブラックハット変換\n",
    "\n",
    "大津の二値化を行った後、ブラックハット変換を行え。\n",
    "\n",
    "ブラックハット変換とはクロージング画像から元画像を差し引いた画像であり、これもトップ変換同様に細い線状やノイズを抽出できると言われる。\n",
    "\n",
    "ここでは、クロージング処理画像(N=3)から大津の二値化画像を差し引いて求めよ。\n",
    "\n",
    "＊ここの問題だと効果が分かりにくいので、他の画像があればそのうち訂正します。\n",
    "\n",
    "|入力 (imori.jpg) |大津の二値化(answer_4.jpg)|出力(answer_53.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_51_60/imori.jpg)|![](./Question_51_60/answer_4.jpg)|![](./Question_51_60/answer_53.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Otsu binary\n",
    "## Grayscale\n",
    "out = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "## Determine threshold of Otsu's binarization\n",
    "max_sigma = 0\n",
    "max_t = 0\n",
    "\n",
    "for _t in range(1, 255):\n",
    "    v0 = out[np.where(out < _t)]\n",
    "    m0 = np.mean(v0) if len(v0) > 0 else 0.\n",
    "    w0 = len(v0) / (H * W)\n",
    "    v1 = out[np.where(out >= _t)]\n",
    "    m1 = np.mean(v1) if len(v1) > 0 else 0.\n",
    "    w1 = len(v1) / (H * W)\n",
    "    sigma = w0 * w1 * ((m0 - m1) ** 2)\n",
    "    if sigma > max_sigma:\n",
    "        max_sigma = sigma\n",
    "        max_t = _t\n",
    "\n",
    "## Binarization\n",
    "#print(\"threshold >>\", max_t)\n",
    "th = max_t\n",
    "out[out < th] = 0\n",
    "out[out >= th] = 255\n",
    "\n",
    "# Morphology filter\n",
    "MF = np.array(((0, 1, 0),\n",
    "               (1, 0, 1),\n",
    "               (0, 1, 0)), dtype=np.int)\n",
    "\n",
    "# Morphology - dilate\n",
    "Dil_time = 3\n",
    "mor = out.copy()\n",
    "\n",
    "for i in range(Dil_time):\n",
    "    tmp = np.pad(out, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) >= 255:\n",
    "                mor[y-1, x-1] = 255\n",
    "\n",
    "# Morphology - erode\n",
    "Erode_time = 3\n",
    "\n",
    "for i in range(Erode_time):\n",
    "    tmp = np.pad(mor, (1, 1), 'edge')\n",
    "    for y in range(1, H+1):\n",
    "        for x in range(1, W+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) < 255*4:\n",
    "                mor[y-1, x-1] = 0\n",
    "\n",
    "out = mor - out\n",
    "                \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.54. テンプレートマッチング SSD\n",
    "\n",
    "ここではテンプレートマッチングのSSDを用いて、*imori_part.jpg*が*imori.jpg*のどこに位置するかを*imori.jpg*の赤の矩形で図示せよ。\n",
    "\n",
    "テンプレートマッチングとは、テンプレート画像と全体画像の一部分で類似度が高い位置を探す手法であり、**物体検出**などで使われる。今では物体検出はCNNで行われるが、テンプレートマッチングは最も基本処理となる。\n",
    "\n",
    "アルゴリズムとしては、画像I (H x W)、テンプレート画像T (h x w)とすると、\n",
    "\n",
    "1. 画像Iにおいて、for ( j = 0, H-h)  for ( i = 0, W-w)と1ピクセルずつずらしながら画像Aの一部分I(i:i+w, j:j+h)とテンプレート画像の類似度Sを計算する。\n",
    "2. Sが最大もしくは最小の位置がマッチング位置となる。\n",
    "\n",
    "Sの選び方は主にSSD, SAD(Q.55), NCC(Q.56), ZNCC(Q.57)などがあり、それぞれ最大値をとるか最小値をとるか異なる。\n",
    "\n",
    "ここではSSD(Sum of Squared Difference)を用いる。\n",
    "SSDとは画素値の差分の二乗値の和を類似度にする手法であり、Sが**最小**の位置がマッチング位置となる。\n",
    "\n",
    "```bash\n",
    "S = Sum_{x=0:w, y=0:h} (I(i+x, j+y) - T(x, y) )^2\n",
    "```\n",
    "\n",
    "ちなみにテンプレートマッチングのように画像を左上から右に順に見ていくことを**走査(ラスタスキャン)**や**スライディングウィンドウ**と呼ぶ。このワードは画像処理でよく出る頻出である。\n",
    "\n",
    "矩形の描画には*cv2.rectangle()*を用いると良い。\n",
    "ちなみにimori_part.jpgは若干色味を変えています。\n",
    "\n",
    "|入力 (imori.jpg) |テンプレート画像(imori_part.jpg)|出力(answer_54.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_51_60/imori.jpg)|![](./Question_51_60/imori_part.jpg)|![](./Question_51_60/answer_54.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Read templete image\n",
    "temp = cv2.imread(\"imori_part.jpg\").astype(np.float32)\n",
    "Ht, Wt, Ct = temp.shape\n",
    "\n",
    "\n",
    "# Templete matching\n",
    "i, j = -1, -1\n",
    "v = 255 * H * W * C\n",
    "for y in range(H-Ht):\n",
    "    for x in range(W-Wt):\n",
    "        _v = np.sum((img[y:y+Ht, x:x+Wt] - temp) ** 2)\n",
    "        if _v < v:\n",
    "            v = _v\n",
    "            i, j = x, y\n",
    "\n",
    "out = img.copy()\n",
    "cv2.rectangle(out, pt1=(i, j), pt2=(i+Wt, j+Ht), color=(0,0,255), thickness=1)\n",
    "out = out.astype(np.uint8)\n",
    "                \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.55. テンプレートマッチング SAD\n",
    "\n",
    "ここではテンプレートマッチングのSADを用いて、*imori_part.jpg*が*imori.jpg*のどこに位置するかを*imori.jpg*の赤の矩形で図示せよ。\n",
    "\n",
    "SAD(Sum of Absolute Difference)とは画素値の差分の絶対値の和を類似度にする手法であり、Sが**最小**の位置がマッチング位置となる。\n",
    "\n",
    "```bash\n",
    "S = Sum_{x=0:w, y=0:h} |I(i+x, j+y) - T(x, y)|\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg) |テンプレート画像(imori_part.jpg)|出力(answer_55.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_51_60/imori.jpg)|![](./Question_51_60/imori_part.jpg)|![](./Question_51_60/answer_55.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Read templete image\n",
    "temp = cv2.imread(\"imori_part.jpg\").astype(np.float32)\n",
    "Ht, Wt, Ct = temp.shape\n",
    "\n",
    "\n",
    "# Templete matching\n",
    "i, j = -1, -1\n",
    "v = 255 * H * W * C\n",
    "for y in range(H-Ht):\n",
    "    for x in range(W-Wt):\n",
    "        _v = np.sum(np.abs(img[y:y+Ht, x:x+Wt] - temp))\n",
    "        if _v < v:\n",
    "            v = _v\n",
    "            i, j = x, y\n",
    "\n",
    "out = img.copy()\n",
    "cv2.rectangle(out, pt1=(i, j), pt2=(i+Wt, j+Ht), color=(0,0,255), thickness=1)\n",
    "out = out.astype(np.uint8)\n",
    "                \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.56. テンプレートマッチング NCC\n",
    "\n",
    "ここではテンプレートマッチングのNCCを用いて、*imori_part.jpg*が*imori.jpg*のどこに位置するかを*imori.jpg*の赤の矩形で図示せよ。\n",
    "\n",
    "NCC(Normalized Cross Correlation)とは正規化相互相関を類似度にする手法であり、Sが**最大**の位置がマッチング位置となる。\n",
    "\n",
    "```bash\n",
    "     Sum_{x=0:w, y=0:h} |I(i+x, j+y) T(x, y)|\n",
    "S = -----------------------------------------------------------------------------\n",
    "    Sqrt(Sum_{x=0:w, y=0:h} I(i+x, j+y)^2) * Sqrt(Sum_{x=0:w, y=0:h} T(x, y)^2)\n",
    "```\n",
    "\n",
    "このSは、-1<=S<=1をとる。\n",
    "NCCは証明変化に強いと言われる。\n",
    "\n",
    "|入力 (imori.jpg) |テンプレート画像(imori_part.jpg)|出力(answer_56.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_51_60/imori.jpg)|![](./Question_51_60/imori_part.jpg)|![](./Question_51_60/answer_56.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Read templete image\n",
    "temp = cv2.imread(\"imori_part.jpg\").astype(np.float32)\n",
    "Ht, Wt, Ct = temp.shape\n",
    "\n",
    "\n",
    "# Templete matching\n",
    "i, j = -1, -1\n",
    "v = -1\n",
    "for y in range(H-Ht):\n",
    "    for x in range(W-Wt):\n",
    "        _v = np.sum(img[y:y+Ht, x:x+Wt] * temp)\n",
    "        _v /= (np.sqrt(np.sum(img[y:y+Ht, x:x+Wt]**2)) * np.sqrt(np.sum(temp**2)))\n",
    "        if _v > v:\n",
    "            v = _v\n",
    "            i, j = x, y\n",
    "\n",
    "out = img.copy()\n",
    "cv2.rectangle(out, pt1=(i, j), pt2=(i+Wt, j+Ht), color=(0,0,255), thickness=1)\n",
    "out = out.astype(np.uint8)\n",
    "                \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.57. テンプレートマッチング ZNCC\n",
    "\n",
    "ここではテンプレートマッチングのZNCCを用いて、*imori_part.jpg*が*imori.jpg*のどこに位置するかを*imori.jpg*の赤の矩形で図示せよ。\n",
    "\n",
    "SZNCC(Zero means Normalized Cross Correlation)とは零平均正規化相互相関を類似度にする手法であり、Sが**最大**の位置がマッチング位置となる。\n",
    "\n",
    "画像Iの平均値をmi、画像Tの平均値をmtとすると、Sは次式で計算される。\n",
    "\n",
    "```bash\n",
    "       Sum_{x=0:w, y=0:h} |(I(i+x, j+y)-mi) (T(x, y)-mt)|\n",
    "S = --------------------------------------------------------------------------------------\n",
    "    Sqrt(Sum_{x=0:w, y=0:h} (I(i+x, j+y)-mi)^2) * Sqrt(Sum_{x=0:w, y=0:h} (T(x, y)-mt)^2)\n",
    "```\n",
    "\n",
    "このSは、-1<=S<=1をとる。\n",
    "ZNCCは平均値を引くことでNCCよりも証明変化に強いと言われる。（だが今回は検出が失敗する。）\n",
    "\n",
    "|入力 (imori.jpg) |テンプレート画像(imori_part.jpg)|出力(answer_57.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_51_60/imori.jpg)|![](./Question_51_60/imori_part.jpg)|![](./Question_51_60/answer_57.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "mi = np.mean(img)\n",
    "\n",
    "# Read templete image\n",
    "temp = cv2.imread(\"imori_part.jpg\").astype(np.float32)\n",
    "Ht, Wt, Ct = temp.shape\n",
    "\n",
    "mt = np.mean(temp)\n",
    "\n",
    "# Templete matching\n",
    "i, j = -1, -1\n",
    "v = -1\n",
    "for y in range(H-Ht):\n",
    "    for x in range(W-Wt):\n",
    "        _v = np.sum((img[y:y+Ht, x:x+Wt]-mi) * (temp-mt))\n",
    "        _v /= (np.sqrt(np.sum((img[y:y+Ht, x:x+Wt]-mi)**2)) * np.sqrt(np.sum((temp-mt)**2)))\n",
    "        if _v > v:\n",
    "            v = _v\n",
    "            i, j = x, y\n",
    "\n",
    "out = img.copy()\n",
    "cv2.rectangle(out, pt1=(i, j), pt2=(i+Wt, j+Ht), color=(0,0,255), thickness=1)\n",
    "out = out.astype(np.uint8)\n",
    "                \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.58. ラベリング 4近傍\n",
    "\n",
    "*seg.png*をラベリングせよ。\n",
    "\n",
    "ラベリングとは隣接したピクセルに同じラベルを割り当てる作業である。\n",
    "\n",
    "つまり、\n",
    "\n",
    "```bash\n",
    "黒　黒　黒　黒\n",
    "黒　白　白　黒\n",
    "黒　白　黒　黒\n",
    "黒　黒　黒　黒\n",
    "```\n",
    "\n",
    "このように隣り合った白ピクセルは同じラベルを割り当てる。\n",
    "\n",
    "このようにピクセルの塊にラベリングしたものは**Connected Component**とも呼ばれる。\n",
    "\n",
    "ここでは４近傍に注目してラベリングを行う。\n",
    "また、ここではルックアップテーブルというものを使用する。\n",
    "\n",
    "ルックアップテーブルとは\n",
    "\n",
    "```bash\n",
    "|   Source   |    Distination   | \n",
    "|     1      |         1        |\n",
    "|     2      |         2        |\n",
    "|     3      |         1        |\n",
    "```\n",
    "\n",
    "というような表になっており、Source=1に割り当てた画素には最終的にラベル1を割り当てる、Source =3に割り当てた画素には最終的にラベル1を割り当てることを示す表である。\n",
    "\n",
    "アルゴリズムは\n",
    "1. 左上からラスタスキャンを行う。\n",
    "2. 注目画素i(x,y)が黒画素なら何も行わない。白画素なら、上画素i(x,y-1)と左画素i(x-1,y)に注目し、どちらも0だった場合、最後に割り当てたラベル+1を割り当てる。\n",
    "3. どちらか一方以上が0でない場合（つまりすでにラベルが割り合っている場合）、上と左に割り当てられたラベルの中で最小の方(0以外)をi(x,y)に割り当てる。ここで、上か左で用いなかったラベルに対応するルックアップテーブルをここで割り当てた番号に変える。\n",
    "4. 最後、ルックアップテーブルを見て、Sourceに対応する画素に当たる部分をDistinationの値に変換する。\n",
    "\n",
    "\n",
    "以上により隣接ピクセル同士に同じラベルを割り当てる。\n",
    "4近傍としているが、ラスタスキャンのため、上画素と左画素の２画素に注目すればいい。\n",
    "\n",
    "|入力 (seg.png) |出力(answer_58.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_51_60/seg.png)|![](./Question_51_60/answer_58.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"seg.png\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "label = np.zeros((H, W), dtype=np.int)\n",
    "label[img[..., 0]>0] = 1\n",
    "\n",
    "LUT = [0 for _ in range(H*W)]\n",
    "\n",
    "n = 1\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if label[y, x] == 0:\n",
    "            continue\n",
    "        c3 = label[max(y-1,0), x]\n",
    "        c5 = label[y, max(x-1,0)]\n",
    "        if c3 < 2 and c5 < 2:\n",
    "            n += 1\n",
    "            label[y, x] = n\n",
    "        else:\n",
    "            _vs = [c3, c5]\n",
    "            vs = [a for a in _vs if a > 1]\n",
    "            v = min(vs)\n",
    "            label[y, x] = v\n",
    "            \n",
    "            minv = v\n",
    "            for _v in vs:\n",
    "                if LUT[_v] != 0:\n",
    "                    minv = min(minv, LUT[_v])\n",
    "            for _v in vs:\n",
    "                LUT[_v] = minv\n",
    "                \n",
    "count = 1\n",
    "\n",
    "for l in range(2, n+1):\n",
    "    flag = True\n",
    "    for i in range(n+1):\n",
    "        if LUT[i] == l:\n",
    "            if flag:\n",
    "                count += 1\n",
    "                flag = False\n",
    "            LUT[i] = count\n",
    "\n",
    "COLORS = [[0, 0, 255], [0, 255, 0], [255, 0, 0], [255, 255, 0]]\n",
    "out = np.zeros((H, W, C), dtype=np.uint8)\n",
    "\n",
    "for i, lut in enumerate(LUT[2:]):\n",
    "    out[label == (i+2)] = COLORS[lut-2]\n",
    "    \n",
    "# Save result\n",
    "cv2.imwrite(\"out.png\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.59. ラベリング 8近傍\n",
    "\n",
    "ここではQ.58のラベリングを8近傍に変えてラベリングを行え。\n",
    "\n",
    "8近傍とは、i(x-1,y-1), i(x, y-1), i(x+1,y-1), i(x-1,y)の4画素に注目すればよい。\n",
    "\n",
    "|入力 (seg.png) |出力(answer_59.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_51_60/seg.png)|![](./Question_51_60/answer_59.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"seg.png\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "label = np.zeros((H, W), dtype=np.int)\n",
    "label[img[..., 0]>0] = 1\n",
    "\n",
    "LUT = [0 for _ in range(H*W)]\n",
    "\n",
    "n = 1\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if label[y, x] == 0:\n",
    "            continue\n",
    "        c2 = label[max(y-1,0), min(x+1, W-1)]\n",
    "        c3 = label[max(y-1,0), x]\n",
    "        c4 = label[max(y-1,0), max(x-1,0)]\n",
    "        c5 = label[y, max(x-1,0)]\n",
    "        if c3 < 2 and c5 < 2 and c2 < 2 and c4 < 2:\n",
    "            n += 1\n",
    "            label[y, x] = n\n",
    "        else:\n",
    "            _vs = [c3, c5, c2, c4]\n",
    "            vs = [a for a in _vs if a > 1]\n",
    "            v = min(vs)\n",
    "            label[y, x] = v\n",
    "\n",
    "            minv = v\n",
    "            for _v in vs:\n",
    "                if LUT[_v] != 0:\n",
    "                    minv = min(minv, LUT[_v])\n",
    "            for _v in vs:\n",
    "                LUT[_v] = minv\n",
    "                \n",
    "count = 1\n",
    "\n",
    "for l in range(2, n+1):\n",
    "    flag = True\n",
    "    for i in range(n+1):\n",
    "        if LUT[i] == l:\n",
    "            if flag:\n",
    "                count += 1\n",
    "                flag = False\n",
    "            LUT[i] = count\n",
    "\n",
    "COLORS = [[0, 0, 255], [0, 255, 0], [255, 0, 0], [255, 255, 0]]\n",
    "out = np.zeros((H, W, C), dtype=np.uint8)\n",
    "\n",
    "for i, lut in enumerate(LUT[2:]):\n",
    "    out[label == (i+2)] = COLORS[lut-2]\n",
    "    \n",
    "# Save result\n",
    "cv2.imwrite(\"out.png\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.60. アルファブレンド\n",
    "\n",
    "アルファブレンドにより、*imori.jpg*と*thorino.jpg*を6:4の割合で画像を合成せよ。\n",
    "\n",
    "アルファブレンドとは透明度（アルファ値）を設定することにより画像の透明度を設定する方法である。\n",
    "OpenCVでは透明度のパラメータはないが、PILなどのライブラリでは存在する。\n",
    "ここではその透明度を手動で設定する。\n",
    "\n",
    "二つの画像を重ね合わせたい時などに、この手法は有効である。\n",
    "\n",
    "img1とimg2を1:1の割合で重ね合わせたい時は、次式となる。\n",
    "alphaの値を変えることで重ねる時の重みを変えることができる。\n",
    "\n",
    "```bash\n",
    "alpha = 0.5\n",
    "out = img1 * alpha + img2 * (1 - alpha)\n",
    "```\n",
    "\n",
    "|入力 (imori.jpg) |入力2 (thorino.jpg) |出力(answer_60.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_51_60/imori.jpg)|![](./Question_51_60/thorino.jpg)|![](./Question_51_60/answer_60.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "img2 = cv2.imread(\"thorino.jpg\").astype(np.float32)\n",
    "\n",
    "a = 0.6\n",
    "out = img * a + img2 * (1 - a)\n",
    "out = out.astype(np.uint8)\n",
    "    \n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 61 - 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.61. 4-連結数\n",
    "\n",
    "*renketsu.png*を4-連結数により、色分けせよ。\n",
    "\n",
    "4-連結数とは近傍との画素の状態を見る値である。\n",
    "通常、近傍は注目画素x0(x,y)が0でない場合に対して、次のように定義される。\n",
    "\n",
    "```bash\n",
    "x4(x-1,y-1) x3(x,y-1) x2(x+1,y-1)\n",
    "x5(x-1,y)   x0(x,y)   x1(x+1,y)\n",
    "x6(x-1,y+1) x7(x,y+1) x8(x+1,y+1)\n",
    "```\n",
    "\n",
    "ここで4連結数とは、次式で計算される。\n",
    "\n",
    "```bash\n",
    "S = (x1 - x1 x2 x3) + (x3 - x3 x4 x5) + (x5 - x5 x6 x7) + (x7 - x7 x8 x1) \n",
    "```\n",
    "\n",
    "S = [0,4]の範囲をとり、\n",
    "- S = 0 は内部点\n",
    "- S = 1 は端点\n",
    "- S = 2 は連結点\n",
    "- S = 3 は分岐点\n",
    "- S = 4 は交差点\n",
    "を示す。\n",
    "\n",
    "|入力 (renketsu.png) |出力(answer_61.png)|\n",
    "|:---:|:---:|\n",
    "|<img src=\"./Question_61_70/renketsu.png\" width=\"50px\">|<img src=\"./Question_61_70/answer_61.png\" width=\"50px\">|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"renketsu.png\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "tmp = np.zeros((H, W), dtype=np.int)\n",
    "tmp[img[..., 0]>0] = 1\n",
    "\n",
    "out = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if tmp[y, x] < 1:\n",
    "            continue\n",
    "\n",
    "        c = 0\n",
    "        c += (tmp[y,min(x+1,W-1)] - tmp[y,min(x+1,W-1)] * tmp[max(y-1,0),min(x+1,W-1)] * tmp[max(y-1,0),x])\n",
    "        c += (tmp[max(y-1,0),x] - tmp[max(y-1,0),x] * tmp[max(y-1,0),max(x-1,0)] * tmp[y,max(x-1,0)])\n",
    "        c += (tmp[y,max(x-1,0)] - tmp[y,max(x-1,0)] * tmp[min(y+1,H-1),max(x-1,0)] * tmp[min(y+1,H-1),x])\n",
    "        c += (tmp[min(y+1,H-1),x] - tmp[min(y+1,H-1),x] * tmp[min(y+1,H-1),min(x+1,W-1)] * tmp[y,min(x+1,W-1)])\n",
    "        \n",
    "        if c == 0:\n",
    "            out[y,x] = [0, 0, 255]\n",
    "        elif c == 1:\n",
    "            out[y,x] = [0, 255, 0]\n",
    "        elif c == 2:\n",
    "            out[y,x] = [255, 0, 0]\n",
    "        elif c == 3:\n",
    "            out[y,x] = [255, 255, 0]\n",
    "        elif c == 4:\n",
    "            out[y,x] = [255, 0, 255]\n",
    "                \n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.png\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.62. 8-連結数\n",
    "\n",
    "*renketsu.png*を8-連結数により、色分けせよ。\n",
    "\n",
    "8連結数とは\n",
    "\n",
    "```bash\n",
    "S = (x1 - x1 x2 x3) + (x3 - x3 x4 x5) + (x5 - x5 x6 x7) + (x7 - x7 x8 x1) \n",
    "```\n",
    "において各x¥*の値の0と1を反転させた値を用いる。\n",
    "\n",
    "|入力 (renketsu.png) |出力(answer_62.png)|\n",
    "|:---:|:---:|\n",
    "|<img src=\"./Question_61_70/renketsu.png\" width=\"50px\">|<img src=\"./Question_61_70/answer_62.png\" width=\"50px\">|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"renketsu.png\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "_tmp = np.zeros((H, W), dtype=np.int)\n",
    "_tmp[img[..., 0]>0] = 1\n",
    "\n",
    "tmp = 1 - _tmp\n",
    "\n",
    "out = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if _tmp[y, x] < 1:\n",
    "            continue\n",
    "\n",
    "        c = 0\n",
    "        c += (tmp[y,min(x+1,W-1)] - tmp[y,min(x+1,W-1)] * tmp[max(y-1,0),min(x+1,W-1)] * tmp[max(y-1,0),x])\n",
    "        c += (tmp[max(y-1,0),x] - tmp[max(y-1,0),x] * tmp[max(y-1,0),max(x-1,0)] * tmp[y,max(x-1,0)])\n",
    "        c += (tmp[y,max(x-1,0)] - tmp[y,max(x-1,0)] * tmp[min(y+1,H-1),max(x-1,0)] * tmp[min(y+1,H-1),x])\n",
    "        c += (tmp[min(y+1,H-1),x] - tmp[min(y+1,H-1),x] * tmp[min(y+1,H-1),min(x+1,W-1)] * tmp[y,min(x+1,W-1)])\n",
    "        \n",
    "        if c == 0:\n",
    "            out[y,x] = [0, 0, 255]\n",
    "        elif c == 1:\n",
    "            out[y,x] = [0, 255, 0]\n",
    "        elif c == 2:\n",
    "            out[y,x] = [255, 0, 0]\n",
    "        elif c == 3:\n",
    "            out[y,x] = [255, 255, 0]\n",
    "        elif c == 4:\n",
    "            out[y,x] = [255, 0, 255]\n",
    "                \n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.png\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.63. 細線化処理\n",
    "\n",
    "*gazo.png* を細線化せよ。\n",
    "\n",
    "細線化とは画素の幅を1にする処理であり、ここでは次のアルゴリズムに沿って処理を行え。\n",
    "\n",
    "1. 左上からラスタスキャンする。\n",
    "2. x0(x,y)=0ならば、処理なし。x0(x,y)=1ならば次の3条件を満たす時にx0=0に変える。\n",
    "(1) 注目画素の4近傍に0が一つ以上存在する\n",
    "(2) x0の4-連結数が1である\n",
    "(3) x0の8近傍に1が3つ以上存在する\n",
    "3. 一回のラスタスキャンで2の変更数が0になるまで、ラスタスキャンを繰り返す。\n",
    "\n",
    "細線化にはヒルディッチのアルゴリズム(Q.64)や、Zhang-Suenのアルゴリズム(Q.65)、田村のアルゴリズムなどが存在する。\n",
    "\n",
    "|入力 (gazo.png) |出力(answer_63.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_61_70/gazo.png)|![](./Question_61_70/answer_63.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"gazo.png\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "out = np.zeros((H, W), dtype=np.int)\n",
    "out[img[..., 0]>0] = 1\n",
    "\n",
    "count = 1\n",
    "while count > 0:\n",
    "    count = 0\n",
    "    tmp = out.copy()\n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            if out[y, x] < 1:\n",
    "                continue\n",
    "            \n",
    "            judge = 0\n",
    "            \n",
    "            ## condition 1\n",
    "            if (tmp[y,min(x+1,W-1)] + tmp[max(y-1,0), x] + tmp[y,max(x-1,0)] + tmp[min(y+1,H-1),x]) < 4:\n",
    "                judge += 1\n",
    "                \n",
    "            ## condition 2\n",
    "            c = 0\n",
    "            c += (out[y,min(x+1,W-1)] - out[y,min(x+1,W-1)]*out[max(y-1,0),min(x+1,W-1)]*out[max(y-1,0),x])\n",
    "            c += (out[max(y-1,0),x] - out[max(y-1,0),x]*out[max(y-1,0),max(x-1,0)]*out[y,max(x-1,0)])\n",
    "            c += (out[y,max(x-1,0)] - out[y,max(x-1,0)]*out[min(y+1,H-1),max(x-1,0)]*out[min(y+1,H-1),x])\n",
    "            c += (out[min(y+1,H-1),x] - out[min(y+1,H-1),x]*out[min(y+1,H-1),min(x+1,W-1)]*out[y,min(x+1,W-1)])\n",
    "            if c == 1:\n",
    "                judge += 1\n",
    "                \n",
    "            ##x condition 3\n",
    "            if np.sum(out[max(y-1,0):min(y+2,H), max(x-1,0):min(x+2,W)]) >= 4:\n",
    "                judge += 1\n",
    "            \n",
    "            if judge == 3:\n",
    "                out[y,x] = 0\n",
    "                count += 1\n",
    "\n",
    "out = out.astype(np.uint8) * 255\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.png\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.64. ヒルディッチの細線化\n",
    "\n",
    "*gazo.png* にヒルディッチの細線化を行え。\n",
    "\n",
    "\n",
    "アルゴリズムは、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.65. Zhang-Suenの細線化\n",
    "\n",
    "*gazo.png*にZhang-Suenの細線化を行え。\n",
    "\n",
    "ただし、以下の操作は全て0が線、1が背景とするので、*gazo.png*の値を反転させる必要があることに注意。\n",
    "\n",
    "注目画素x1(x,y)に対して8近傍を次のように定義する。\n",
    "\n",
    "```bash\n",
    "x9 x2 x3\n",
    "x8 x1 x4\n",
    "x7 x6 x5\n",
    "```\n",
    "これらに対して二つのステップを考える。\n",
    "\n",
    "Step.1\n",
    "ラスタスキャンを行い、以下の5条件を満たすピクセルを全て記録する。\n",
    "1. 黒画素である\n",
    "2. x2, x3, ..., x9, x2と時計まわりに見て、0から1に変わる回数がちょうど1\n",
    "3. x2, x3, ..., x9の中で1の個数が2以上6以下\n",
    "4. x2, x4, x6のどれかが1\n",
    "5. x4, x6, x8のどれかが1\n",
    "記録したピクセルを全て1に変更する。\n",
    "\n",
    "Step.2\n",
    "ラスタスキャンを行い、以下の5条件を満たすピクセルを全て記録する。\n",
    "1. 黒画素である\n",
    "2. x2, x3, ..., x9, x2と時計まわりに見て、0から1に変わる回数がちょうど1\n",
    "3. x2, x3, ..., x9の中で1の個数が2以上6以下\n",
    "4. x2, x4, x8のどれかが1\n",
    "5. x2, x6, x8のどれかが1\n",
    "記録したピクセルを全て1に変更する。\n",
    "\n",
    "Step1, 2で変更する点がなくなるまで交互に繰り返す。\n",
    "\n",
    "|入力 (gazo.png) |出力(answer_65.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_61_70/gazo.png)|![](./Question_61_70/answer_65.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"gazo.png\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "out = np.zeros((H, W), dtype=np.int)\n",
    "out[img[..., 0]>0] = 1\n",
    "\n",
    "out = 1 - out\n",
    "\n",
    "while True:\n",
    "    s1 = []\n",
    "    s2 = []\n",
    "\n",
    "    # step 1\n",
    "    for y in range(1, H-1):\n",
    "        for x in range(1, W-1):\n",
    "            \n",
    "            # condition 1\n",
    "            if out[y, x] > 0:\n",
    "                continue\n",
    "\n",
    "            # condition 2\n",
    "            f1 = 0\n",
    "            if (out[y-1, x+1] - out[y-1, x]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y, x+1] - out[y-1, x+1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y+1, x+1] - out[y, x+1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y+1, x] - out[y+1,x+1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y+1, x-1] - out[y+1, x]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y, x-1] - out[y+1, x-1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y-1, x-1] - out[y, x-1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y-1, x] - out[y-1, x-1]) == 1:\n",
    "                f1 += 1\n",
    "\n",
    "            if f1 != 1:\n",
    "                continue\n",
    "                \n",
    "            # condition 3\n",
    "            f2 = np.sum(out[y-1:y+2, x-1:x+2])\n",
    "            if f2 < 2 or f2 > 6:\n",
    "                continue\n",
    "            \n",
    "            # condition 4\n",
    "            if out[y-1, x] + out[y, x+1] + out[y+1, x] < 1:\n",
    "                continue\n",
    "\n",
    "            # condition 5\n",
    "            if out[y, x+1] + out[y+1, x] + out[y, x-1] < 1:\n",
    "                continue\n",
    "                \n",
    "            s1.append([y, x])\n",
    "\n",
    "    for v in s1:\n",
    "        out[v[0], v[1]] = 1\n",
    "\n",
    "    # step 2\n",
    "    for y in range(1, H-1):\n",
    "        for x in range(1, W-1):\n",
    "            \n",
    "            # condition 1\n",
    "            if out[y, x] > 0:\n",
    "                continue\n",
    "\n",
    "            # condition 2\n",
    "            f1 = 0\n",
    "            if (out[y-1, x+1] - out[y-1, x]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y, x+1] - out[y-1, x+1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y+1, x+1] - out[y, x+1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y+1, x] - out[y+1,x+1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y+1, x-1] - out[y+1, x]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y, x-1] - out[y+1, x-1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y-1, x-1] - out[y, x-1]) == 1:\n",
    "                f1 += 1\n",
    "            if (out[y-1, x] - out[y-1, x-1]) == 1:\n",
    "                f1 += 1\n",
    "\n",
    "            if f1 != 1:\n",
    "                continue\n",
    "                \n",
    "            # condition 3\n",
    "            f2 = np.sum(out[y-1:y+2, x-1:x+2])\n",
    "            if f2 < 2 or f2 > 6:\n",
    "                continue\n",
    "            \n",
    "            # condition 4\n",
    "            if out[y-1, x] + out[y, x+1] + out[y, x-1] < 1:\n",
    "                continue\n",
    "\n",
    "            # condition 5\n",
    "            if out[y-1, x] + out[y+1, x] + out[y, x-1] < 1:\n",
    "                continue\n",
    "                \n",
    "            s2.append([y, x])\n",
    "\n",
    "    for v in s2:\n",
    "        out[v[0], v[1]] = 1\n",
    "\n",
    "    if len(s1) < 1 and len(s2) < 1:\n",
    "        break\n",
    "\n",
    "out = 1 - out\n",
    "out = out.astype(np.uint8) * 255\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.png\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.66. HOG (Step.1) 勾配強度・勾配角度\n",
    "\n",
    "*imoir.jpg*のHOG特徴量の勾配強度・勾配角度を求めよ。\n",
    "\n",
    "HOG(Histogram of Oriented Gradients)とは画像の特徴量表現の一種である。\n",
    "\n",
    "特徴量とは画像の状態などを表すベクトル集合のことである。\n",
    "\n",
    "画像認識(画像が何を写した画像か)や検出（画像の中で物体がどこにあるか）では、(1)画像から特徴量を得て(特徴抽出)、(2)特徴量を基に認識や検出を行う(認識・検出)。\n",
    "\n",
    "ディープラーニングでは特徴抽出から認識までを機械学習により自動で行うため、HOGなどは見られなくなっているが、ディープラーニングが流行る前まではHOGは特徴量表現としてよく使われたらしい。\n",
    "\n",
    "HOGは以下のアルゴリズムで得られる。\n",
    "1. 画像をグレースケール化し、x、ｙ方向の輝度勾配を求める\n",
    " \n",
    "```bash\n",
    "x方向: gx = I(x+1, y) - I(x-1, y)\n",
    "y方向: gy = I(x, y+1) - I(x, y-1)\n",
    "```\n",
    "2. gx, gyから勾配強度と勾配角度を求める。\n",
    "\n",
    "```bash\n",
    "勾配強度: mag = sqrt(gt ** 2 + gy ** 2)\n",
    "勾配角度: ang = arctan(gy / gx)\n",
    "```\n",
    "3. 勾配角度を [0, 180]で9分割した値に量子化する。つまり、[0,20]には0、[20, 40]には1というインデックスを求める。\n",
    "4. 画像をN x Nの領域に分割し(この領域をセルという)、セル内で3で求めたインデックスのヒストグラムを作成する。ただし、当表示は1でなく勾配角度を求める。\n",
    "5. C x Cのセルを１つとして(これをブロックという)、ブロック内のセルのヒストグラムを次式で正規化する。これを1セルずつずらしながら行うので、一つのセルが何回も正規化される。\n",
    "\n",
    "```bash\n",
    "h(t) = h(t) / sqrt(Sum h(t) + epsilon)\n",
    "通常は　epsilon=1\n",
    "```\n",
    "\n",
    "以上でHOG特徴量が求められる。\n",
    "\n",
    "ここでは1から3までを行う。\n",
    "\n",
    "解答例はみやすくするため、graは色付けしてある。またmagは[0, 255]に正規化してある。\n",
    "\n",
    "|入力 (imori.jpg) |勾配強度(answer_66_mag.jpg)|勾配角度(answer_66_gra.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_61_70/imori.jpg)|![](./Question_61_70/answer_66_mag.jpg)|![](./Question_61_70/answer_66_gra.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Magnitude and gradient\n",
    "gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "gx = gray[1:H+1, 2:] - gray[1:H+1, :W]\n",
    "gy = gray[2:, 1:W+1] - gray[:H, 1:W+1]\n",
    "gx[gx == 0] = 0.000001\n",
    "\n",
    "mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "gra = np.arctan(gy / gx)\n",
    "gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "# Gradient histogram\n",
    "gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "d = np.pi / 9\n",
    "for i in range(9):\n",
    "    gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "\n",
    "# Draw\n",
    "_mag = (mag / mag.max() * 255).astype(np.uint8)\n",
    "\n",
    "cv2.imwrite(\"out_mag.jpg\", _mag)\n",
    "\n",
    "# Save result\n",
    "out = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "C = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0], [255, 0, 255], [0, 255, 255],\n",
    "     [127, 127, 0], [127, 0, 127], [0, 127, 127]]\n",
    "for i in range(9):\n",
    "    out[gra_n == i] = C[i]\n",
    "\n",
    "cv2.imwrite(\"out_gra.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.67. HOG (Step.2) 勾配ヒストグラム\n",
    "\n",
    "ここではHOGの4を実装する。\n",
    "\n",
    "N=8として、8x8の領域を1セルとして、勾配角度のインデックスに勾配強度を投票する形式でヒストグラムを作成せよ。\n",
    "\n",
    "解答は \n",
    "```bash\n",
    "1 2 3\n",
    "4 5 6\n",
    "7 8 9\n",
    "```\n",
    "の順に量子化したインデックスに対応するヒストグラムを示す。\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_67.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_61_70/imori.jpg)|<img src=\"./Question_61_70/answer_67.png\" width=\"400px\">|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Magnitude and gradient\n",
    "gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "gx = gray[1:H+1, 2:] - gray[1:H+1, :W]\n",
    "gy = gray[2:, 1:W+1] - gray[:H, 1:W+1]\n",
    "gx[gx == 0] = 0.000001\n",
    "\n",
    "mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "gra = np.arctan(gy / gx)\n",
    "gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "# Gradient histogram\n",
    "gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "d = np.pi / 9\n",
    "for i in range(9):\n",
    "    gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "    \n",
    "N = 8\n",
    "HH = H // N\n",
    "HW = W // N\n",
    "Hist = np.zeros((HH, HW, 9), dtype=np.float32)\n",
    "for y in range(HH):\n",
    "    for x in range(HW):\n",
    "        for j in range(N):\n",
    "            for i in range(N):\n",
    "                Hist[y, x, gra_n[y*4+j, x*4+i]] += mag[y*4+j, x*4+i]\n",
    "                \n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(Hist[..., i])\n",
    "    plt.axis('off')\n",
    "    plt.xticks(color=\"None\")\n",
    "    plt.yticks(color=\"None\")\n",
    "plt.savefig(\"out.png\")\n",
    "plt.show()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.68. HOG (Step.3) ヒストグラム正規化\n",
    "\n",
    "ここではHOGの5を実装する。\n",
    "\n",
    "C = 3 として、3 x 3のセルを1ブロックとして扱い、ヒストグラムの正規化を行え。\n",
    "\n",
    "```bash\n",
    "h(t) = h(t) / sqrt(Sum h(t) + epsilon)\n",
    "通常は　epsilon=1\n",
    "```\n",
    "\n",
    "これでHOG特徴量が得られた。\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_68.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_61_70/imori.jpg)|<img src=\"./Question_61_70/answer_68.png\" width=\"400px\">|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Magnitude and gradient\n",
    "gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "gx = gray[1:H+1, 2:] - gray[1:H+1, :W]\n",
    "gy = gray[2:, 1:W+1] - gray[:H, 1:W+1]\n",
    "gx[gx == 0] = 0.000001\n",
    "\n",
    "mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "gra = np.arctan(gy / gx)\n",
    "gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "# Gradient histogram\n",
    "gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "d = np.pi / 9\n",
    "for i in range(9):\n",
    "    gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "\n",
    "    \n",
    "N = 8\n",
    "HH = H // N\n",
    "HW = W // N\n",
    "Hist = np.zeros((HH, HW, 9), dtype=np.float32)\n",
    "for y in range(HH):\n",
    "    for x in range(HW):\n",
    "        for j in range(N):\n",
    "            for i in range(N):\n",
    "                Hist[y, x, gra_n[y*4+j, x*4+i]] += mag[y*4+j, x*4+i]\n",
    "                \n",
    "## Normalization\n",
    "C = 3\n",
    "eps = 1\n",
    "for y in range(HH):\n",
    "    for x in range(HW):\n",
    "        #for i in range(9):\n",
    "        Hist[y, x] /= np.sqrt(np.sum(Hist[max(y-1,0):min(y+2, HH), max(x-1,0):min(x+2, HW)] ** 2) + eps)\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(Hist[..., i])\n",
    "    plt.axis('off')\n",
    "    plt.xticks(color=\"None\")\n",
    "    plt.yticks(color=\"None\")\n",
    "plt.savefig(\"out.png\")\n",
    "plt.show()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.69. HOG (Step.4) 特徴量の描画\n",
    "\n",
    "ここでは得られた特徴量を描画せよ。\n",
    "\n",
    "描画は*imori.jpg*をグレースケール化したものに重ねれば見やすい。\n",
    "\n",
    "方法としては、セル内のインデックスごとに角度がついて直線を描けばよく、ヒストグラムの値が大きいほど白、値が小さいほど黒で描くと見やすい。\n",
    "\n",
    "解答例\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_69.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_61_70/imori.jpg)|![](./Question_61_70/answer_69.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Magnitude and gradient\n",
    "gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "gx = gray[1:H+1, 2:] - gray[1:H+1, :W]\n",
    "gy = gray[2:, 1:W+1] - gray[:H, 1:W+1]\n",
    "gx[gx == 0] = 0.000001\n",
    "\n",
    "mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "gra = np.arctan(gy / gx)\n",
    "gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "# Gradient histogram\n",
    "gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "d = np.pi / 9\n",
    "for i in range(9):\n",
    "    gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "\n",
    "    \n",
    "N = 8\n",
    "HH = H // N\n",
    "HW = W // N\n",
    "Hist = np.zeros((HH, HW, 9), dtype=np.float32)\n",
    "for y in range(HH):\n",
    "    for x in range(HW):\n",
    "        for j in range(N):\n",
    "            for i in range(N):\n",
    "                Hist[y, x, gra_n[y*4+j, x*4+i]] += mag[y*4+j, x*4+i]\n",
    "                \n",
    "## Normalization\n",
    "C = 3\n",
    "eps = 1\n",
    "for y in range(HH):\n",
    "    for x in range(HW):\n",
    "        #for i in range(9):\n",
    "        Hist[y, x] /= np.sqrt(np.sum(Hist[max(y-1,0):min(y+2, HH), max(x-1,0):min(x+2, HW)] ** 2) + eps)\n",
    "        \n",
    "## Draw\n",
    "out = gray[1:H+1, 1:W+1].copy().astype(np.uint8)\n",
    "\n",
    "for y in range(HH):\n",
    "    for x in range(HW):\n",
    "        cx = x * N + N // 2\n",
    "        cy = y * N + N // 2\n",
    "        x1 = cx + N // 2 - 1\n",
    "        y1 = cy\n",
    "        x2 = cx - N // 2 + 1\n",
    "        y2 = cy\n",
    "\n",
    "        h = Hist[y, x] / np.sum(Hist[y, x])\n",
    "        h /= h.max()\n",
    "        \n",
    "        for c in range(9):\n",
    "            #angle = (20 * c + 10 - 90) / 180. * np.pi\n",
    "            angle = (20 * c + 10) / 180. * np.pi\n",
    "            rx = int(np.sin(angle) * (x1 - cx) + np.cos(angle) * (y1 - cy) + cx)\n",
    "            ry = int(np.cos(angle) * (x1 - cx) - np.cos(angle) * (y1 - cy) + cy)\n",
    "            lx = int(np.sin(angle) * (x2 - cx) + np.cos(angle) * (y2 - cy) + cx)\n",
    "            ly = int(np.cos(angle) * (x2 - cx) - np.cos(angle) * (y2 - cy) + cy)\n",
    "        \n",
    "            c = int(255. * h[c])\n",
    "            cv2.line(out, (lx, ly), (rx, ry), (c, c, c), thickness=1)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.70. カラートラッキング\n",
    "\n",
    "*imori.jpg*に対してHSVを用いて青色の箇所のみが255となる画像を作成せよ。\n",
    "\n",
    "カラートラッキングとは特定の色の箇所を抽出する手法である。\n",
    "\n",
    "ただし、RGBの状態で色成分を指定するのは256^3のパターンがあり、とても大変である（というか手動ではかなり難しい）ので、HSV変換を用いる。\n",
    "\n",
    "HSV変換とは Q.5で用いた処理であるが、RGBをH(色相)、S(彩度)、V(明度)に変換する手法である。\n",
    "\n",
    "- Saturation(彩度) 彩度が小さいほど白、彩度が大きいほど色が濃くなる。 0<=S<=1\n",
    "- Value (明度) 明度が小さいほど黒くなり、明度が大きいほど色がきれいになる。 0<=V<=1\n",
    "- Hue(色相) 色を0<=H<=360の角度で表し、具体的には次のように表される。\n",
    "\n",
    "```bash\n",
    "赤 黄色  緑  水色  青  紫   赤\n",
    "0  60  120  180 240 300 360\n",
    "```\n",
    "\n",
    "つまり、青色のカラートラッキングを行うにはHSV変換を行い、180<=H<=260となる位置が255となるような二値画像を出力すればよい。\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_70.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_61_70/imori.jpg)|![](./Question_61_70/answer_70.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32) / 255.\n",
    "\n",
    "# RGB > HSV\n",
    "out = np.zeros_like(img)\n",
    "\n",
    "max_v = np.max(img, axis=2).copy()\n",
    "min_v = np.min(img, axis=2).copy()\n",
    "min_arg = np.argmin(img, axis=2)\n",
    "\n",
    "H = np.zeros_like(max_v)\n",
    "\n",
    "H[np.where(max_v == min_v)] = 0\n",
    "## if min == B\n",
    "ind = np.where(min_arg == 0)\n",
    "H[ind] = 60 * (img[..., 1][ind] - img[..., 2][ind]) / (max_v[ind] - min_v[ind]) + 60\n",
    "## if min == R\n",
    "ind = np.where(min_arg == 2)\n",
    "H[ind] = 60 * (img[..., 0][ind] - img[..., 1][ind]) / (max_v[ind] - min_v[ind]) + 180\n",
    "## if min == G\n",
    "ind = np.where(min_arg == 1)\n",
    "H[ind] = 60 * (img[..., 2][ind] - img[..., 0][ind]) / (max_v[ind] - min_v[ind]) + 300\n",
    "    \n",
    "V = max_v.copy()\n",
    "S = max_v.copy() - min_v.copy()\n",
    "\n",
    "# color tracking\n",
    "mask = np.zeros_like(H)\n",
    "mask[np.where((H>180) & (H<260))] = 255\n",
    "\n",
    "out = mask.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.png\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 71 - 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.71. マスキング\n",
    "\n",
    "*imori.jpg*に対してHSVを用いて青色の箇所のみが黒くなるようにマスキングせよ。\n",
    "\n",
    "このように白黒のバイナリ画像を用いて黒部分に対応する元画像の画素を黒に変更する操作をマスキングという。\n",
    "\n",
    "青色箇所の抽出はHSVで180<=H<=260となる位置が1となるような二値画像を作成し、それの0と1を反転したものと元画像との積をとればよい。\n",
    "\n",
    "これによりある程度のイモリの部分の抽出ができる。\n",
    "\n",
    "|入力 (imori.jpg) |マスク(answer_70.png)|出力(answer_71.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_71_80/imori.jpg)|![](./Question_71_80/answer_70.png)|![](./Question_71_80/answer_71.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32) / 255.\n",
    "\n",
    "# RGB > HSV\n",
    "\n",
    "max_v = np.max(img, axis=2).copy()\n",
    "min_v = np.min(img, axis=2).copy()\n",
    "min_arg = np.argmin(img, axis=2)\n",
    "\n",
    "H = np.zeros_like(max_v)\n",
    "\n",
    "H[np.where(max_v == min_v)] = 0\n",
    "## if min == B\n",
    "ind = np.where(min_arg == 0)\n",
    "H[ind] = 60 * (img[..., 1][ind] - img[..., 2][ind]) / (max_v[ind] - min_v[ind]) + 60\n",
    "## if min == R\n",
    "ind = np.where(min_arg == 2)\n",
    "H[ind] = 60 * (img[..., 0][ind] - img[..., 1][ind]) / (max_v[ind] - min_v[ind]) + 180\n",
    "## if min == G\n",
    "ind = np.where(min_arg == 1)\n",
    "H[ind] = 60 * (img[..., 2][ind] - img[..., 0][ind]) / (max_v[ind] - min_v[ind]) + 300\n",
    "    \n",
    "V = max_v.copy()\n",
    "S = max_v.copy() - min_v.copy()\n",
    "\n",
    "# color tracking\n",
    "mask = np.zeros_like(H)\n",
    "mask[np.where((H>180) & (H<260))] = 1\n",
    "\n",
    "# masking\n",
    "mask = 1 - mask\n",
    "out = img.copy() * 255.\n",
    "\n",
    "for c in range(3):\n",
    "    out[..., c] *= mask\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.72. マスキング(カラートラッキング＋モルフォロジー)\n",
    "\n",
    "Q.71ではマスクが雑になってしまっていたので、イモリの目の部分が削除されていたり、背景がところどころ残ってしまった。\n",
    "\n",
    "よってマスク画像にN=5のクロージング処理(Q.50)とオープニング処理(Q.49)を施してマスク画像を正確にして、マスキングを行え。\n",
    "\n",
    "|入力 (imori.jpg) |マスク(answer_72_mask.png)|出力(answer_72.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_71_80/imori.jpg)|![](./Question_71_80/answer_72_mask.png)|![](./Question_71_80/answer_72.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32) / 255.\n",
    "\n",
    "# RGB > HSV\n",
    "\n",
    "max_v = np.max(img, axis=2).copy()\n",
    "min_v = np.min(img, axis=2).copy()\n",
    "min_arg = np.argmin(img, axis=2)\n",
    "\n",
    "H = np.zeros_like(max_v)\n",
    "\n",
    "H[np.where(max_v == min_v)] = 0\n",
    "## if min == B\n",
    "ind = np.where(min_arg == 0)\n",
    "H[ind] = 60 * (img[..., 1][ind] - img[..., 2][ind]) / (max_v[ind] - min_v[ind]) + 60\n",
    "## if min == R\n",
    "ind = np.where(min_arg == 2)\n",
    "H[ind] = 60 * (img[..., 0][ind] - img[..., 1][ind]) / (max_v[ind] - min_v[ind]) + 180\n",
    "## if min == G\n",
    "ind = np.where(min_arg == 1)\n",
    "H[ind] = 60 * (img[..., 2][ind] - img[..., 0][ind]) / (max_v[ind] - min_v[ind]) + 300\n",
    "    \n",
    "V = max_v.copy()\n",
    "S = max_v.copy() - min_v.copy()\n",
    "\n",
    "# color tracking\n",
    "mask = np.zeros_like(H)\n",
    "mask[np.where((H>180) & (H<260))] = 255\n",
    "\n",
    "h, w, _ = img.shape\n",
    "\n",
    "# Closing\n",
    "## Morphology filter\n",
    "MF = np.array(((0, 1, 0),\n",
    "               (1, 0, 1),\n",
    "               (0, 1, 0)), dtype=np.int)\n",
    "\n",
    "## Morphology - dilate\n",
    "Dil_time = 5\n",
    "\n",
    "for i in range(Dil_time):\n",
    "    tmp = np.pad(mask, (1, 1), 'edge')\n",
    "    for y in range(1, h+1):\n",
    "        for x in range(1, w+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) >= 255:\n",
    "                mask[y-1, x-1] = 255\n",
    "## Morphology - erode\n",
    "Erode_time = 5\n",
    "\n",
    "for i in range(Erode_time):\n",
    "    tmp = np.pad(mask, (1, 1), 'edge')\n",
    "    for y in range(1, h+1):\n",
    "        for x in range(1, w+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) < 255*4:\n",
    "                mask[y-1, x-1] = 0\n",
    "\n",
    "# Opening\n",
    "## Morphology - erode\n",
    "Erode_time = 5\n",
    "\n",
    "for i in range(Erode_time):\n",
    "    tmp = np.pad(mask, (1, 1), 'edge')\n",
    "    for y in range(1, h+1):\n",
    "        for x in range(1, w+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) < 255*4:\n",
    "                mask[y-1, x-1] = 0\n",
    "\n",
    "## Morphology - dilate\n",
    "Dil_time = 5\n",
    "\n",
    "for i in range(Dil_time):\n",
    "    tmp = np.pad(mask, (1, 1), 'edge')\n",
    "    for y in range(1, h+1):\n",
    "        for x in range(1, w+1):\n",
    "            if np.sum(MF * tmp[y-1:y+2, x-1:x+2]) >= 255:\n",
    "                mask[y-1, x-1] = 255\n",
    "\n",
    "# masking\n",
    "cv2.imwrite(\"out_mask.png\", mask.astype(np.uint8))\n",
    "\n",
    "mask = 1 - mask / 255\n",
    "out = img.copy() * 255.\n",
    "\n",
    "for c in range(3):\n",
    "    out[..., c] *= mask\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.73. 縮小と拡大\n",
    "\n",
    "*imori.jpg*をグレースケールにしたものを0.5倍に縮小した後に2倍に拡大した画像を求めよ。\n",
    "この処理を行うと、ぼやけた画像ができる。\n",
    "\n",
    "拡大縮小にはbi-linear補間を用いよ。bi-linear補間をメソッド（関数）化すると、プログラムが簡潔にできる。\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_73.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_71_80/imori.jpg)|![](./Question_71_80/answer_73.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "def resize(img, a):\n",
    "    _h, _w  = img.shape\n",
    "    h = int(a * _h)\n",
    "    w = int(a * _w)\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / a)\n",
    "    x = (x / a)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int)\n",
    "    iy = np.floor(y).astype(np.int)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _w-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "p = resize(gray, 0.5)\n",
    "p = resize(p, 2.)\n",
    "\n",
    "out = p.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.74. ピラミッド差分による高周波成分の抽出\n",
    "\n",
    "Q.73で求めた画像と元画像の差分を求め、[0,255]に正規化せよ。\n",
    "\n",
    "ここで求めた画像はエッジとなっている。つまり、画像中の高周波成分をとったことになる。\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_74.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_71_80/imori.jpg)|![](./Question_71_80/answer_74.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "def resize(img, a):\n",
    "    _h, _w  = img.shape\n",
    "    h = int(a * _h)\n",
    "    w = int(a * _w)\n",
    "\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / a)\n",
    "    x = (x / a)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int)\n",
    "    iy = np.floor(y).astype(np.int)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _w-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "p = resize(gray, 0.5)\n",
    "p = resize(p, 2.)\n",
    "\n",
    "out = np.abs(gray - p)\n",
    "\n",
    "out = out / out.max() * 255\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.75. ガウシアンピラミッド\n",
    "\n",
    "ここでは、元画像を1/2, 1/4, 1/8, 1/16, 1/32にリサイズした画像を求めよ。\n",
    "\n",
    "このように元画像を小さくリサイズして重ねたものを**ガウシアンピラミッド**と呼ぶ。\n",
    "\n",
    "このガウシアンピラミッドの概念は現在でも有効であり、画像をきれいにする超解像を行うディープラーニングの手法でもガウシアンピラミッドの概念が用いられる。\n",
    "\n",
    "|入力 (imori.jpg) |1/1(answer_75_1.jpg)|1/2|1/4|1/8|1/16|1/32|\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|![](./Question_71_80/imori.jpg)|![](./Question_71_80/answer_75_1.jpg)|![](./Question_71_80/answer_75_2.jpg)|![](./Question_71_80/answer_75_4.jpg)|![](./Question_71_80/answer_75_8.jpg)|![](./Question_71_80/answer_75_16.jpg)|![](./Question_71_80/answer_75_32.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "def resize(img, a):\n",
    "    _h, _w  = img.shape\n",
    "    h = int(a * _h)\n",
    "    w = int(a * _w)\n",
    "    \"\"\"\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = np.floor(y / a).astype(np.int)\n",
    "    x = np.floor(x / a).astype(np.int)\n",
    "    y = np.minimum(y, _h-1)\n",
    "    x = np.minimum(x, _w-1)\n",
    "    out = img[y,x]\n",
    "    \"\"\"\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / a)\n",
    "    x = (x / a)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int)\n",
    "    iy = np.floor(y).astype(np.int)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _w-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    #dx = np.repeat(np.expand_dims(dx, axis=-1), 3, axis=-1)\n",
    "    #dy = np.repeat(np.expand_dims(dy, axis=-1), 3, axis=-1)\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "pyramid = [gray]\n",
    "for i in range(1, 6):\n",
    "    a = 2. ** i\n",
    "    p = resize(gray, 1. / a)\n",
    "    pyramid.append(p)\n",
    "\n",
    "for i in range(6):\n",
    "    cv2.imwrite(\"out_{}.jpg\".format(2**i), pyramid[i].astype(np.uint8))\n",
    "    plt.subplot(1, 6, i+1)\n",
    "    plt.imshow(pyramid[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.xticks(color=\"None\")\n",
    "    plt.yticks(color=\"None\")\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.76. 顕著性マップ\n",
    "\n",
    "ここではガウシアンピラミッドを用いた簡単な顕著性マップを作成する。\n",
    "\n",
    "顕著性マップとは画像の中で人間の目を引きやすい領域を表した画像である。\n",
    "\n",
    "現在ではディープラーニングによる顕著性マップがよく用いられるが、本来は画像のRGB成分やHSV成分などのガウシアンピラミッドを作成し、それらの差分から求める手法がよく用いられた(例えばIttiらの手法などがある)。\n",
    "\n",
    "ここではQ.75で作成したガウシアンピラミッドから簡単な顕著性マップを作成する。\n",
    "アルゴリズムは、\n",
    "1. ガウシアンピラミッドをそれぞれ、128, 64, 32, ...というサイズになっているが、はじめにそれらを128にリサイズせよ。リサイズはbi-linear補間を用いよ。\n",
    "2. 作成したピラミッド（それぞれ0, 1, 2, 3, 4, 5と番号をふる）の２つを選び差分を求める。\n",
    "3. 2で求めた差分を全て足し合わせ、[0, 255]に正規化せよ。\n",
    "\n",
    "以上で顕著性マップが求められる。\n",
    "2で選ぶ２つの画像は特に指定はしないが、いいものを選べば解答例のように顕著性マップが作成できる。\n",
    "\n",
    "イモリの目の部分や色が周辺と極端に違う部分など、人の目に止まりやすい領域が白くなっているのが分かる。\n",
    "\n",
    "解答例( (0,1), (0,3), (0,5), (1,4), (2,3), (3,5) を使用)\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_76.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_71_80/imori.jpg)|![](./Question_71_80/answer_76.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "def resize(img, a):\n",
    "    _h, _w  = img.shape\n",
    "    h = int(a * _h)\n",
    "    w = int(a * _w)\n",
    "    \"\"\"\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = np.floor(y / a).astype(np.int)\n",
    "    x = np.floor(x / a).astype(np.int)\n",
    "    y = np.minimum(y, _h-1)\n",
    "    x = np.minimum(x, _w-1)\n",
    "    out = img[y,x]\n",
    "    \"\"\"\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / a)\n",
    "    x = (x / a)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int)\n",
    "    iy = np.floor(y).astype(np.int)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _w-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    #dx = np.repeat(np.expand_dims(dx, axis=-1), 3, axis=-1)\n",
    "    #dy = np.repeat(np.expand_dims(dy, axis=-1), 3, axis=-1)\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "pyramid = [gray]\n",
    "for i in range(1, 6):\n",
    "    a = 2. ** i\n",
    "    p = resize(gray, 1. / a)\n",
    "    p = resize(p, a)\n",
    "    pyramid.append(p)\n",
    "    \n",
    "out = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "out += np.abs(pyramid[0] - pyramid[1])\n",
    "out += np.abs(pyramid[0] - pyramid[3])\n",
    "out += np.abs(pyramid[0] - pyramid[5])\n",
    "out += np.abs(pyramid[1] - pyramid[4])\n",
    "out += np.abs(pyramid[2] - pyramid[3])\n",
    "out += np.abs(pyramid[3] - pyramid[5])\n",
    "\n",
    "\n",
    "out = out / out.max() * 255\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "# Save result\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.77. ガボールフィルタ\n",
    "\n",
    "ガボールフィルタを実装せよ。\n",
    "\n",
    "ガボールフィルタとは\n",
    "\n",
    "ガウス分布と周波数変換を合わせたフィルタであり、画像の特定方向のみのエッジを抽出する時に使われる。\n",
    "\n",
    "フィルタは次式で定義される。\n",
    "\n",
    "```bash\n",
    "G(y, x) = exp(-(x'^2 + g^2 y'^2) / 2 s^2) * cos(2 pi x' / l + p)\n",
    "x' = cosA * x + sinA * y\n",
    "y' = -sinA * x + cosA * y\n",
    "\n",
    "y, x はフィルタの位置　フィルタサイズがKとすると、 y, x は [-K//2, k//2]　の値を取る。\n",
    "g ... gamma ガボールフィルタの楕円率\n",
    "s ... sigma ガウス分布の標準偏差\n",
    "l ... lambda 周波数の波長\n",
    "p ... 位相オフセット\n",
    "A ... フィルタの回転　抽出したい角度を指定する。\n",
    "```\n",
    "\n",
    "ここでは、K=111, s=10, g = 1.2, l =10, p=0, A=0としてガボールフィルタを可視化せよ。\n",
    "\n",
    "ガボールフィルタを実際に使う時は、フィルタ値の絶対値の和が1になるように正規化すると使いやすくなる。\n",
    "\n",
    "答えでは可視化のためにフィルタの値を[0,255]に正規化している。\n",
    "\n",
    "|出力(answer_77.jpg)|\n",
    "|:---:|\n",
    "|![](./Question_71_80/answer_77.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gabor\n",
    "K_size = 111\n",
    "Sigma = 10\n",
    "Gamma = 1.2\n",
    "Lambda = 10.\n",
    "Psi = 0.\n",
    "angle = 0\n",
    "\n",
    "d = K_size // 2\n",
    "\n",
    "gabor = np.zeros((K_size, K_size), dtype=np.float32)\n",
    "\n",
    "for y in range(K_size):\n",
    "    for x in range(K_size):\n",
    "        px = x - d\n",
    "        py = y - d\n",
    "        theta = angle / 180. * np.pi\n",
    "        _x = np.cos(theta) * px + np.sin(theta) * py\n",
    "        _y = -np.sin(theta) * px + np.cos(theta) * py\n",
    "        gabor[x, y] = np.exp(-(_x**2 + Gamma**2 * _y**2) / (2 * Sigma**2)) * np.cos(2*np.pi*_x/Lambda + Psi)\n",
    "\n",
    "gabor /= np.sum(np.abs(gabor))\n",
    "\n",
    "# Visualize\n",
    "out = gabor - np.min(gabor)\n",
    "out /= np.max(out)\n",
    "out *= 255\n",
    "out = out.astype(np.uint8)\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.78. ガボールフィルタの回転\n",
    "\n",
    "ここでは A=0, 45, 90, 135として回転方向のガボールフィルタを求めよ。\n",
    "その他のパラメータはQ.76同様、K=111, s=10, g = 1.2, l =10, p=0とせよ。\n",
    "\n",
    "ここではガボールフィルタをメソッド化すれば簡単に実装できる。\n",
    "\n",
    "|出力(answer_78.png)|\n",
    "|:---:|\n",
    "|![](./Question_71_80/answer_78.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Gabor\n",
    "\n",
    "def gabor_f(k=111, s=10, g=1.2, l=10, p=0, A=0):\n",
    "    d = k // 2\n",
    "\n",
    "    gabor = np.zeros((k, k), dtype=np.float32)\n",
    "    \n",
    "    for y in range(k):\n",
    "        for x in range(k):\n",
    "            px = x - d\n",
    "            py = y - d\n",
    "            theta = A / 180. * np.pi\n",
    "            _x = np.cos(theta) * px + np.sin(theta) * py\n",
    "            _y = -np.sin(theta) * px + np.cos(theta) * py\n",
    "            gabor[x, y] = np.exp(-(_x**2 + g**2 * _y**2) / (2 * s**2)) * np.cos(2*np.pi*_x/l + p)\n",
    "\n",
    "    gabor /= np.sum(np.abs(gabor))\n",
    "\n",
    "    return gabor\n",
    "\n",
    "As = [0, 45, 90, 135]\n",
    "\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0, hspace=0, wspace=0.2)\n",
    "\n",
    "for i, A in enumerate(As):\n",
    "    gabor = gabor_f(A=A)\n",
    "    out = gabor - np.min(gabor)\n",
    "    out /= np.max(out)\n",
    "    out *= 255\n",
    "    out = out.astype(np.uint8)\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(out, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Angle \"+str(A))\n",
    "\n",
    "plt.savefig(\"out.png\")\n",
    "plt.show()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.79. ガボールフィルタによるエッジ抽出\n",
    "\n",
    "*imori.jpg*をグレースケール化し、A=0, 45, 90, 135 のガボールフィルタでフィルタリングせよ。\n",
    "\n",
    "パラメータはK=11, s=1.5, g=1.2, l=3, p=0とする。\n",
    "\n",
    "解答例の様に、ガボールフィルタで指定した方向のエッジが抽出できていることが分かる。\n",
    "このようにガボールフィルタはエッジの特徴抽出に優れている。\n",
    "\n",
    "ガボールフィルタは生物の視神経における脳内の一次視覚野(V1)での働きに近いとされていて、つまり生物が見ている時の眼の前の画像の特徴抽出を再現しているともいわれる。\n",
    "\n",
    "**ディープラーニング**のConvolutional層はガボールフィルタの働きに近いとも考えられている。しかし、ディープラーニングではフィルタの係数が機械学習によって自動的に決定される。機械学習の結果、ガボールフィルタに近い働きが生じると言われる。\n",
    "\n",
    "入力 (imori.jpg) |出力(answer_79.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_71_80/imori.jpg)|![](./Question_71_80/answer_79.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Otsu binary\n",
    "## Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# Gabor\n",
    "def gabor_f(k=111, s=10, g=1.2, l=10, p=0, A=0):\n",
    "    d = k // 2\n",
    "\n",
    "    gabor = np.zeros((k, k), dtype=np.float32)\n",
    "    \n",
    "    for y in range(k):\n",
    "        for x in range(k):\n",
    "            px = x - d\n",
    "            py = y - d\n",
    "            theta = A / 180. * np.pi\n",
    "            _x = np.cos(theta) * px + np.sin(theta) * py\n",
    "            _y = -np.sin(theta) * px + np.cos(theta) * py\n",
    "            gabor[x, y] = np.exp(-(_x**2 + g**2 * _y**2) / (2 * s**2)) * np.cos(2*np.pi*_x/l + p)\n",
    "\n",
    "    gabor /= np.sum(np.abs(gabor))\n",
    "\n",
    "    return gabor\n",
    "\n",
    "K_size = 11\n",
    "Sigma = 1.5\n",
    "Gamma = 1.2\n",
    "Lambda = 3.\n",
    "Psi = 0.\n",
    "\n",
    "gray = np.pad(gray, (K_size//2, K_size//2), 'edge')\n",
    "\n",
    "As = [0, 45, 90, 135]\n",
    "\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0, hspace=0, wspace=0.2)\n",
    "\n",
    "for i, A in enumerate(As):\n",
    "    gabor = gabor_f(k=K_size, s=Sigma, g=Gamma, l=Lambda, p=Psi, A=A)\n",
    "\n",
    "    out = np.zeros((H, W), dtype=np.float32)\n",
    "    \n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            out[y, x] = np.sum(gray[y:y+K_size, x:x+K_size] * gabor)\n",
    "\n",
    "    out[out < 0] = 0\n",
    "    out[out > 255] = 255\n",
    "    \n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(out, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Angle \"+str(A))\n",
    "\n",
    "plt.savefig(\"out.png\")\n",
    "plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.80. ガボールフィルタによる特徴抽出\n",
    "\n",
    "Q.79で求めた４枚の画像を足し合わせることで、画像の特徴を抽出せよ。\n",
    "\n",
    "結果を見ると、画像の輪郭部分が白くなっていることからエッジ検出のような出力を得たように見える。\n",
    "\n",
    "ディープラーニングのCNN(Convolutional Neural Network)では、最初に画像の特徴を抽出する働きが備わっているが、その特徴抽出の計算はこの問で行ったような操作を延々と繰り返している。ディープラーニングではこのようにして画像の特徴を自動的に抽出している。\n",
    "\n",
    "入力 (imori.jpg) |出力(answer_80.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_71_80/imori.jpg)|![](./Question_71_80/answer_80.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Otsu binary\n",
    "## Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "# Gabor\n",
    "def gabor_f(k=111, s=10, g=1.2, l=10, p=0, A=0):\n",
    "    d = k // 2\n",
    "\n",
    "    gabor = np.zeros((k, k), dtype=np.float32)\n",
    "    \n",
    "    for y in range(k):\n",
    "        for x in range(k):\n",
    "            px = x - d\n",
    "            py = y - d\n",
    "            theta = A / 180. * np.pi\n",
    "            _x = np.cos(theta) * px + np.sin(theta) * py\n",
    "            _y = -np.sin(theta) * px + np.cos(theta) * py\n",
    "            gabor[x, y] = np.exp(-(_x**2 + g**2 * _y**2) / (2 * s**2)) * np.cos(2*np.pi*_x/l + p)\n",
    "\n",
    "    gabor /= np.sum(np.abs(gabor))\n",
    "\n",
    "    return gabor\n",
    "\n",
    "K_size = 11\n",
    "Sigma = 1.5\n",
    "Gamma = 1.2\n",
    "Lambda = 3.\n",
    "Psi = 0.\n",
    "\n",
    "gray = np.pad(gray, (K_size//2, K_size//2), 'edge')\n",
    "\n",
    "As = [0, 45, 90, 135]\n",
    "\n",
    "gs = []\n",
    "\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0, hspace=0, wspace=0.2)\n",
    "\n",
    "for i, A in enumerate(As):\n",
    "    gabor = gabor_f(k=K_size, s=Sigma, g=Gamma, l=Lambda, p=Psi, A=A)\n",
    "\n",
    "    out = np.zeros((H, W), dtype=np.float32)\n",
    "    \n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            out[y, x] = np.sum(gray[y:y+K_size, x:x+K_size] * gabor)\n",
    "\n",
    "    out[out < 0] = 0\n",
    "    out[out > 255] = 255\n",
    "    \n",
    "    gs.append(out)\n",
    "\n",
    "\n",
    "out = np.zeros((H, W), dtype=np.float32)\n",
    "for g in gs:\n",
    "    out += g\n",
    "\n",
    "    \n",
    "out = out / out.max() * 255\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 81 - 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.81. Hessianのコーナー検出\n",
    "\n",
    "*thorino.jpg*にHessian(ヘシアン)のコーナー検出を行え。\n",
    "\n",
    "コーナー検出とはエッジにおける角の点を検出することである。\n",
    "\n",
    "コーナーは曲率が大きくなる点であり、次式のガウス曲率において、\n",
    "\n",
    "```bash\n",
    "ガウス曲率 K = det(H) / (1 + Ix^2 + Iy^2)^2\n",
    "\n",
    "det(H) = Ixx Iyy - IxIy^2\n",
    "H ... ヘシアン行列。画像の二次微分(グレースケール画像などに対して、Sobelフィルタを掛けて求められる)。画像上の一点に対して、次式で定義される。\n",
    "Ix ... x方向のsobelフィルタを掛けたもの。 Iy ... y方向のsobelフィルタ\n",
    "H = [ Ix^2  IxIy]\n",
    "      IxIy  Iy^2\n",
    "```\n",
    "\n",
    "ヘシアンのコーナー検出では、det(H)が極大点をコーナーとみなす。\n",
    "極大点は注目画素と8近傍を比較して、注目画素の値が最大であれば極大点として扱う。\n",
    "\n",
    "解答ではdet(H)が極大点かつ、max(H)*0.1以上である点をコーナーとしている。\n",
    "\n",
    "|入力 (thorino.jpg) |出力(answer_81.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_81_90/thorino.jpg)|![](./Question_81_90/answer_81.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"thorino.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "## Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "gray = gray.astype(np.uint8)\n",
    "\n",
    "## Sobel\n",
    "sobely = np.array(((1, 2, 1),\n",
    "                   (0, 0, 0),\n",
    "                   (-1, -2, -1)), dtype=np.float32)\n",
    "\n",
    "sobelx = np.array(((1, 0, -1),\n",
    "                   (2, 0, -2),\n",
    "                   (1, 0, -1)), dtype=np.float32)\n",
    "\n",
    "tmp = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "Ix = np.zeros_like(gray, dtype=np.float32)\n",
    "Iy = np.zeros_like(gray, dtype=np.float32)\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        Ix[y, x] = np.mean(tmp[y:y+3, x:x+3] * sobelx)\n",
    "        Iy[y, x] = np.mean(tmp[y:y+3, x:x+3] * sobely)\n",
    "     \n",
    "Ix2 = Ix ** 2\n",
    "IxIy = Ix * Iy\n",
    "Iy2 = Iy ** 2\n",
    "\n",
    "out = np.array((gray, gray, gray))\n",
    "out = np.transpose(out, (1,2,0))\n",
    "\n",
    "## Hessian\n",
    "Hes = np.zeros((H, W))\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        Hes[y,x] = Ix2[y,x] * Iy2[y,x] - IxIy[y,x] ** 2\n",
    "\n",
    "## Detect Corner\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        if Hes[y,x] == np.max(Hes[max(y-1,0):min(y+2,H), max(x-1,0):min(x+2,W)]) and Hes[y,x] > np.max(Hes)*0.1:\n",
    "            out[y, x] = [0, 0, 255]\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.82. Harrisのコーナー検出 (Step.1) Sobel + Gauusian\n",
    "\n",
    "ここからQ.83まで*thorino.jpg*にHarris(ハリス)のコーナー検出を行っていく。\n",
    "\n",
    "Harrisのコーナー検出のアルゴリズムは、\n",
    "1. 画像をグレースケール化。\n",
    "2. Sobelフィルタにより、ヘシアン行列を求める。\n",
    "```bash\n",
    "H = [ Ix^2  IxIy]\n",
    "      IxIy  Iy^2\n",
    "```\n",
    "3. Ix^2, Iy^2, IxIyにそれぞれガウシアンフィルターをかける。\n",
    "4. 各ピクセル毎に、R = det(H) - k (trace(H))^2 を計算する。 (kは実験的に0.04 - 0.16らへんが良いとされる)\n",
    "5. R >= max(R) * th を満たすピクセルがコーナーとなる。  (thは0.1となることが多い)\n",
    "\n",
    "Q.82-83においての各パラメータは以下の通り。\n",
    "- ガウシアンフィルター(k=3, sigma=3)\n",
    "- k = 0.04, th = 0.1\n",
    "\n",
    "ここでは1-3までを実装せよ。\n",
    "\n",
    "|入力 (thorino.jpg) |出力(answer_82.png)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_81_90/thorino.jpg)|![](./Question_81_90/answer_82.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"thorino.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "## Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Harris\n",
    "\n",
    "## Sobel\n",
    "sobely = np.array(((1, 2, 1),\n",
    "                   (0, 0, 0),\n",
    "                   (-1, -2, -1)), dtype=np.float32)\n",
    "\n",
    "sobelx = np.array(((1, 0, -1),\n",
    "                   (2, 0, -2),\n",
    "                   (1, 0, -1)), dtype=np.float32)\n",
    "\n",
    "tmp = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "Ix = np.zeros_like(gray, dtype=np.float32)\n",
    "Iy = np.zeros_like(gray, dtype=np.float32)\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        Ix[y, x] = np.sum(tmp[y:y+3, x:x+3] * sobelx)\n",
    "        Iy[y, x] = np.sum(tmp[y:y+3, x:x+3] * sobely)\n",
    "\n",
    "Ix2 = Ix ** 2\n",
    "Iy2 = Iy ** 2\n",
    "Ixy = Ix * Iy\n",
    "\n",
    "## gaussian\n",
    "K_size = 3\n",
    "sigma = 3\n",
    "Ix2_t = np.pad(Ix2, (K_size // 2, K_size // 2), 'edge')\n",
    "Iy2_t = np.pad(Iy2, (K_size // 2, K_size // 2), 'edge')\n",
    "Ixy_t = np.pad(Ixy, (K_size // 2, K_size // 2), 'edge')\n",
    "\n",
    "K = np.zeros((K_size, K_size), dtype=np.float)\n",
    "for x in range(K_size):\n",
    "    for y in range(K_size):\n",
    "        _x = x - K_size // 2\n",
    "        _y = y - K_size // 2\n",
    "        K[y, x] = np.exp( -(_x**2 + _y**2) / (2 * (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        Ix2[y,x] = np.sum(Ix2_t[y:y+K_size, x:x+K_size] * K)\n",
    "        Iy2[y,x] = np.sum(Iy2_t[y:y+K_size, x:x+K_size] * K)\n",
    "        Ixy[y,x] = np.sum(Ixy_t[y:y+K_size, x:x+K_size] * K)\n",
    "\n",
    "out = np.array((gray, gray, gray))\n",
    "out = np.transpose(out, (1,2,0))\n",
    "\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0, hspace=0, wspace=0.2)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(Ix2, cmap='gray')\n",
    "plt.title(\"Ix^2\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(Iy2, cmap='gray')\n",
    "plt.title(\"Iy^2\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(Ixy, cmap='gray')\n",
    "plt.title(\"Ixy\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig(\"out.png\")\n",
    "plt.show()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.83. Harrisのコーナー検出 (Step.2) コーナー検出\n",
    "\n",
    "ここではアルゴリズム4-5を実装せよ。\n",
    "\n",
    "4における k = 0.04、5におけるth = 0.1\n",
    "\n",
    "|入力 (thorino.jpg) |出力(answer_83.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_81_90/thorino.jpg)|![](./Question_81_90/answer_83.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"thorino.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "## Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "# Harris\n",
    "\n",
    "## Sobel\n",
    "sobely = np.array(((1, 2, 1),\n",
    "                   (0, 0, 0),\n",
    "                   (-1, -2, -1)), dtype=np.float32)\n",
    "\n",
    "sobelx = np.array(((1, 0, -1),\n",
    "                   (2, 0, -2),\n",
    "                   (1, 0, -1)), dtype=np.float32)\n",
    "\n",
    "tmp = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "Ix = np.zeros_like(gray, dtype=np.float32)\n",
    "Iy = np.zeros_like(gray, dtype=np.float32)\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        Ix[y, x] = np.sum(tmp[y:y+3, x:x+3] * sobelx)\n",
    "        Iy[y, x] = np.sum(tmp[y:y+3, x:x+3] * sobely)\n",
    "\n",
    "Ix2 = Ix ** 2\n",
    "Iy2 = Iy ** 2\n",
    "Ixy = Ix * Iy\n",
    "\n",
    "## gaussian\n",
    "K_size = 3\n",
    "sigma = 3\n",
    "Ix2_t = np.pad(Ix2, (K_size // 2, K_size // 2), 'edge')\n",
    "Iy2_t = np.pad(Iy2, (K_size // 2, K_size // 2), 'edge')\n",
    "Ixy_t = np.pad(Ixy, (K_size // 2, K_size // 2), 'edge')\n",
    "\n",
    "K = np.zeros((K_size, K_size), dtype=np.float)\n",
    "for x in range(K_size):\n",
    "    for y in range(K_size):\n",
    "        _x = x - K_size // 2\n",
    "        _y = y - K_size // 2\n",
    "        K[y, x] = np.exp( -(_x**2 + _y**2) / (2 * (sigma**2)))\n",
    "K /= (sigma * np.sqrt(2 * np.pi))\n",
    "K /= K.sum()\n",
    "\n",
    "for y in range(H):\n",
    "    for x in range(W):\n",
    "        Ix2[y,x] = np.sum(Ix2_t[y:y+K_size, x:x+K_size] * K)\n",
    "        Iy2[y,x] = np.sum(Iy2_t[y:y+K_size, x:x+K_size] * K)\n",
    "        Ixy[y,x] = np.sum(Ixy_t[y:y+K_size, x:x+K_size] * K)\n",
    "\n",
    "out = np.array((gray, gray, gray))\n",
    "out = np.transpose(out, (1,2,0))\n",
    "\n",
    "## select corner\n",
    "k = 0.04\n",
    "M = (Ix2 * Iy2 - Ixy ** 2) - k * ((Ix2 + Iy2) ** 2)\n",
    "\n",
    "th = 0.1\n",
    "out[M >= np.max(M) * th] = [0, 0, 255]\n",
    "\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.84. 簡単な画像認識 (Step.1) 減色化 + ヒストグラム\n",
    "\n",
    "ここでは簡単な画像認識を作成する。\n",
    "\n",
    "画像認識とは画像に写っているモノが何か（どのクラスに属するか）を特定するタスクである。\n",
    "画像認識はよく、画像分類、Classification(クラス分類)、Categorization(カテゴライゼーション)、Clustering(クラスタリング)、などと呼ばれる。\n",
    "\n",
    "よくある手法は画像から何らかの特徴(HOGやSIFT, SURFなど)を抽出し、その特徴によりクラスを判別する。\n",
    "CNNが流行る以前はこのアプローチがよく取られたが、CNNは特徴抽出から判別までを一括して行える。\n",
    "\n",
    "ここでは、画像の色ヒストグラムを用いた簡単な画像認識を行う。\n",
    "\n",
    "アルゴリズムとしては、\n",
    "1. 画像(train_***.jpg)を減色処理(Q.6. RGBをそれぞれ4階調)する。\n",
    "2. 減色処理した画像のヒストグラムを作成する。ここでのヒストグラムはRGBがそれぞれ4値をとるが、それらを区別するため、B=[1,4], G=[5,8], R=[9,12]のbin=12となる。それぞれの画像に対応するヒストグラムも保存する必要があるので注意。\n",
    " 　つまり、database = np.zeros((10(学習データ数), 13(RGB + class), dtype=np.int)　に学習データのヒストグラムを格納する必要がある。\n",
    "3. ２のヒストグラムをデータベースとする。\n",
    "4. 認識したい画像(test_@@@.jpg)とヒストグラムの差を計算して、特徴量とする。\n",
    "5. ヒストグラムの差の合計で、最小となった画像が予測となるクラスである。つまり、色が近い画像と同じクラスになると考えられる。\n",
    "\n",
    "ここでは1-3を実装し、ヒストグラムを可視化せよ。\n",
    "学習データは train_akahara_@@@.jpg (クラス1)と train_madara_@@@.jpg(クラス2) を用いる。(計10枚)\n",
    "akaharaとはアカハライモリ、madaraはマダライモリである。\n",
    "\n",
    "\n",
    "このような予め特徴量を保存しておくデータベース型は人工知能第一世代の手法である。ようは、全部のパターンを暗記しておけばOKという考え方である。ただし、そうするとメモリを大量に消費するので使用が限られる手法である。\n",
    "\n",
    "\n",
    "|出力(answer_84.png)|\n",
    "|:---:|\n",
    "|![](./Question_81_90/answer_84.png)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "## Dicrease color\n",
    "def dic_color(img):\n",
    "    img //= 63\n",
    "    img = img * 64 + 32\n",
    "    return img\n",
    "\n",
    "## Database\n",
    "train = glob(\"train_*\")\n",
    "train.sort()\n",
    "\n",
    "db = np.zeros((len(train), 13), dtype=np.int32)\n",
    "\n",
    "for i, path in enumerate(train):\n",
    "    img = dic_color(cv2.imread(path))\n",
    "    ## histogram\n",
    "    for j in range(4):\n",
    "        db[i, j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        db[i, j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        db[i, j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## class\n",
    "    if 'akahara' in path:\n",
    "        cls = 0\n",
    "    elif 'madara' in path:\n",
    "        cls = 1\n",
    "    db[i, -1] = cls\n",
    "\n",
    "    img_h = img.copy() // 64\n",
    "    img_h[..., 1] += 4\n",
    "    img_h[..., 2] += 8\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.hist(img_h.ravel(), bins=12, rwidth=0.8)\n",
    "    plt.title(path)\n",
    "\n",
    "print(db)\n",
    "plt.show()\n",
    "```\n",
    "</div></details>\n",
    "\n",
    "```bash\n",
    "格納されるヒストグラムの中身\n",
    "[[  172 12254  2983   975   485 11576  3395   928   387 10090  4845  1062  0]\n",
    "[ 3627  7350  4420   987  1743  8438  4651  1552   848  9089  4979  1468  0]\n",
    "[ 1646  6547  5807  2384  1715  8502  5233   934  1553  5270  7167  2394  0]\n",
    "[  749 10142  5465    28  1431  7922  7001    30  1492  7819  7024    49  0]\n",
    "[  927  4197  8581  2679   669  5689  7959  2067   506  3973  6387  5518  0]\n",
    "[ 2821  6404  2540  4619  1625  7317  3019  4423   225  8635  1591  5933  1]\n",
    "[ 5575  7831  1619  1359  4638  6777  3553  1416  4675  7964  2176  1569  1]\n",
    "[ 4867  7523  3275   719  4457  6390  3049  2488  4328  7135  3377  1544  1]\n",
    "[ 7881  6160  1992   351  7426  3967  4258   733  7359  4979  3322   724  1]\n",
    "[ 5638  6580  3916   250  5041  4185  6286   872  5226  4930  5552   676  1]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.85. 簡単な画像認識 (Step.2) クラス判別\n",
    "\n",
    "ここではアルゴリズム4-5を実装せよ。\n",
    "\n",
    "テストデータには test_akahara_@@@.jpgとtest_madara_@@@.jpgを用いよ。（計4枚）\n",
    "ただし、各画像と最もヒストグラム差分が小さい画像の名前と予測クラスの2つを出力せよ。\n",
    "\n",
    "これはNearesetNeighbourと呼ばれる評価方法である。\n",
    "\n",
    "答え\n",
    "\n",
    "```bash\n",
    "test_akahara_1.jpg is similar >> train_akahara_3.jpg  Pred >> akahara\n",
    "test_akahara_2.jpg is similar >> train_akahara_1.jpg  Pred >> akahara\n",
    "test_madara_1.jpg is similar >> train_madara_2.jpg  Pred >> madara\n",
    "test_madara_2.jpg is similar >> train_akahara_2.jpg  Pred >> akahara\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "## Dicrease color\n",
    "def dic_color(img):\n",
    "    img //= 63\n",
    "    img = img * 64 + 32\n",
    "    return img\n",
    "\n",
    "## Database\n",
    "train = glob(\"train_*\")\n",
    "train.sort()\n",
    "\n",
    "db = np.zeros((len(train), 13), dtype=np.int32)\n",
    "pdb = []\n",
    "\n",
    "for i, path in enumerate(train):\n",
    "    img = dic_color(cv2.imread(path))\n",
    "    ## histogram\n",
    "    for j in range(4):\n",
    "        db[i, j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        db[i, j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        db[i, j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## class\n",
    "    if 'akahara' in path:\n",
    "        cls = 0\n",
    "    elif 'madara' in path:\n",
    "        cls = 1\n",
    "    db[i, -1] = cls\n",
    "    pdb.append(path)\n",
    "\n",
    "## test\n",
    "test = glob(\"test_*\")\n",
    "test.sort()\n",
    "\n",
    "success_num = 0.\n",
    "\n",
    "for path in test:\n",
    "    img = dic_color(cv2.imread(path))\n",
    "\n",
    "    hist = np.zeros(12, dtype=np.int32)\n",
    "    for j in range(4):\n",
    "        hist[j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        hist[j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        hist[j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## compute difference\n",
    "    difs = np.abs(db[:, :12] - hist)\n",
    "    difs = np.sum(difs, axis=1)\n",
    "    pred_i = np.argmin(difs)\n",
    "    pred = db[pred_i, -1]\n",
    "\n",
    "    if pred == 0:\n",
    "        pl = \"akahara\"\n",
    "    elif pred == 1:\n",
    "        pl = \"madara\"\n",
    "    \n",
    "    print(path, \"is similar >>\", pdb[pred_i], \" Pred >>\", pl)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.86. 簡単な画像認識 (Step.3) 評価(Accuracy)\n",
    "\n",
    "ここでは画像認識の結果を評価する。\n",
    "\n",
    "画像認識の場合はどれくらい正解クラスを予想できたかを示す**Accuracy**(Precisionといったりもする)が一般的な評価指標である。Accuracyは次式で計算される。要はテストにおける得点率である。小数表示するときや、100掛けてパーセンテージで表すこともある。\n",
    "\n",
    "```bash\n",
    "Accuracy = (正解した画像数) / (テストした画像の総数)\n",
    "```\n",
    "以上を踏まえて、Q.85のAccuracyを求めよ。\n",
    "\n",
    "\n",
    "答え\n",
    "\n",
    "```bash\n",
    "Accuracy >> 0.75 (3/4)\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "## Dicrease color\n",
    "def dic_color(img):\n",
    "    img //= 63\n",
    "    img = img * 64 + 32\n",
    "    return img\n",
    "\n",
    "## Database\n",
    "train = glob(\"train_*\")\n",
    "train.sort()\n",
    "\n",
    "db = np.zeros((len(train), 13), dtype=np.int32)\n",
    "pdb = []\n",
    "\n",
    "for i, path in enumerate(train):\n",
    "    img = dic_color(cv2.imread(path))\n",
    "    ## histogram\n",
    "    for j in range(4):\n",
    "        db[i, j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        db[i, j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        db[i, j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## class\n",
    "    if 'akahara' in path:\n",
    "        cls = 0\n",
    "    elif 'madara' in path:\n",
    "        cls = 1\n",
    "    db[i, -1] = cls\n",
    "    pdb.append(path)\n",
    "\n",
    "## test\n",
    "test = glob(\"test_*\")\n",
    "test.sort()\n",
    "\n",
    "success_num = 0.\n",
    "\n",
    "for path in test:\n",
    "    img = dic_color(cv2.imread(path))\n",
    "\n",
    "    hist = np.zeros(12, dtype=np.int32)\n",
    "    for j in range(4):\n",
    "        hist[j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        hist[j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        hist[j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## compute difference\n",
    "    difs = np.abs(db[:, :12] - hist)\n",
    "    difs = np.sum(difs, axis=1)\n",
    "    pred_i = np.argmin(difs)\n",
    "    pred = db[pred_i, -1]\n",
    "\n",
    "    if pred == 0:\n",
    "        pl = \"akahara\"\n",
    "    elif pred == 1:\n",
    "        pl = \"madara\"\n",
    "    \n",
    "    print(path, \"is similar >>\", pdb[pred_i], \" Pred >>\", pl)\n",
    "\n",
    "    ## Count success\n",
    "    gt = \"akahara\" if \"akahara\" in path else \"madara\"\n",
    "    if gt == pl:\n",
    "        success_num += 1.\n",
    "\n",
    "accuracy = success_num / len(test)\n",
    "print(\"Accuracy >>\", accuracy, \"({}/{})\".format(int(success_num), len(test)))\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.87. 簡単な画像認識 (Step.4) k-NN\n",
    "\n",
    "Q.85では最も色が近い画像が予測クラスであるとしたが、そこで*test_madara_2.jpg*が*train_akahara_2.jpg*と最も色が近いと判断された。\n",
    "\n",
    "|test_marada_2.jpg|train_akahara_2.jpg|\n",
    "|:---:|:---:|\n",
    "|![](./Question_81_90/test_madara_2.jpg)|![](./Question_81_90/train_akahara_2.jpg)|\n",
    "\n",
    "2つの画像を見比べるとたしかに両方とも緑の割合と黒の割合が近く見えるので、画像全体に対しての画像の色味が同じ様に見えてしまう。これは認識時のサンプルを一つにしたことによって、例外的な画像が選ばれてしまったためである。このように学習データの特徴は常にきれいに分離されているわけではなく、時に特徴の分布から逸しているサンプルも含まれる。\n",
    "\n",
    "これを回避するために、ここでは色合いが近い画像を3つ選び、それらの多数決によって予測クラスを決定し、Accuracyを計算せよ。\n",
    "\n",
    "このように特徴が近いものを学習データから3つ選んで判断する手法をk近傍(k-NN: k-Nearest Neighbor)という。Q.85.のNN法はk=1の場合とみれる。\n",
    "\n",
    "\n",
    "答え\n",
    "```bash\n",
    "test_akahara_1.jpg is similar >> train_akahara_3.jpg, train_akahara_2.jpg, train_akahara_4.jpg, |Pred >> akahara\n",
    "test_akahara_2.jpg is similar >> train_akahara_1.jpg, train_akahara_2.jpg, train_akahara_4.jpg, |Pred >> akahara\n",
    "test_madara_1.jpg is similar >> train_madara_2.jpg, train_madara_4.jpg, train_madara_3.jpg, |Pred >> madara\n",
    "test_madara_2.jpg is similar >> train_akahara_2.jpg, train_madara_3.jpg, train_madara_2.jpg, |Pred >> madara\n",
    "Accuracy >> 1.0 (4/4)\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "## Dicrease color\n",
    "def dic_color(img):\n",
    "    img //= 63\n",
    "    img = img * 64 + 32\n",
    "    return img\n",
    "\n",
    "## Database\n",
    "train = glob(\"train_*\")\n",
    "train.sort()\n",
    "\n",
    "db = np.zeros((len(train), 13), dtype=np.int32)\n",
    "pdb = []\n",
    "\n",
    "for i, path in enumerate(train):\n",
    "    img = dic_color(cv2.imread(path))\n",
    "    ## histogram\n",
    "    for j in range(4):\n",
    "        db[i, j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        db[i, j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        db[i, j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## class\n",
    "    if 'akahara' in path:\n",
    "        cls = 0\n",
    "    elif 'madara' in path:\n",
    "        cls = 1\n",
    "    db[i, -1] = cls\n",
    "    pdb.append(path)\n",
    "\n",
    "## test\n",
    "test = glob(\"test_*\")\n",
    "test.sort()\n",
    "\n",
    "success_num = 0.\n",
    "\n",
    "for path in test:\n",
    "    img = dic_color(cv2.imread(path))\n",
    "\n",
    "    hist = np.zeros(12, dtype=np.int32)\n",
    "    for j in range(4):\n",
    "        hist[j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        hist[j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        hist[j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## compute difference\n",
    "    difs = np.abs(db[:, :12] - hist)\n",
    "    difs = np.sum(difs, axis=1)\n",
    "    pred_i = np.argsort(difs)[:3]\n",
    "    pred = db[pred_i, -1]\n",
    "    if len(pred[pred == 0]) > len(pred[pred == 1]):\n",
    "        pl = \"akahara\"\n",
    "    else:\n",
    "        pl = 'madara'\n",
    "\n",
    "    print(path, \"is similar >> \", end='')\n",
    "    for i in pred_i:\n",
    "        print(pdb[i], end=', ')\n",
    "    print(\"|Pred >>\", pl)\n",
    "\n",
    "    ## Count success\n",
    "    gt = \"akahara\" if \"akahara\" in path else \"madara\"\n",
    "    if gt == pl:\n",
    "        success_num += 1.\n",
    "\n",
    "accuracy = success_num / len(test)\n",
    "print(\"Accuracy >>\", accuracy, \"({}/{})\".format(int(success_num), len(test)))\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.88. K-means (Step.1) 重心作成\n",
    "\n",
    "Q.84-87の画像認識は教師データを必要とするいわゆる**教師あり学習**(supervised-training)のものすごく簡単なものだったが、ここでは教師を必要としない**教師なし学習**(unsupervised-training)で画像を分類する。\n",
    "\n",
    "最も簡単な方法が**K-meansクラスタリング法**である。\n",
    "\n",
    "これは予めクラス数が分かっている場合に使うことができ、特徴量を重心に分けながらクラスタリングする手法である。\n",
    "\n",
    "K-Meansアルゴリズムとしては、\n",
    "1. データにそれぞれランダムにクラスを割り当てる。\n",
    "2. クラスごとに重心を計算する。\n",
    "3. 各データと重心の距離を計算し、最も距離が近い重心のクラスを割り当てる。\n",
    "4. 2-3をクラス変更がなくなるまで繰り返す。\n",
    "\n",
    "ここでは、減色化とヒストグラムを特徴量として次のようにアルゴリズムを作成する。\n",
    "1. 画像を減色化し、ヒストグラムを作成し、これを特徴量とする。\n",
    "2. 各画像にランダムに0か1のクラスを割り当てる。 (ここでは、クラス数=2, np.random.seed(1)　として、np.random.random < thなら0、>=0thなら1を割り当てる。th=0.5)\n",
    "3. クラスが0、１の特徴量の重心(mean)をそれぞれ取る。(重心は gs = np.zeros((Class, 12), dtype=np.float32)に格納する。)\n",
    "4. 各画像に対して、特徴量と重心の距離(ユークリッド距離(L1ノルム): 差を二乗し、その合計のsqrtをとったもの)を計算し、距離が近い重心のクラスを割り当てる。\n",
    "5. 3-4をクラスの変更がなくなるまで繰り返す。\n",
    "\n",
    "ここでは、1-3までを実装せよ(4,5のことを考えてループを作らなくてもよい)。分類する画像は*test_@@@.jpg*とする。\n",
    "\n",
    "\n",
    "答え\n",
    "\n",
    "```bash\n",
    "assigned label\n",
    "[[ 1493  7892  4900  2099  1828  9127  4534   895  1554  6750  5406  2674 0]\n",
    "[  242 10338  3628  2176   587 12212  2247  1338   434 10822  4506   622 1]\n",
    "[ 6421  5478   719  3766  5482  4294  2537  4071  5609  4823  2051  3901 0]\n",
    "[ 3343  8134  4756   151  3787  7588  3935  1074  3595  8444  4069   276 0]]\n",
    "Grabity\n",
    "[[ 3752.3333  7168.      3458.3333  2005.3334  3699.      7003.\n",
    "3668.6667  2013.3334  3586.      6672.3335  3842.      2283.6667]\n",
    "[  242.     10338.      3628.      2176.       587.     12212.\n",
    "2247.      1338.       434.     10822.      4506.       622.    ]]\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "## Dicrease color\n",
    "def dic_color(img):\n",
    "    img //= 63\n",
    "    img = img * 64 + 32\n",
    "    return img\n",
    "\n",
    "## Database\n",
    "train = glob(\"test_*\")\n",
    "train.sort()\n",
    "\n",
    "db = np.zeros((len(train), 13), dtype=np.int32)\n",
    "pdb = []\n",
    "\n",
    "for i, path in enumerate(train):\n",
    "    img = dic_color(cv2.imread(path))\n",
    "    ## histogram\n",
    "    for j in range(4):\n",
    "        db[i, j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        db[i, j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        db[i, j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## class\n",
    "    if 'akahara' in path:\n",
    "        cls = 0\n",
    "    elif 'madara' in path:\n",
    "        cls = 1\n",
    "    db[i, -1] = cls\n",
    "    pdb.append(path)\n",
    "\n",
    "# k-Means\n",
    "Class = 2\n",
    "\n",
    "feats = db.copy()\n",
    "np.random.seed(1)\n",
    "## assign random class \n",
    "for i in range(len(feats)):\n",
    "    if np.random.random() < 0.5:\n",
    "        feats[i, -1] = 0\n",
    "    else:\n",
    "        feats[i, -1] = 1\n",
    "\n",
    "gs = np.zeros((Class, 12), dtype=np.float32)\n",
    "    \n",
    "for i in range(Class):\n",
    "    gs[i] = np.mean(feats[np.where(feats[..., -1] == i)[0], :12], axis=0)\n",
    "print(\"assigned label\")\n",
    "print(feats)\n",
    "print(\"Grabity\")\n",
    "print(gs)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.89. K-means (Step.2) クラスタリング\n",
    "\n",
    "ここではアルゴリズム4-5も実装して、クラスタリングを行え。\n",
    "\n",
    "ここで予測クラスが0,1となっているが、Q.85-87と違いラベルの順番はバラバラである。\n",
    "なので、K-meansはあくまでカテゴリ別に分類する手法であり、それが具体的に何のクラスかまでは分からない。\n",
    "また、クラス数は予めこちらが知って置かなければいけない。\n",
    "\n",
    "**K-meansクラスタリングでは最初に割り当てるラベルの状態によって、最後の出力が大きく左右される**ので注意が必要である。\n",
    "また、データ数が少ないと失敗しやすい。これはデータ数が少ないことで、真のデータの分布をサンプリングしにくいことが原因である。つまり、データ数が多いほどデータの分布が精度良くえられることによる。\n",
    "\n",
    "答え\n",
    "\n",
    "```bash\n",
    "test_akahara_1.jpg  Pred: 0\n",
    "test_akahara_2.jpg  Pred: 1\n",
    "test_madara_1.jpg  Pred: 0\n",
    "test_madara_2.jpg  Pred: 0\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "## Dicrease color\n",
    "def dic_color(img):\n",
    "    img //= 63\n",
    "    img = img * 64 + 32\n",
    "    return img\n",
    "\n",
    "## Database\n",
    "train = glob(\"test_*\")\n",
    "train.sort()\n",
    "\n",
    "db = np.zeros((len(train), 13), dtype=np.int32)\n",
    "pdb = []\n",
    "\n",
    "for i, path in enumerate(train):\n",
    "    img = dic_color(cv2.imread(path))\n",
    "    ## histogram\n",
    "    for j in range(4):\n",
    "        db[i, j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        db[i, j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        db[i, j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## class\n",
    "    if 'akahara' in path:\n",
    "        cls = 0\n",
    "    elif 'madara' in path:\n",
    "        cls = 1\n",
    "    db[i, -1] = cls\n",
    "    pdb.append(path)\n",
    "\n",
    "# k-Means\n",
    "Class = 2\n",
    "\n",
    "feats = db.copy()\n",
    "np.random.seed(1)\n",
    "## assign random class \n",
    "for i in range(len(feats)):\n",
    "    if np.random.random() < 0.5:\n",
    "        feats[i, -1] = 0\n",
    "    else:\n",
    "        feats[i, -1] = 1\n",
    "\n",
    "while True:\n",
    "    gs = np.zeros((Class, 12), dtype=np.float32)\n",
    "    change_count = 0\n",
    "\n",
    "    ## compute gravity\n",
    "    for i in range(Class):\n",
    "        gs[i] = np.mean(feats[np.where(feats[..., -1] == i)[0], :12], axis=0)\n",
    "\n",
    "    ## re-labeling\n",
    "    for i in range(len(feats)):\n",
    "        dis = np.square(np.sum(np.abs(gs - feats[i, :12]), axis=1))\n",
    "        pred = np.argmin(dis, axis=0)\n",
    "        if int(feats[i, -1]) != pred:\n",
    "            change_count += 1\n",
    "            feats[i, -1] = pred\n",
    "\n",
    "    if change_count < 1:\n",
    "        break\n",
    "\n",
    "for i in range(len(train)):\n",
    "    print(pdb[i], \" Pred:\", feats[i, -1])\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.90. K-means (Step.3) 初期ラベルの変更\n",
    "\n",
    "K-meansを用いて*train_@@@.jpg*の8枚を完璧にクラスタリングせよ。\n",
    "\n",
    "ここでは、np.random.seed()の値やラベルを割り当てる閾値 np.random.random() < th　のthを変更して、K-meansでクラスを完璧に予測せよ。\n",
    "*train_@@@.jpg*はQ.89より画像数が２倍になっているので、クラスタリングしやすくなっている。\n",
    "\n",
    "これは試行錯誤するしかない。\n",
    "\n",
    "答え\n",
    "\n",
    "```bash\n",
    "train_akahara_1.jpg  Pred: 1\n",
    "train_akahara_2.jpg  Pred: 1\n",
    "train_akahara_3.jpg  Pred: 1\n",
    "train_akahara_4.jpg  Pred: 1\n",
    "train_akahara_5.jpg  Pred: 1\n",
    "train_madara_1.jpg  Pred: 0\n",
    "train_madara_2.jpg  Pred: 0\n",
    "train_madara_3.jpg  Pred: 0\n",
    "train_madara_4.jpg  Pred: 0\n",
    "train_madara_5.jpg  Pred: 0\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "## Dicrease color\n",
    "def dic_color(img):\n",
    "    img //= 63\n",
    "    img = img * 64 + 32\n",
    "    return img\n",
    "\n",
    "## Database\n",
    "train = glob(\"train_*\")\n",
    "train.sort()\n",
    "\n",
    "db = np.zeros((len(train), 13), dtype=np.int32)\n",
    "pdb = []\n",
    "\n",
    "for i, path in enumerate(train):\n",
    "    img = dic_color(cv2.imread(path))\n",
    "    ## histogram\n",
    "    for j in range(4):\n",
    "        db[i, j] = len(np.where(img[..., 0] == (64 * j + 32))[0])\n",
    "        db[i, j+4] = len(np.where(img[..., 1] == (64 * j + 32))[0])\n",
    "        db[i, j+8] = len(np.where(img[..., 2] == (64 * j + 32))[0])\n",
    "\n",
    "    ## class\n",
    "    if 'akahara' in path:\n",
    "        cls = 0\n",
    "    elif 'madara' in path:\n",
    "        cls = 1\n",
    "    db[i, -1] = cls\n",
    "    pdb.append(path)\n",
    "\n",
    "# k-Means\n",
    "Class = 2\n",
    "\n",
    "feats = db.copy()\n",
    "np.random.seed(4)\n",
    "## assign random class \n",
    "for i in range(len(feats)):\n",
    "    if np.random.random() < 0.3:\n",
    "        feats[i, -1] = 0\n",
    "    else:\n",
    "        feats[i, -1] = 1\n",
    "\n",
    "while True:\n",
    "    gs = np.zeros((Class, 12), dtype=np.float32)\n",
    "    change_count = 0\n",
    "\n",
    "    ## compute gravity\n",
    "    for i in range(Class):\n",
    "        gs[i] = np.mean(feats[np.where(feats[..., -1] == i)[0], :12], axis=0)\n",
    "\n",
    "    ## re-labeling\n",
    "    for i in range(len(feats)):\n",
    "        dis = np.square(np.sum(np.abs(gs - feats[i, :12]), axis=1))\n",
    "        pred = np.argmin(dis, axis=0)\n",
    "        if int(feats[i, -1]) != pred:\n",
    "            change_count += 1\n",
    "            feats[i, -1] = pred\n",
    "\n",
    "    if change_count < 1:\n",
    "        break\n",
    "\n",
    "for i in range(len(train)):\n",
    "    print(pdb[i], \" Pred:\", feats[i, -1])\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. 91 - 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.91. K-meansによる減色処理 (Step.1) 色の距離によるクラス分類\n",
    "\n",
    "*imori.jpg*をK-meansを用いた減色処理せよ。\n",
    "\n",
    "減色処理はQ.6でも扱ったが、Q.6では予め決めた色に減色した。ここで扱うのはK-meansを用いて動的に減色する色を決定する。\n",
    "\n",
    "アルゴリズムは,\n",
    "1. 画像からランダムにK個のRGB成分をサンプリングする。（これをクラスと呼ぶことにする。）\n",
    "2. 画像のそれぞれの画素に対して色の距離が最小となるクラスのインデックスを割り振る。\n",
    "\n",
    "```bash\n",
    "色の距離 dis = sqrt( (R-R')^2 + (G-G')^2 + (B-B')^2)\n",
    "```\n",
    "3. 各インデックスに対応する色成分の平均をRGBそれぞれに対して取り、新たなクラスとする。\n",
    "4. 元のクラスと新しいクラスが全く同じならK-meansを終了する。そうでなければ、新しいクラスを元クラスとして2-3を繰り返す。\n",
    "5. 元画像の各画素で色の距離が最小となるクラスのRGBを割り当てる。\n",
    "\n",
    "ここでは1-2を実装せよ。\n",
    "- クラス数はk=5とする\n",
    "- ここでは画像をreshape((HxW, 3))にreshapeすると扱いやすくなる。\n",
    "- 1においてはnp.random.seed(0)として、np.random.choice(np.arrange(画像のWxH), 5, replace=False)\n",
    "- まずは3-5のループを考えずに実装せよ\n",
    "\n",
    "\n",
    "```bash\n",
    "# 最初に選ばれた色\n",
    "[[140. 121. 148.]\n",
    " [135. 109. 122.]\n",
    " [211. 189. 213.]\n",
    " [135.  86.  84.]\n",
    " [118.  99.  96.]]\n",
    "```\n",
    "\n",
    "最初に選ばれた色との色の距離でクラスのインデックスをつけたもの(アルゴリズム2)。\n",
    "解答では0-4にインデックスの値をx50にして見やすいようにしている。\n",
    "\n",
    "|入力 (imori.jpg) |出力(answer_91.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_91_100/imori.jpg)|![](./Question_91_100/answer_91.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# k-Means\n",
    "Class = 5\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "img = np.reshape(img, (H*W, -1))\n",
    "\n",
    "i = np.random.choice(np.arange(H*W), Class, replace=False)\n",
    "Cs = img[i].copy()\n",
    "\n",
    "print(Cs)\n",
    "\n",
    "clss = np.zeros((H*W), dtype=int)\n",
    "\n",
    "for i in range(H*W):\n",
    "    dis = np.sum(np.abs(Cs - img[i]), axis=1)\n",
    "    clss[i] = np.argmin(dis)\n",
    "\n",
    "\n",
    "out = np.reshape(clss, (H, W)) * 50\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.92. K-meansによる減色処理 (Step.2) 減色処理\n",
    "\n",
    "ここではアルゴリズム3-5も実装せよ。\n",
    "\n",
    "```bash\n",
    "# 選ばれた色\n",
    "[[182.86730957 156.13246155 180.24510193]\n",
    " [156.75152588 123.88993835 137.39085388]\n",
    " [227.31060791 199.93135071 209.36465454]\n",
    " [ 91.9105835   57.94448471  58.26378632]\n",
    " [121.8759613   88.4736557   96.99688721]]\n",
    "```\n",
    "\n",
    "減色処理したもの。塗り絵イラスト風な画像にできる。k=10にすればある程度の色を保持しながらもイラスト風に減色できる。\n",
    "\n",
    "また、k=5にして*madara.jpg*にも試してみよ。\n",
    "\n",
    "|入力 (imori.jpg) | 出力(answer_92.jpg) | k=10(answer_92_k10.jpg) |入力2 (madara.jpg) |出力(answer_92_m.jpg) |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|![](./Question_91_100/imori.jpg)|![](./Question_91_100/answer_92.jpg)|![](./Question_91_100/answer_92_k10.jpg)|![](./Question_91_100/madara.jpg)|![](./Question_91_100/answer_92_m.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "img = cv2.imread(\"imori.jpg\").astype(np.float32)\n",
    "H, W, C = img.shape\n",
    "\n",
    "# k-Means\n",
    "Class = 5\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "img = np.reshape(img, (H*W, -1))\n",
    "\n",
    "\n",
    "i = np.random.choice(np.arange(H*W), Class, replace=False)\n",
    "Cs = img[i].copy()\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    clss = np.zeros((H*W), dtype=int)\n",
    "    \n",
    "    for i in range(H*W):\n",
    "        dis = np.sum(np.abs(Cs - img[i]), axis=1)\n",
    "        clss[i] = np.argmin(dis)\n",
    "\n",
    "    Cs_tmp = np.zeros((Class, 3))\n",
    "    \n",
    "    for i in range(Class):\n",
    "        Cs_tmp[i] = np.mean(img[clss==i], axis=0)\n",
    "\n",
    "    if (Cs == Cs_tmp).all():\n",
    "        break\n",
    "    else:\n",
    "        Cs = Cs_tmp.copy()\n",
    "\n",
    "out = np.zeros((H*W, 3), dtype=np.float32)\n",
    "        \n",
    "for i in range(Class):\n",
    "    out[clss == i] = Cs[i]\n",
    "\n",
    "print(Cs)\n",
    "    \n",
    "out[out < 0] = 0\n",
    "out[out > 255] = 255\n",
    "out = np.reshape(out, (H, W, 3))\n",
    "out = out.astype(np.uint8)\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", out)\n",
    "cv2.imshow(\"result\", out)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.93. 機械学習の学習データの用意 (Step.1) IoUの計算\n",
    "\n",
    "ここから機械学習で用いる学習データの準備を行う。\n",
    "\n",
    "最終的にはイモリの顔か否かを判別する識別器を作りたい。そのためにはイモリの顔の画像とイモリの顔以外の画像が必要になる。それらを用意するためのプログラムを作成する。\n",
    "\n",
    "そのためにはイモリの顔周辺を一枚の画像から切り抜く必要がある。\n",
    "そこで一つの矩形を設定して(GT: Ground-truth, 正解と呼ぶ)、ランダムに切り抜いた矩形がGTとある程度重なっていれば、イモリの顔となる。\n",
    "\n",
    "その重なり具合を計算するのが、IoU: Intersection over unionであり、次式で計算される。\n",
    "\n",
    "```bash\n",
    "R1...Ground-truthの領域 , R2...切り抜いた矩形 , Rol...R1とR2の重なっている領域\n",
    "IoU = |Rol| / |R1 + R2 - Rol|\n",
    "```\n",
    "\n",
    "ここでは、以下の２つの矩形のIoUを計算せよ。\n",
    "\n",
    "```python\n",
    "# [x1, y1, x2, y2] x1,y1...矩形の左上のx,y  x2,y2...矩形の右下のx,y\n",
    "a = np.array((50, 50, 150, 150), dtype=np.float32)\n",
    "\n",
    "b = np.array((60, 60, 170, 160), dtype=np.float32)\n",
    "```\n",
    "\n",
    "答え\n",
    "\n",
    "```bash\n",
    "0.627907\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# [x1, y1, x2, y2]\n",
    "a = np.array((50, 50, 150, 150), dtype=np.float32)\n",
    "\n",
    "b = np.array((60, 60, 170, 160), dtype=np.float32)\n",
    "\n",
    "def iou(a, b):\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "    iou_w = iou_x2 - iou_x1\n",
    "    iou_h = iou_y2 - iou_y1\n",
    "    area_iou = iou_w * iou_h\n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "\n",
    "    return iou\n",
    "\n",
    "print(iou(a, b))\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.94. 機械学習の学習データの用意 (Step.2) ランダムクラッピング\n",
    "\n",
    "次に、*imori_1.jpg*からランダムに画像を切り抜いて(cropping, クラッピングと呼ぶ)学習データを作成する。\n",
    "\n",
    "ここでは画像から60x60のサイズの矩形をランダムに200個切り抜け。\n",
    "\n",
    "ただし、以下の条件を満たせ。\n",
    "1. np.random.seed(0)として、切り抜く矩形の左上のx1 = np.random.randint(W-60), y1=np.random.randint(H-60)で求めよ。\n",
    "2. GT (gt = np.array((47, 41, 129, 103), dtype=np.float32))とのIoUが0.5以上の時はその矩形に教師ラベル1, 0.5未満の場合はラベル0を与えよ。\n",
    "\n",
    "答えは、ラベル1の矩形を赤、ラベル0の矩形を青、GTを緑にしている。\n",
    "これでイモリの顔の画像、それ以外の画像を簡易的に用意できた。\n",
    "\n",
    "|入力 (imori_1.jpg) |出力(answer_94.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_91_100/imori_1.jpg)|![](./Question_91_100/answer_94.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(\"imori_1.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "gt = np.array((47, 41, 129, 103), dtype=np.float32)\n",
    "\n",
    "cv2.rectangle(img, (gt[0], gt[1]), (gt[2], gt[3]), (0,255,0), 1)\n",
    "\n",
    "def iou(a, b):\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "    iou_w = max(iou_x2 - iou_x1, 0)\n",
    "    iou_h = max(iou_y2 - iou_y1, 0)\n",
    "    area_iou = iou_w * iou_h\n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "    return iou\n",
    "\n",
    "\n",
    "# crop and create database\n",
    "Crop_num = 200\n",
    "L = 60\n",
    "\n",
    "for i in range(Crop_num):\n",
    "    x1 = np.random.randint(W-L)\n",
    "    y1 = np.random.randint(H-L)\n",
    "    x2 = x1 + L\n",
    "    y2 = y1 + L\n",
    "    crop = np.array((x1, y1, x2, y2))\n",
    "\n",
    "    _iou = iou(gt, crop)\n",
    "\n",
    "    if _iou >= 0.5:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "        label = 1\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "        label = 0\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", img)\n",
    "cv2.imshow(\"result\", img)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.95. ニューラルネットワーク (Step.1) ディープラーニングにする\n",
    "\n",
    "ここでは識別器としてニューラルネットワークを用いる。\n",
    "これは現在流行っているディープラーニングである。\n",
    "\n",
    "\n",
    "入力層、中間層(ユニット数:64)、出力層(1)のネットワークは次のようにプログラムできる。これは、排他的論理和を実現するネットワークである。プログラムに関しては https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6 を参照せよ。\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ind=2, w=64, outd=1, lr=0.1):\n",
    "        self.w2 = np.random.randn(ind, w)\n",
    "        self.b2 = np.random.randn(w)\n",
    "        self.wout = np.random.randn(w, outd)\n",
    "        self.bout = np.random.randn(outd)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = x\n",
    "        self.z2 = self.sigmoid(np.dot(self.z1, self.w2) + self.b2)\n",
    "        self.out = self.sigmoid(np.dot(self.z2, self.wout) + self.bout)\n",
    "        return self.out\n",
    "\n",
    "    def train(self, x, t):\n",
    "        # backpropagation output layer\n",
    "        out_d = 2*(self.out - t) * self.out * (1 - self.out)\n",
    "        out_dW = np.dot(self.z2.T, out_d)\n",
    "        out_dB = np.dot(np.ones([1, out_d.shape[0]]), out_d)\n",
    "        self.wout -= self.lr * out_dW\n",
    "        self.bout -= self.lr * out_dB[0]\n",
    "\n",
    "        # backpropagation inter layer\n",
    "        w2_d = np.dot(out_d, self.wout.T) * self.z2 * (1 - self.z2)\n",
    "        w2_dW = np.dot(self.z1.T, w2_d)\n",
    "        w2_dB = np.dot(np.ones([1, w2_d.shape[0]]), w2_d)\n",
    "        self.w2 -= self.lr * w2_dW\n",
    "        self.b2 -= self.lr * w2_dB[0]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "train_x = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "train_t = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "nn = NN(ind=train_x.shape[1])\n",
    "\n",
    "# train\n",
    "for i in range(1000):\n",
    "    nn.forward(train_x)\n",
    "    nn.train(train_x, train_t)\n",
    "\n",
    "# test\n",
    "for j in range(4):\n",
    "    x = train_x[j]\n",
    "    t = train_t[j]\n",
    "    print(\"in:\", x, \"pred:\", nn.forward(x))\n",
    "```\n",
    "\n",
    "ここでは、中間層(ユニット数:64)をもう一層増やし、学習・テストを行え。\n",
    "\n",
    "\n",
    "答え\n",
    "\n",
    "```bash\n",
    "in: [0. 0.] pred: [0.03724313]\n",
    "in: [0. 1.] pred: [0.95885516]\n",
    "in: [1. 0.] pred: [0.9641076]\n",
    "in: [1. 1.] pred: [0.03937037]\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ind=2, w=64, w2=64, outd=1, lr=0.1):\n",
    "        self.w2 = np.random.randn(ind, w)\n",
    "        self.b2 = np.random.randn(w)\n",
    "        self.w3 = np.random.randn(w, w2)\n",
    "        self.b3 = np.random.randn(w2)\n",
    "        self.wout = np.random.randn(w2, outd)\n",
    "        self.bout = np.random.randn(outd)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = x\n",
    "        self.z2 = self.sigmoid(np.dot(self.z1, self.w2) + self.b2)\n",
    "        self.z3 = self.sigmoid(np.dot(self.z2, self.w3) + self.b3)\n",
    "        self.out = self.sigmoid(np.dot(self.z3, self.wout) + self.bout)\n",
    "        return self.out\n",
    "\n",
    "    def train(self, x, t):\n",
    "        # backpropagation output layer\n",
    "        out_d = 2*(self.out - t) * self.out * (1 - self.out)\n",
    "        out_dW = np.dot(self.z3.T, out_d)\n",
    "        out_dB = np.dot(np.ones([1, out_d.shape[0]]), out_d)\n",
    "        self.wout -= self.lr * out_dW\n",
    "        self.bout -= self.lr * out_dB[0]\n",
    "\n",
    "        w3_d = np.dot(out_d, self.wout.T) * self.z3 * (1 - self.z3)\n",
    "        w3_dW = np.dot(self.z2.T, w3_d)\n",
    "        w3_dB = np.dot(np.ones([1, w3_d.shape[0]]), w3_d)\n",
    "        self.w3 -= self.lr * w3_dW\n",
    "        self.b3 -= self.lr * w3_dB[0]\n",
    "        \n",
    "        # backpropagation inter layer\n",
    "        w2_d = np.dot(w3_d, self.w3.T) * self.z2 * (1 - self.z2)\n",
    "        w2_dW = np.dot(self.z1.T, w2_d)\n",
    "        w2_dB = np.dot(np.ones([1, w2_d.shape[0]]), w2_d)\n",
    "        self.w2 -= self.lr * w2_dW\n",
    "        self.b2 -= self.lr * w2_dB[0]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "train_x = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "train_t = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "nn = NN(ind=train_x.shape[1])\n",
    "\n",
    "# train\n",
    "for i in range(1000):\n",
    "    nn.forward(train_x)\n",
    "    nn.train(train_x, train_t)\n",
    "\n",
    "# test\n",
    "for j in range(4):\n",
    "    x = train_x[j]\n",
    "    t = train_t[j]\n",
    "    print(\"in:\", x, \"pred:\", nn.forward(x))\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.96. ニューラルネットワーク (Step.2) 学習\n",
    "\n",
    "ここでは、Q.94で用意した学習データ200のHOG特徴量を入力として、Q.95で作成したニューラルネットを学習せよ。\n",
    "\n",
    "ここでは、学習データに対してAccuracyを計算せよ。ただし、出力(予測確率)が0.5以上で予測ラベルが1、0.5未満で予測ラベルは0としてAccuracyを計算せよ。\n",
    "学習のハイパーパラメータは、下記の通り。\n",
    "- 学習率 lr= 0.01\n",
    "- 学習回数 epch=10000\n",
    "- 切り抜いた画像を32x32にリサイズして、HOG特徴量を取得せよ。(HOGは8x8を1セルとする。)\n",
    "\n",
    "```bash\n",
    "Accuracy >> 1.0 (200.0 / 200)\n",
    "```\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(\"imori_1.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "gt = np.array((47, 41, 129, 103), dtype=np.float32)\n",
    "\n",
    "#cv2.rectangle(img, (gt[0], gt[1]), (gt[2], gt[3]), (0,255,255), 1)\n",
    "\n",
    "def iou(a, b):\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "    iou_w = max(iou_x2 - iou_x1, 0)\n",
    "    iou_h = max(iou_y2 - iou_y1, 0)\n",
    "    area_iou = iou_w * iou_h\n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def hog(gray):\n",
    "    h, w = gray.shape\n",
    "    # Magnitude and gradient\n",
    "    gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "    gx = gray[1:h+1, 2:] - gray[1:h+1, :w]\n",
    "    gy = gray[2:, 1:w+1] - gray[:h, 1:w+1]\n",
    "    gx[gx == 0] = 0.000001\n",
    "\n",
    "    mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "    gra = np.arctan(gy / gx)\n",
    "    gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "    # Gradient histogram\n",
    "    gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "    d = np.pi / 9\n",
    "    for i in range(9):\n",
    "        gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "\n",
    "    N = 8\n",
    "    HH = h // N\n",
    "    HW = w // N\n",
    "    Hist = np.zeros((HH, HW, 9), dtype=np.float32)\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            for j in range(N):\n",
    "                for i in range(N):\n",
    "                    Hist[y, x, gra_n[y*4+j, x*4+i]] += mag[y*4+j, x*4+i]\n",
    "                \n",
    "    ## Normalization\n",
    "    C = 3\n",
    "    eps = 1\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            #for i in range(9):\n",
    "            Hist[y, x] /= np.sqrt(np.sum(Hist[max(y-1,0):min(y+2, HH), max(x-1,0):min(x+2, HW)] ** 2) + eps)\n",
    "\n",
    "    return Hist\n",
    "\n",
    "def resize(img, h, w):\n",
    "    _h, _w  = img.shape\n",
    "    ah = 1. * h / _h\n",
    "    aw = 1. * w / _w\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / ah)\n",
    "    x = (x / aw)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int32)\n",
    "    iy = np.floor(y).astype(np.int32)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _h-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ind=2, w=64, w2=64, outd=1, lr=0.1):\n",
    "        self.w2 = np.random.randn(ind, w)\n",
    "        self.b2 = np.random.randn(w)\n",
    "        self.w3 = np.random.randn(w, w2)\n",
    "        self.b3 = np.random.randn(w2)\n",
    "        self.wout = np.random.randn(w2, outd)\n",
    "        self.bout = np.random.randn(outd)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = x\n",
    "        self.z2 = self.sigmoid(np.dot(self.z1, self.w2) + self.b2)\n",
    "        self.z3 = self.sigmoid(np.dot(self.z2, self.w3) + self.b3)\n",
    "        self.out = self.sigmoid(np.dot(self.z3, self.wout) + self.bout)\n",
    "        return self.out\n",
    "\n",
    "    def train(self, x, t):\n",
    "        # backpropagation output layer\n",
    "        out_d = 2*(self.out - t) * self.out * (1 - self.out)\n",
    "        out_dW = np.dot(self.z3.T, out_d)\n",
    "        out_dB = np.dot(np.ones([1, out_d.shape[0]]), out_d)\n",
    "        self.wout -= self.lr * out_dW\n",
    "        self.bout -= self.lr * out_dB[0]\n",
    "\n",
    "        w3_d = np.dot(out_d, self.wout.T) * self.z3 * (1 - self.z3)\n",
    "        w3_dW = np.dot(self.z2.T, w3_d)\n",
    "        w3_dB = np.dot(np.ones([1, w3_d.shape[0]]), w3_d)\n",
    "        self.w3 -= self.lr * w3_dW\n",
    "        self.b3 -= self.lr * w3_dB[0]\n",
    "        \n",
    "        # backpropagation inter layer\n",
    "        w2_d = np.dot(w3_d, self.w3.T) * self.z2 * (1 - self.z2)\n",
    "        w2_dW = np.dot(self.z1.T, w2_d)\n",
    "        w2_dB = np.dot(np.ones([1, w2_d.shape[0]]), w2_d)\n",
    "        self.w2 -= self.lr * w2_dW\n",
    "        self.b2 -= self.lr * w2_dB[0]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "# crop and create database\n",
    "\n",
    "Crop_num = 200\n",
    "L = 60\n",
    "H_size = 32\n",
    "F_n = ((H_size // 8) ** 2) * 9\n",
    "\n",
    "db = np.zeros((Crop_num, F_n+1))\n",
    "\n",
    "for i in range(Crop_num):\n",
    "    x1 = np.random.randint(W-L)\n",
    "    y1 = np.random.randint(H-L)\n",
    "    x2 = x1 + L\n",
    "    y2 = y1 + L\n",
    "    crop = np.array((x1, y1, x2, y2))\n",
    "\n",
    "    _iou = np.zeros((3,))\n",
    "    _iou[0] = iou(gt, crop)\n",
    "    #_iou[1] = iou(gt2, crop)\n",
    "    #_iou[2] = iou(gt3, crop)\n",
    "\n",
    "    if _iou.max() >= 0.5:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "        label = 1\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "        label = 0\n",
    "\n",
    "    crop_area = gray[y1:y2, x1:x2]\n",
    "    crop_area = resize(crop_area, H_size, H_size)\n",
    "    _hog = hog(crop_area)\n",
    "    \n",
    "    db[i, :F_n] = _hog.ravel()\n",
    "    db[i, -1] = label\n",
    "\n",
    "# train neural network\n",
    "nn = NN(ind=F_n, lr=0.01)\n",
    "for i in range(10000):\n",
    "    nn.forward(db[:, :F_n])\n",
    "    nn.train(db[:, :F_n], db[:, -1][..., None])\n",
    "\n",
    "# test\n",
    "success_pred = 0.\n",
    "for data in db:\n",
    "    t = data[-1]\n",
    "    prob = nn.forward(data[:F_n])\n",
    "    pred = 1 if prob >= 0.5 else 0\n",
    "    if t == pred:\n",
    "        success_pred += 1\n",
    "\n",
    "accuracy = success_pred / len(db)\n",
    "\n",
    "print(\"Accuracy >> {} ({} / {})\".format(accuracy, success_pred, len(db)))\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.97. 簡単な物体検出 (Step.1) スライディングウィンドウ + HOG\n",
    "\n",
    "ここから物体検出を行う。\n",
    "\n",
    "物体検出とは、画像中でどこに何が写っているかを出力するタスクである。\n",
    "例えば、画像の[x1, y1, x2, y2]の位置に犬がいるなど。\n",
    "このような物体を囲む矩形のことをBounding-box(バウンディングボックス)と呼ぶ。\n",
    "\n",
    "ここでは簡単な物体検出のアルゴリズムを作成する。\n",
    "\n",
    "1. 画像の左上からスライディングウィンドウを行う。\n",
    "2. 各画像の位置について、注目位置を中心に複数の矩形を用意する。\n",
    "3. それぞれの矩形に対応する画像を切り抜いて、特徴抽出(HOG, SIFTなど)を行う。\n",
    "4. 識別機(CNN, SVMなど)に掛けて各矩形が物体か否かを判別する。\n",
    "\n",
    "これである程度の物体と矩形の座標が得られる。現在は物体検出はディープラーニングによる手法(Faster R-CNN, YOLO, SSDなど)が主流であるが、ディープラーニングが流行る前まではこのようなスライディングウィンドウの手法が主流であった。今回は検出の基礎を学ぶため、スライディングウィンドウを扱う。\n",
    "\n",
    "ここでは1-3を実装する。\n",
    "\n",
    "*imori_many.jpg*に対してイモリの顔検出を行う。\n",
    "条件は以下。\n",
    "- 矩形は下記のものを用いる。\n",
    "```python\n",
    "# [h, w]\n",
    "recs = np.array(((42, 42), (56, 56), (70, 70)), dtype=np.float32)\n",
    "```\n",
    "- スライドは4ピクセルおきに行う。(1ピクセルでもいいが、計算が多くなって処理が長くなってしまう。)\n",
    "- 矩形が画像サイズをはみ出る場合は、はみ出ないように変形する。\n",
    "- 矩形部分を切り抜いたら、その部分を32x32にリサイズする。\n",
    "- HOG特徴量の取得は8x8を1セルとする。\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(\"imori_1.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "gt = np.array((47, 41, 129, 103), dtype=np.float32)\n",
    "\n",
    "cv2.rectangle(img, (gt[0], gt[1]), (gt[2], gt[3]), (0,255,255), 1)\n",
    "\n",
    "\n",
    "def iou(a, b):\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "    iou_w = max(iou_x2 - iou_x1, 0)\n",
    "    iou_h = max(iou_y2 - iou_y1, 0)\n",
    "    area_iou = iou_w * iou_h\n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def hog(gray):\n",
    "    h, w = gray.shape\n",
    "    # Magnitude and gradient\n",
    "    gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "    gx = gray[1:h+1, 2:] - gray[1:h+1, :w]\n",
    "    gy = gray[2:, 1:w+1] - gray[:h, 1:w+1]\n",
    "    gx[gx == 0] = 0.000001\n",
    "\n",
    "    mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "    gra = np.arctan(gy / gx)\n",
    "    gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "    # Gradient histogram\n",
    "    gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "    d = np.pi / 9\n",
    "    for i in range(9):\n",
    "        gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "\n",
    "    N = 8\n",
    "    HH = h // N\n",
    "    HW = w // N\n",
    "    Hist = np.zeros((HH, HW, 9), dtype=np.float32)\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            for j in range(N):\n",
    "                for i in range(N):\n",
    "                    Hist[y, x, gra_n[y*4+j, x*4+i]] += mag[y*4+j, x*4+i]\n",
    "                \n",
    "    ## Normalization\n",
    "    C = 3\n",
    "    eps = 1\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            #for i in range(9):\n",
    "            Hist[y, x] /= np.sqrt(np.sum(Hist[max(y-1,0):min(y+2, HH), max(x-1,0):min(x+2, HW)] ** 2) + eps)\n",
    "\n",
    "    return Hist\n",
    "\n",
    "def resize(img, h, w):\n",
    "    _h, _w  = img.shape\n",
    "    ah = 1. * h / _h\n",
    "    aw = 1. * w / _w\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / ah)\n",
    "    x = (x / aw)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int32)\n",
    "    iy = np.floor(y).astype(np.int32)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _h-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "# read detect target image\n",
    "img2 = cv2.imread(\"imori_many.jpg\")\n",
    "H2, W2, C2 = img2.shape\n",
    "\n",
    "# Resize size\n",
    "H_size = 32\n",
    "# HOG Feature vector size\n",
    "F_n = ((H_size // 8) ** 2) * 9\n",
    "\n",
    "# Grayscale\n",
    "gray2 = 0.2126 * img2[..., 2] + 0.7152 * img2[..., 1] + 0.0722 * img2[..., 0]\n",
    "\n",
    "# [h, w]\n",
    "recs = np.array(((42, 42), (56, 56), (70, 70)), dtype=np.float32)\n",
    "\n",
    "\n",
    "# sliding window\n",
    "for y in range(0, H2, 4):\n",
    "    for x in range(0, W2, 4):\n",
    "        for rec in recs:\n",
    "            dh = int(rec[0] // 2)\n",
    "            dw = int(rec[1] // 2)\n",
    "            x1 = max(x-dw, 0)\n",
    "            x2 = min(x+dw, W2)\n",
    "            y1 = max(y-dh, 0)\n",
    "            y2 = min(y+dh, H2)\n",
    "            region = gray2[max(y-dh,0):min(y+dh,H2), max(x-dw,0):min(x+dw,W2)]\n",
    "            region = resize(region, H_size, H_size)\n",
    "            region_hog = hog(region).ravel()\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.98. 簡単な物体検出 (Step.2) スライディングウィンドウ + NN\n",
    "\n",
    "*imori_many.jpg*に対して、ここではQ.97で求めた各矩形のHOG特徴量を入力として、Q.96で学習したニューラルネットでイモリの顔か否かを識別せよ。\n",
    "\n",
    "ここでスコア(予測確率)が0.7以上の矩形を描画せよ。\n",
    "\n",
    "答え\n",
    "検出された矩形 [x1, y1, x2, y2, score]\n",
    "\n",
    "```bash\n",
    "[[ 27.           0.          69.          21.           0.74268049]\n",
    "[ 31.           0.          73.          21.           0.89631011]\n",
    "[ 52.           0.         108.          36.           0.84373157]\n",
    "[165.           0.         235.          43.           0.73741703]\n",
    "[ 55.           0.          97.          33.           0.70987278]\n",
    "[165.           0.         235.          47.           0.92333214]\n",
    "[169.           0.         239.          47.           0.84030839]\n",
    "[ 51.           0.          93.          37.           0.84301022]\n",
    "[168.           0.         224.          44.           0.79237294]\n",
    "[165.           0.         235.          51.           0.86038564]\n",
    "[ 51.           0.          93.          41.           0.85151915]\n",
    "[ 48.           0.         104.          56.           0.73268318]\n",
    "[168.           0.         224.          56.           0.86675902]\n",
    "[ 43.          15.          85.          57.           0.93562483]\n",
    "[ 13.          37.          83.         107.           0.77192307]\n",
    "[180.          44.         236.         100.           0.82054873]\n",
    "[173.          37.         243.         107.           0.8478805 ]\n",
    "[177.          37.         247.         107.           0.87183443]\n",
    "[ 24.          68.          80.         124.           0.7279032 ]\n",
    "[103.          75.         145.         117.           0.73725153]\n",
    "[104.          68.         160.         124.           0.71314282]\n",
    "[ 96.          72.         152.         128.           0.86269195]\n",
    "[100.          72.         156.         128.           0.98826957]\n",
    "[ 25.          69.          95.         139.           0.73449174]\n",
    "[100.          76.         156.         132.           0.74963093]\n",
    "[104.          76.         160.         132.           0.96620193]\n",
    "[ 75.          91.         117.         133.           0.80533424]\n",
    "[ 97.          77.         167.         144.           0.7852362 ]\n",
    "[ 97.          81.         167.         144.           0.70371708]]\n",
    "```\n",
    "\n",
    "|入力 (imori_many.jpg) |出力(answer_98.jpg)|\n",
    "|:---:|:---:|\n",
    "|![](./Question_91_100/imori_many.jpg)|![](./Question_91_100/answer_98.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(\"imori_1.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "gt = np.array((47, 41, 129, 103), dtype=np.float32)\n",
    "\n",
    "cv2.rectangle(img, (gt[0], gt[1]), (gt[2], gt[3]), (0,255,255), 1)\n",
    "\n",
    "def iou(a, b):\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "    iou_w = max(iou_x2 - iou_x1, 0)\n",
    "    iou_h = max(iou_y2 - iou_y1, 0)\n",
    "    area_iou = iou_w * iou_h\n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def hog(gray):\n",
    "    h, w = gray.shape\n",
    "    # Magnitude and gradient\n",
    "    gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "    gx = gray[1:h+1, 2:] - gray[1:h+1, :w]\n",
    "    gy = gray[2:, 1:w+1] - gray[:h, 1:w+1]\n",
    "    gx[gx == 0] = 0.000001\n",
    "\n",
    "    mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "    gra = np.arctan(gy / gx)\n",
    "    gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "    # Gradient histogram\n",
    "    gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "    d = np.pi / 9\n",
    "    for i in range(9):\n",
    "        gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "\n",
    "    N = 8\n",
    "    HH = h // N\n",
    "    HW = w // N\n",
    "    Hist = np.zeros((HH, HW, 9), dtype=np.float32)\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            for j in range(N):\n",
    "                for i in range(N):\n",
    "                    Hist[y, x, gra_n[y*4+j, x*4+i]] += mag[y*4+j, x*4+i]\n",
    "                \n",
    "    ## Normalization\n",
    "    C = 3\n",
    "    eps = 1\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            #for i in range(9):\n",
    "            Hist[y, x] /= np.sqrt(np.sum(Hist[max(y-1,0):min(y+2, HH), max(x-1,0):min(x+2, HW)] ** 2) + eps)\n",
    "\n",
    "    return Hist\n",
    "\n",
    "def resize(img, h, w):\n",
    "    _h, _w  = img.shape\n",
    "    ah = 1. * h / _h\n",
    "    aw = 1. * w / _w\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / ah)\n",
    "    x = (x / aw)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int32)\n",
    "    iy = np.floor(y).astype(np.int32)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _h-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ind=2, w=64, w2=64, outd=1, lr=0.1):\n",
    "        self.w2 = np.random.randn(ind, w)\n",
    "        self.b2 = np.random.randn(w)\n",
    "        self.w3 = np.random.randn(w, w2)\n",
    "        self.b3 = np.random.randn(w2)\n",
    "        self.wout = np.random.randn(w2, outd)\n",
    "        self.bout = np.random.randn(outd)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = x\n",
    "        self.z2 = self.sigmoid(np.dot(self.z1, self.w2) + self.b2)\n",
    "        self.z3 = self.sigmoid(np.dot(self.z2, self.w3) + self.b3)\n",
    "        self.out = self.sigmoid(np.dot(self.z3, self.wout) + self.bout)\n",
    "        return self.out\n",
    "\n",
    "    def train(self, x, t):\n",
    "        # backpropagation output layer\n",
    "        out_d = 2*(self.out - t) * self.out * (1 - self.out)\n",
    "        out_dW = np.dot(self.z3.T, out_d)\n",
    "        out_dB = np.dot(np.ones([1, out_d.shape[0]]), out_d)\n",
    "        self.wout -= self.lr * out_dW\n",
    "        self.bout -= self.lr * out_dB[0]\n",
    "\n",
    "        w3_d = np.dot(out_d, self.wout.T) * self.z3 * (1 - self.z3)\n",
    "        w3_dW = np.dot(self.z2.T, w3_d)\n",
    "        w3_dB = np.dot(np.ones([1, w3_d.shape[0]]), w3_d)\n",
    "        self.w3 -= self.lr * w3_dW\n",
    "        self.b3 -= self.lr * w3_dB[0]\n",
    "        \n",
    "        # backpropagation inter layer\n",
    "        w2_d = np.dot(w3_d, self.w3.T) * self.z2 * (1 - self.z2)\n",
    "        w2_dW = np.dot(self.z1.T, w2_d)\n",
    "        w2_dB = np.dot(np.ones([1, w2_d.shape[0]]), w2_d)\n",
    "        self.w2 -= self.lr * w2_dW\n",
    "        self.b2 -= self.lr * w2_dB[0]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "# crop and create database\n",
    "\n",
    "Crop_num = 200\n",
    "L = 60\n",
    "H_size = 32\n",
    "F_n = ((H_size // 8) ** 2) * 9\n",
    "\n",
    "db = np.zeros((Crop_num, F_n+1))\n",
    "\n",
    "for i in range(Crop_num):\n",
    "    x1 = np.random.randint(W-L)\n",
    "    y1 = np.random.randint(H-L)\n",
    "    x2 = x1 + L\n",
    "    y2 = y1 + L\n",
    "    crop = np.array((x1, y1, x2, y2))\n",
    "\n",
    "    _iou = iou(gt, crop)\n",
    "\n",
    "    if _iou >= 0.5:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "        label = 1\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "        label = 0\n",
    "\n",
    "    crop_area = gray[y1:y2, x1:x2]\n",
    "    crop_area = resize(crop_area, H_size, H_size)\n",
    "    _hog = hog(crop_area)\n",
    "    \n",
    "    db[i, :F_n] = _hog.ravel()\n",
    "    db[i, -1] = label\n",
    "\n",
    "## train neural network\n",
    "nn = NN(ind=F_n, lr=0.01)\n",
    "for i in range(10000):\n",
    "    nn.forward(db[:, :F_n])\n",
    "    nn.train(db[:, :F_n], db[:, -1][..., None])\n",
    "\n",
    "\n",
    "# read detect target image\n",
    "img2 = cv2.imread(\"imori_many.jpg\")\n",
    "H2, W2, C2 = img2.shape\n",
    "\n",
    "# Grayscale\n",
    "gray2 = 0.2126 * img2[..., 2] + 0.7152 * img2[..., 1] + 0.0722 * img2[..., 0]\n",
    "\n",
    "# [h, w]\n",
    "recs = np.array(((42, 42), (56, 56), (70, 70)), dtype=np.float32)\n",
    "\n",
    "detects = np.ndarray((0, 5), dtype=np.float32)\n",
    "\n",
    "# sliding window\n",
    "for y in range(0, H2, 4):\n",
    "    for x in range(0, W2, 4):\n",
    "        for rec in recs:\n",
    "            dh = int(rec[0] // 2)\n",
    "            dw = int(rec[1] // 2)\n",
    "            x1 = max(x-dw, 0)\n",
    "            x2 = min(x+dw, W2)\n",
    "            y1 = max(y-dh, 0)\n",
    "            y2 = min(y+dh, H2)\n",
    "            region = gray2[max(y-dh,0):min(y+dh,H2), max(x-dw,0):min(x+dw,W2)]\n",
    "            region = resize(region, H_size, H_size)\n",
    "            region_hog = hog(region).ravel()\n",
    "\n",
    "            score = nn.forward(region_hog)\n",
    "            if score >= 0.7:\n",
    "                cv2.rectangle(img2, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "                detects = np.vstack((detects, np.array((x1, y1, x2, y2, score))))\n",
    "\n",
    "print(detects)\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", img2)\n",
    "cv2.imshow(\"result\", img2)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.99. 簡単な物体検出 (Step.3) Non-Maximum Suppression\n",
    "\n",
    "Q.97であらかたの検出はできたが、このままではBrounding-boxの数が多すぎて、ここから何かしらの処理に繋げるには不便である。\n",
    "そこで、NMS: Non-maximum suppressionという手法を用いて矩形の数を減らす。\n",
    "\n",
    "NMSとはスコアの高いBounding-boxのみを残す手法であり、アルゴリズムは以下の通り。\n",
    "\n",
    "1. Boundinb-boxの集合Bをスコアが高い順にソートする。\n",
    "2. スコアが最大のものをb0とする。\n",
    "3. b0と他のBounding-boxのIoUを計算する。IoUが閾値t以上のBounding-boxをBから削除する。B0は出力する集合Rに加え、Bから削除する。\n",
    "4. 2-3をBがなくなるまで行う。\n",
    "5. Rを出力する。\n",
    "\n",
    "Q.98にNMS(閾値t=0.25)を組み込み、出力を描画せよ。\n",
    "解答では検出の左上にスコアも加えている。\n",
    "\n",
    "精度はともあれ、これで検出の一連の流れが完了した。\n",
    "ニューラルネットの学習を増やしたりすることで、検出の精度は更に向上ができる。\n",
    "\n",
    "|入力 (imori_many.jpg) |NMS前(answer_98.jpg)|NMS後(answer_99.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_91_100/imori_many.jpg)|![](./Question_91_100/answer_98.jpg)|![](./Question_91_100/answer_99.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(\"imori_1.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "gt = np.array((47, 41, 129, 103), dtype=np.float32)\n",
    "\n",
    "cv2.rectangle(img, (gt[0], gt[1]), (gt[2], gt[3]), (0,255,255), 1)\n",
    "\n",
    "def iou(a, b):\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "    iou_w = max(iou_x2 - iou_x1, 0)\n",
    "    iou_h = max(iou_y2 - iou_y1, 0)\n",
    "    area_iou = iou_w * iou_h\n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def hog(gray):\n",
    "    h, w = gray.shape\n",
    "    # Magnitude and gradient\n",
    "    gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "    gx = gray[1:h+1, 2:] - gray[1:h+1, :w]\n",
    "    gy = gray[2:, 1:w+1] - gray[:h, 1:w+1]\n",
    "    gx[gx == 0] = 0.000001\n",
    "\n",
    "    mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "    gra = np.arctan(gy / gx)\n",
    "    gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "    # Gradient histogram\n",
    "    gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "    d = np.pi / 9\n",
    "    for i in range(9):\n",
    "        gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "\n",
    "    N = 8\n",
    "    HH = h // N\n",
    "    HW = w // N\n",
    "    Hist = np.zeros((HH, HW, 9), dtype=np.float32)\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            for j in range(N):\n",
    "                for i in range(N):\n",
    "                    Hist[y, x, gra_n[y*4+j, x*4+i]] += mag[y*4+j, x*4+i]\n",
    "                \n",
    "    ## Normalization\n",
    "    C = 3\n",
    "    eps = 1\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            #for i in range(9):\n",
    "            Hist[y, x] /= np.sqrt(np.sum(Hist[max(y-1,0):min(y+2, HH), max(x-1,0):min(x+2, HW)] ** 2) + eps)\n",
    "\n",
    "    return Hist\n",
    "\n",
    "def resize(img, h, w):\n",
    "    _h, _w  = img.shape\n",
    "    ah = 1. * h / _h\n",
    "    aw = 1. * w / _w\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / ah)\n",
    "    x = (x / aw)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int32)\n",
    "    iy = np.floor(y).astype(np.int32)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _h-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ind=2, w=64, w2=64, outd=1, lr=0.1):\n",
    "        self.w2 = np.random.randn(ind, w)\n",
    "        self.b2 = np.random.randn(w)\n",
    "        self.w3 = np.random.randn(w, w2)\n",
    "        self.b3 = np.random.randn(w2)\n",
    "        self.wout = np.random.randn(w2, outd)\n",
    "        self.bout = np.random.randn(outd)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = x\n",
    "        self.z2 = self.sigmoid(np.dot(self.z1, self.w2) + self.b2)\n",
    "        self.z3 = self.sigmoid(np.dot(self.z2, self.w3) + self.b3)\n",
    "        self.out = self.sigmoid(np.dot(self.z3, self.wout) + self.bout)\n",
    "        return self.out\n",
    "\n",
    "    def train(self, x, t):\n",
    "        # backpropagation output layer\n",
    "        out_d = 2*(self.out - t) * self.out * (1 - self.out)\n",
    "        out_dW = np.dot(self.z3.T, out_d)\n",
    "        out_dB = np.dot(np.ones([1, out_d.shape[0]]), out_d)\n",
    "        self.wout -= self.lr * out_dW\n",
    "        self.bout -= self.lr * out_dB[0]\n",
    "\n",
    "        w3_d = np.dot(out_d, self.wout.T) * self.z3 * (1 - self.z3)\n",
    "        w3_dW = np.dot(self.z2.T, w3_d)\n",
    "        w3_dB = np.dot(np.ones([1, w3_d.shape[0]]), w3_d)\n",
    "        self.w3 -= self.lr * w3_dW\n",
    "        self.b3 -= self.lr * w3_dB[0]\n",
    "        \n",
    "        # backpropagation inter layer\n",
    "        w2_d = np.dot(w3_d, self.w3.T) * self.z2 * (1 - self.z2)\n",
    "        w2_dW = np.dot(self.z1.T, w2_d)\n",
    "        w2_dB = np.dot(np.ones([1, w2_d.shape[0]]), w2_d)\n",
    "        self.w2 -= self.lr * w2_dW\n",
    "        self.b2 -= self.lr * w2_dB[0]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "# crop and create database\n",
    "\n",
    "Crop_num = 200\n",
    "L = 60\n",
    "H_size = 32\n",
    "F_n = ((H_size // 8) ** 2) * 9\n",
    "\n",
    "db = np.zeros((Crop_num, F_n+1))\n",
    "\n",
    "for i in range(Crop_num):\n",
    "    x1 = np.random.randint(W-L)\n",
    "    y1 = np.random.randint(H-L)\n",
    "    x2 = x1 + L\n",
    "    y2 = y1 + L\n",
    "    crop = np.array((x1, y1, x2, y2))\n",
    "\n",
    "    _iou = iou(gt, crop)\n",
    "\n",
    "    if _iou >= 0.5:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "        label = 1\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "        label = 0\n",
    "\n",
    "    crop_area = gray[y1:y2, x1:x2]\n",
    "    crop_area = resize(crop_area, H_size, H_size)\n",
    "    _hog = hog(crop_area)\n",
    "    \n",
    "    db[i, :F_n] = _hog.ravel()\n",
    "    db[i, -1] = label\n",
    "\n",
    "\n",
    "## training neural network\n",
    "nn = NN(ind=F_n, lr=0.01)\n",
    "for i in range(10000):\n",
    "    nn.forward(db[:, :F_n])\n",
    "    nn.train(db[:, :F_n], db[:, -1][..., None])\n",
    "\n",
    "\n",
    "# read detect target image\n",
    "img2 = cv2.imread(\"imori_many.jpg\")\n",
    "H2, W2, C2 = img2.shape\n",
    "\n",
    "# Grayscale\n",
    "gray2 = 0.2126 * img2[..., 2] + 0.7152 * img2[..., 1] + 0.0722 * img2[..., 0]\n",
    "\n",
    "# [h, w]\n",
    "recs = np.array(((42, 42), (56, 56), (70, 70)), dtype=np.float32)\n",
    "\n",
    "detects = np.ndarray((0, 5), dtype=np.float32)\n",
    "\n",
    "# sliding window\n",
    "for y in range(0, H2, 4):\n",
    "    for x in range(0, W2, 4):\n",
    "        for rec in recs:\n",
    "            dh = int(rec[0] // 2)\n",
    "            dw = int(rec[1] // 2)\n",
    "            x1 = max(x-dw, 0)\n",
    "            x2 = min(x+dw, W2)\n",
    "            y1 = max(y-dh, 0)\n",
    "            y2 = min(y+dh, H2)\n",
    "            region = gray2[max(y-dh,0):min(y+dh,H2), max(x-dw,0):min(x+dw,W2)]\n",
    "            region = resize(region, H_size, H_size)\n",
    "            region_hog = hog(region).ravel()\n",
    "\n",
    "            score = nn.forward(region_hog)\n",
    "            if score >= 0.7:\n",
    "                #cv2.rectangle(img2, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "                detects = np.vstack((detects, np.array((x1, y1, x2, y2, score))))\n",
    "\n",
    "\n",
    "# Non-maximum suppression\n",
    "def nms(_bboxes, iou_th=0.5, select_num=None, prob_th=None):\n",
    "    #\n",
    "    # Non Maximum Suppression\n",
    "    #\n",
    "    # Argument\n",
    "    #  bboxes(Nx5) ... [bbox-num, 5(leftTopX,leftTopY,w,h, score)]\n",
    "    #  iou_th([float]) ... threshold for iou between bboxes.\n",
    "    #  select_num([int]) ... max number for choice bboxes. If None, this is unvalid.\n",
    "    #  prob_th([float]) ... probability threshold to choice. If None, this is unvalid.\n",
    "    # Return\n",
    "    #  inds ... choced indices for bboxes\n",
    "    #\n",
    "\n",
    "    bboxes = _bboxes.copy()\n",
    "    \n",
    "    bboxes[:, 2] = bboxes[:, 2] - bboxes[:, 0]\n",
    "    bboxes[:, 3] = bboxes[:, 3] - bboxes[:, 1]\n",
    "    \n",
    "    # Sort by bbox's score. High -> Low\n",
    "    sort_inds = np.argsort(bboxes[:, -1])[::-1]\n",
    "\n",
    "    processed_bbox_ind = []\n",
    "    return_inds = []\n",
    "\n",
    "    unselected_inds = sort_inds.copy()\n",
    "    \n",
    "    while len(unselected_inds) > 0:\n",
    "        process_bboxes = bboxes[unselected_inds]\n",
    "        argmax_score_ind = np.argmax(process_bboxes[::, -1])\n",
    "        max_score_ind = unselected_inds[argmax_score_ind]\n",
    "        return_inds += [max_score_ind]\n",
    "        unselected_inds = np.delete(unselected_inds, argmax_score_ind)\n",
    "\n",
    "        base_bbox = bboxes[max_score_ind]\n",
    "        compare_bboxes = bboxes[unselected_inds]\n",
    "        \n",
    "        base_x1 = base_bbox[0]\n",
    "        base_y1 = base_bbox[1]\n",
    "        base_x2 = base_bbox[2] + base_x1\n",
    "        base_y2 = base_bbox[3] + base_y1\n",
    "        base_w = np.maximum(base_bbox[2], 0)\n",
    "        base_h = np.maximum(base_bbox[3], 0)\n",
    "        base_area = base_w * base_h\n",
    "\n",
    "        # compute iou-area between base bbox and other bboxes\n",
    "        iou_x1 = np.maximum(base_x1, compare_bboxes[:, 0])\n",
    "        iou_y1 = np.maximum(base_y1, compare_bboxes[:, 1])\n",
    "        iou_x2 = np.minimum(base_x2, compare_bboxes[:, 2] + compare_bboxes[:, 0])\n",
    "        iou_y2 = np.minimum(base_y2, compare_bboxes[:, 3] + compare_bboxes[:, 1])\n",
    "        iou_w = np.maximum(iou_x2 - iou_x1, 0)\n",
    "        iou_h = np.maximum(iou_y2 - iou_y1, 0)\n",
    "        iou_area = iou_w * iou_h\n",
    "\n",
    "        compare_w = np.maximum(compare_bboxes[:, 2], 0)\n",
    "        compare_h = np.maximum(compare_bboxes[:, 3], 0)\n",
    "        compare_area = compare_w * compare_h\n",
    "\n",
    "        # bbox's index which iou ratio over threshold is excluded\n",
    "        all_area = compare_area + base_area - iou_area\n",
    "        iou_ratio = np.zeros((len(unselected_inds)))\n",
    "        iou_ratio[all_area < 0.9] = 0.\n",
    "        _ind = all_area >= 0.9\n",
    "        iou_ratio[_ind] = iou_area[_ind] / all_area[_ind]\n",
    "        \n",
    "        unselected_inds = np.delete(unselected_inds, np.where(iou_ratio >= iou_th)[0])\n",
    "\n",
    "    if prob_th is not None:\n",
    "        preds = bboxes[return_inds][:, -1]\n",
    "        return_inds = np.array(return_inds)[np.where(preds >= prob_th)[0]].tolist()\n",
    "        \n",
    "    # pick bbox's index by defined number with higher score\n",
    "    if select_num is not None:\n",
    "        return_inds = return_inds[:select_num]\n",
    "\n",
    "    return return_inds\n",
    "\n",
    "\n",
    "detects = detects[nms(detects, iou_th=0.25)]\n",
    "\n",
    "for d in detects:\n",
    "    v = list(map(int, d[:4]))\n",
    "    cv2.rectangle(img2, (v[0], v[1]), (v[2], v[3]), (0,0,255), 1)\n",
    "    cv2.putText(img2, \"{:.2f}\".format(d[-1]), (v[0], v[1]+9),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,0,255), 1)\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", img2)\n",
    "cv2.imshow(\"result\", img2)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.100. 簡単な物体検出 (Step.4) 評価 Precision, Recall, F-score, mAP\n",
    "\n",
    "ついに100問目！！！\n",
    "\n",
    "ここでは検出の評価指標を実装する。\n",
    "\n",
    "検出はBounding-boxとそのクラスの２つが一致していないと、精度の評価ができない。\n",
    "検出の評価指標には、Recal, Precision, F-score, mAPなどが存在する。\n",
    "\n",
    "### Recall ... 正解の矩形がどれだけ検出できたか。正解をどれだけ網羅できたかを示す。[0,1]の範囲を取り、1が最高。\n",
    "\n",
    "```bash\n",
    "G' ... Ground-truthの中で検出のどれかとIoUが閾値t以上となったGround-truthの数。\n",
    "G ... Ground-truthの矩形の数。\n",
    "Recall = G' / G\n",
    "```\n",
    "### Precision ... 検出がどれだけ正確に行われたかを示す。[0,1]の範囲を取り、1が最高。\n",
    "\n",
    "```bash\n",
    "D' ... 検出の中で、Ground-truthのどれかとIoUが閾値t以上となった検出の数。\n",
    "D ... 検出の数。\n",
    "Precision = D' / D\n",
    "```\n",
    "\n",
    "### F-score ... RecallとPrecisonの調和平均。　２つのバランスを示すもので、[0,1]の範囲を取り、1が最高。\n",
    "\n",
    "```bash\n",
    "F-scoer = 2 * Recall * Precision / (Recall + Precision)\n",
    "```\n",
    "\n",
    "文字を検出する文字検出はRecall, Precision, F-scoreで精度を測ることが多い。\n",
    "\n",
    "### mAP ... Mean Average Precision。物体を検出する物体検出では、mAPで測ることが多い。mAPの計算方法は少し複雑である。\n",
    "\n",
    "1. 各検出に関してGround-truthとのIoUが閾値t以上かどうかを判断して、表を作成する。\n",
    "```bash\n",
    "   Detect | judge\n",
    "------------------\n",
    "  detect1 |   1   (1はGround-truthとのIoU>=tとなったもの)\n",
    "  detect2 |   0   (0はGround-truthとのIoU<tとなったもの)\n",
    "  detect3 |   1\n",
    "```\n",
    "2. mAP = 0として、上から順に見て、judgeが1の時は、見ているものの上すべてに関して、Precisionを計算し、mAPに加算する。\n",
    "3. 上から順に2を行い、全て行ったら、加算回数でmAPを割る。\n",
    "\n",
    "以上でmAPが求まる。上の例でいうと、\n",
    "1. detect1 が1なので、Precisionを求める。Precision = 1/1 = 1なので、mAP = 1\n",
    "2. detect2 が0なので、無視。\n",
    "3. detect3 が1なので、Precisionを求める。Precision = 2/3 = 0.67 なので、 mAP = 1 + 0.67 = 1.67\n",
    "4. mAPに加算したのは計2回なので、mAP = 1.67 / 2 = 0.835\n",
    "となる。\n",
    "\n",
    "\n",
    "ここでは、閾値t=0.5として、Recall, Precision, F-score, mAPを算出せよ。\n",
    "Ground-truthは次とする。\n",
    "```python\n",
    "# [x1, y1, x2, y2]\n",
    "GT = np.array(((27, 48, 95, 110), (101, 75, 171, 138)), dtype=np.float32)\n",
    "```\n",
    "\n",
    "ここでは、GTとのIoUが0.5以上の検出を赤、それ以外を青にして描画せよ。\n",
    "\n",
    "解答\n",
    "```bash\n",
    "Recall >> 1.00 (2.0 / 2)\n",
    "Precision >> 0.25 (2.0 / 8)\n",
    "F-score >>  0.4\n",
    "mAP >> 0.0625\n",
    "```\n",
    "\n",
    "|入力 (imori_many.jpg) |GT(answer_100_gt.jpg)|出力(answer_100.jpg)|\n",
    "|:---:|:---:|:---:|\n",
    "|![](./Question_91_100/imori_many.jpg)|![](./Question_91_100/answer_100_gt.jpg)|![](./Question_91_100/answer_100.jpg)|\n",
    "\n",
    "<details><summary>答え(クリックで展開)</summary><div>\n",
    "    \n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(\"imori_1.jpg\")\n",
    "H, W, C = img.shape\n",
    "\n",
    "# Grayscale\n",
    "gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "\n",
    "gt = np.array((47, 41, 129, 103), dtype=np.float32)\n",
    "\n",
    "cv2.rectangle(img, (gt[0], gt[1]), (gt[2], gt[3]), (0,255,255), 1)\n",
    "\n",
    "def iou(a, b):\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "    iou_w = max(iou_x2 - iou_x1, 0)\n",
    "    iou_h = max(iou_y2 - iou_y1, 0)\n",
    "    area_iou = iou_w * iou_h\n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def hog(gray):\n",
    "    h, w = gray.shape\n",
    "    # Magnitude and gradient\n",
    "    gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "    gx = gray[1:h+1, 2:] - gray[1:h+1, :w]\n",
    "    gy = gray[2:, 1:w+1] - gray[:h, 1:w+1]\n",
    "    gx[gx == 0] = 0.000001\n",
    "\n",
    "    mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "    gra = np.arctan(gy / gx)\n",
    "    gra[gra<0] = np.pi / 2 + gra[gra < 0] + np.pi / 2\n",
    "\n",
    "    # Gradient histogram\n",
    "    gra_n = np.zeros_like(gra, dtype=np.int)\n",
    "\n",
    "    d = np.pi / 9\n",
    "    for i in range(9):\n",
    "        gra_n[np.where((gra >= d * i) & (gra <= d * (i+1)))] = i\n",
    "\n",
    "    N = 8\n",
    "    HH = h // N\n",
    "    HW = w // N\n",
    "    Hist = np.zeros((HH, HW, 9), dtype=np.float32)\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            for j in range(N):\n",
    "                for i in range(N):\n",
    "                    Hist[y, x, gra_n[y*4+j, x*4+i]] += mag[y*4+j, x*4+i]\n",
    "                \n",
    "    ## Normalization\n",
    "    C = 3\n",
    "    eps = 1\n",
    "    for y in range(HH):\n",
    "        for x in range(HW):\n",
    "            #for i in range(9):\n",
    "            Hist[y, x] /= np.sqrt(np.sum(Hist[max(y-1,0):min(y+2, HH), max(x-1,0):min(x+2, HW)] ** 2) + eps)\n",
    "\n",
    "    return Hist\n",
    "\n",
    "def resize(img, h, w):\n",
    "    _h, _w  = img.shape\n",
    "    ah = 1. * h / _h\n",
    "    aw = 1. * w / _w\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "    y = (y / ah)\n",
    "    x = (x / aw)\n",
    "\n",
    "    ix = np.floor(x).astype(np.int32)\n",
    "    iy = np.floor(y).astype(np.int32)\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _h-2)\n",
    "\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "    \n",
    "    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]\n",
    "    out[out>255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ind=2, w=64, w2=64, outd=1, lr=0.1):\n",
    "        self.w2 = np.random.randn(ind, w)\n",
    "        self.b2 = np.random.randn(w)\n",
    "        self.w3 = np.random.randn(w, w2)\n",
    "        self.b3 = np.random.randn(w2)\n",
    "        self.wout = np.random.randn(w2, outd)\n",
    "        self.bout = np.random.randn(outd)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = x\n",
    "        self.z2 = self.sigmoid(np.dot(self.z1, self.w2) + self.b2)\n",
    "        self.z3 = self.sigmoid(np.dot(self.z2, self.w3) + self.b3)\n",
    "        self.out = self.sigmoid(np.dot(self.z3, self.wout) + self.bout)\n",
    "        return self.out\n",
    "\n",
    "    def train(self, x, t):\n",
    "        # backpropagation output layer\n",
    "        out_d = 2*(self.out - t) * self.out * (1 - self.out)\n",
    "        out_dW = np.dot(self.z3.T, out_d)\n",
    "        out_dB = np.dot(np.ones([1, out_d.shape[0]]), out_d)\n",
    "        self.wout -= self.lr * out_dW\n",
    "        self.bout -= self.lr * out_dB[0]\n",
    "\n",
    "        w3_d = np.dot(out_d, self.wout.T) * self.z3 * (1 - self.z3)\n",
    "        w3_dW = np.dot(self.z2.T, w3_d)\n",
    "        w3_dB = np.dot(np.ones([1, w3_d.shape[0]]), w3_d)\n",
    "        self.w3 -= self.lr * w3_dW\n",
    "        self.b3 -= self.lr * w3_dB[0]\n",
    "        \n",
    "        # backpropagation inter layer\n",
    "        w2_d = np.dot(w3_d, self.w3.T) * self.z2 * (1 - self.z2)\n",
    "        w2_dW = np.dot(self.z1.T, w2_d)\n",
    "        w2_dB = np.dot(np.ones([1, w2_d.shape[0]]), w2_d)\n",
    "        self.w2 -= self.lr * w2_dW\n",
    "        self.b2 -= self.lr * w2_dB[0]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "# crop and create database\n",
    "\n",
    "Crop_num = 200\n",
    "L = 60\n",
    "H_size = 32\n",
    "F_n = ((H_size // 8) ** 2) * 9\n",
    "\n",
    "db = np.zeros((Crop_num, F_n+1))\n",
    "\n",
    "for i in range(Crop_num):\n",
    "    x1 = np.random.randint(W-L)\n",
    "    y1 = np.random.randint(H-L)\n",
    "    x2 = x1 + L\n",
    "    y2 = y1 + L\n",
    "    crop = np.array((x1, y1, x2, y2))\n",
    "\n",
    "    _iou = iou(gt, crop)\n",
    "\n",
    "    if _iou >= 0.5:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "        label = 1\n",
    "    else:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "        label = 0\n",
    "\n",
    "    crop_area = gray[y1:y2, x1:x2]\n",
    "    crop_area = resize(crop_area, H_size, H_size)\n",
    "    _hog = hog(crop_area)\n",
    "    \n",
    "    db[i, :F_n] = _hog.ravel()\n",
    "    db[i, -1] = label\n",
    "\n",
    "\n",
    "## training neural network\n",
    "nn = NN(ind=F_n, lr=0.01)\n",
    "for i in range(10000):\n",
    "    nn.forward(db[:, :F_n])\n",
    "    nn.train(db[:, :F_n], db[:, -1][..., None])\n",
    "\n",
    "\n",
    "# read detect target image\n",
    "img2 = cv2.imread(\"imori_many.jpg\")\n",
    "H2, W2, C2 = img2.shape\n",
    "\n",
    "# Grayscale\n",
    "gray2 = 0.2126 * img2[..., 2] + 0.7152 * img2[..., 1] + 0.0722 * img2[..., 0]\n",
    "\n",
    "# [h, w]\n",
    "recs = np.array(((42, 42), (56, 56), (70, 70)), dtype=np.float32)\n",
    "\n",
    "detects = np.ndarray((0, 5), dtype=np.float32)\n",
    "\n",
    "# sliding window\n",
    "for y in range(0, H2, 4):\n",
    "    for x in range(0, W2, 4):\n",
    "        for rec in recs:\n",
    "            dh = int(rec[0] // 2)\n",
    "            dw = int(rec[1] // 2)\n",
    "            x1 = max(x-dw, 0)\n",
    "            x2 = min(x+dw, W2)\n",
    "            y1 = max(y-dh, 0)\n",
    "            y2 = min(y+dh, H2)\n",
    "            region = gray2[max(y-dh,0):min(y+dh,H2), max(x-dw,0):min(x+dw,W2)]\n",
    "            region = resize(region, H_size, H_size)\n",
    "            region_hog = hog(region).ravel()\n",
    "\n",
    "            score = nn.forward(region_hog)\n",
    "            if score >= 0.7:\n",
    "                #cv2.rectangle(img2, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "                detects = np.vstack((detects, np.array((x1, y1, x2, y2, score))))\n",
    "\n",
    "\n",
    "# Non-maximum suppression\n",
    "def nms(_bboxes, iou_th=0.5, select_num=None, prob_th=None):\n",
    "    #\n",
    "    # Non Maximum Suppression\n",
    "    #\n",
    "    # Argument\n",
    "    #  bboxes(Nx5) ... [bbox-num, 5(leftTopX,leftTopY,w,h, score)]\n",
    "    #  iou_th([float]) ... threshold for iou between bboxes.\n",
    "    #  select_num([int]) ... max number for choice bboxes. If None, this is unvalid.\n",
    "    #  prob_th([float]) ... probability threshold to choice. If None, this is unvalid.\n",
    "    # Return\n",
    "    #  inds ... choced indices for bboxes\n",
    "    #\n",
    "\n",
    "    bboxes = _bboxes.copy()\n",
    "    \n",
    "    bboxes[:, 2] = bboxes[:, 2] - bboxes[:, 0]\n",
    "    bboxes[:, 3] = bboxes[:, 3] - bboxes[:, 1]\n",
    "    \n",
    "    # Sort by bbox's score. High -> Low\n",
    "    sort_inds = np.argsort(bboxes[:, -1])[::-1]\n",
    "\n",
    "    processed_bbox_ind = []\n",
    "    return_inds = []\n",
    "\n",
    "    unselected_inds = sort_inds.copy()\n",
    "    \n",
    "    while len(unselected_inds) > 0:\n",
    "        process_bboxes = bboxes[unselected_inds]\n",
    "        argmax_score_ind = np.argmax(process_bboxes[::, -1])\n",
    "        max_score_ind = unselected_inds[argmax_score_ind]\n",
    "        return_inds += [max_score_ind]\n",
    "        unselected_inds = np.delete(unselected_inds, argmax_score_ind)\n",
    "\n",
    "        base_bbox = bboxes[max_score_ind]\n",
    "        compare_bboxes = bboxes[unselected_inds]\n",
    "        \n",
    "        base_x1 = base_bbox[0]\n",
    "        base_y1 = base_bbox[1]\n",
    "        base_x2 = base_bbox[2] + base_x1\n",
    "        base_y2 = base_bbox[3] + base_y1\n",
    "        base_w = np.maximum(base_bbox[2], 0)\n",
    "        base_h = np.maximum(base_bbox[3], 0)\n",
    "        base_area = base_w * base_h\n",
    "\n",
    "        # compute iou-area between base bbox and other bboxes\n",
    "        iou_x1 = np.maximum(base_x1, compare_bboxes[:, 0])\n",
    "        iou_y1 = np.maximum(base_y1, compare_bboxes[:, 1])\n",
    "        iou_x2 = np.minimum(base_x2, compare_bboxes[:, 2] + compare_bboxes[:, 0])\n",
    "        iou_y2 = np.minimum(base_y2, compare_bboxes[:, 3] + compare_bboxes[:, 1])\n",
    "        iou_w = np.maximum(iou_x2 - iou_x1, 0)\n",
    "        iou_h = np.maximum(iou_y2 - iou_y1, 0)\n",
    "        iou_area = iou_w * iou_h\n",
    "\n",
    "        compare_w = np.maximum(compare_bboxes[:, 2], 0)\n",
    "        compare_h = np.maximum(compare_bboxes[:, 3], 0)\n",
    "        compare_area = compare_w * compare_h\n",
    "\n",
    "        # bbox's index which iou ratio over threshold is excluded\n",
    "        all_area = compare_area + base_area - iou_area\n",
    "        iou_ratio = np.zeros((len(unselected_inds)))\n",
    "        iou_ratio[all_area < 0.9] = 0.\n",
    "        _ind = all_area >= 0.9\n",
    "        iou_ratio[_ind] = iou_area[_ind] / all_area[_ind]\n",
    "        \n",
    "        unselected_inds = np.delete(unselected_inds, np.where(iou_ratio >= iou_th)[0])\n",
    "\n",
    "    if prob_th is not None:\n",
    "        preds = bboxes[return_inds][:, -1]\n",
    "        return_inds = np.array(return_inds)[np.where(preds >= prob_th)[0]].tolist()\n",
    "        \n",
    "    # pick bbox's index by defined number with higher score\n",
    "    if select_num is not None:\n",
    "        return_inds = return_inds[:select_num]\n",
    "\n",
    "    return return_inds\n",
    "\n",
    "\n",
    "detects = detects[nms(detects, iou_th=0.25)]\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# [x1, y1, x2, y2]\n",
    "GT = np.array(((27, 48, 95, 110), (101, 75, 171, 138)), dtype=np.float32)\n",
    "\n",
    "## Recall, Precision, F-score\n",
    "iou_th = 0.5\n",
    "\n",
    "Rs = np.zeros((len(GT)))\n",
    "Ps = np.zeros((len(detects)))\n",
    "\n",
    "for i, g in enumerate(GT):\n",
    "    iou_x1 = np.maximum(g[0], detects[:, 0])\n",
    "    iou_y1 = np.maximum(g[1], detects[:, 1])\n",
    "    iou_x2 = np.minimum(g[2], detects[:, 2])\n",
    "    iou_y2 = np.minimum(g[3], detects[:, 3])\n",
    "    iou_w = np.maximum(0, iou_x2 - iou_x1)\n",
    "    iou_h = np.maximum(0, iou_y2 - iou_y1)\n",
    "    iou_area = iou_w * iou_h\n",
    "    g_area = (g[2] - g[0]) * (g[3] - g[1])\n",
    "    d_area = (detects[:, 2] - detects[:, 0]) * (detects[:, 3] - detects[:, 1])\n",
    "    ious = iou_area / (g_area + d_area - iou_area)\n",
    "    \n",
    "    Rs[i] = 1 if len(np.where(ious >= iou_th)[0]) > 0 else 0\n",
    "    Ps[ious >= iou_th] = 1\n",
    "    \n",
    "\n",
    "R = np.sum(Rs) / len(Rs)\n",
    "P = np.sum(Ps) / len(Ps)\n",
    "F = (2 * P * R) / (P + R) \n",
    "\n",
    "print(\"Recall >> {:.2f} ({} / {})\".format(R, np.sum(Rs), len(Rs)))\n",
    "print(\"Precision >> {:.2f} ({} / {})\".format(P, np.sum(Ps), len(Ps)))\n",
    "print(\"F-score >> \", F)\n",
    "\n",
    "## mAP\n",
    "mAP = 0.\n",
    "for i in range(len(detects)):\n",
    "    mAP += np.sum(Ps[:i]) / (i + 1) * Ps[i]\n",
    "mAP /= np.sum(Ps)\n",
    "\n",
    "print(\"mAP >>\", mAP)\n",
    "\n",
    "# Display\n",
    "for i in range(len(detects)):\n",
    "    v = list(map(int, detects[i, :4]))\n",
    "    if Ps[i] > 0:\n",
    "        cv2.rectangle(img2, (v[0], v[1]), (v[2], v[3]), (0,0,255), 1)\n",
    "    else:\n",
    "        cv2.rectangle(img2, (v[0], v[1]), (v[2], v[3]), (255,0,0), 1)\n",
    "    cv2.putText(img2, \"{:.2f}\".format(detects[i, -1]), (v[0], v[1]+9),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,0,255), 1)\n",
    "\n",
    "for g in GT:\n",
    "    cv2.rectangle(img2, (g[0], g[1]), (g[2], g[3]), (0,255,0), 1)\n",
    "\n",
    "cv2.imwrite(\"out.jpg\", img2)\n",
    "cv2.imshow(\"result\", img2)\n",
    "cv2.waitKey(0)\n",
    "```\n",
    "</div></details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/2905304360bdfc5bea53f1a16e0f877c"
  },
  "gist": {
   "data": {
    "description": "言語処理100本ノック.ipynb",
    "public": true
   },
   "id": "2905304360bdfc5bea53f1a16e0f877c"
  },
  "kernelspec": {
   "display_name": "gasyori100",
   "language": "python",
   "name": "gasyori100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "目次",
   "title_sidebar": "目次",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
